{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6b7cee",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-12T12:00:25.521415Z",
     "iopub.status.busy": "2025-12-12T12:00:25.521104Z",
     "iopub.status.idle": "2025-12-12T12:01:46.896306Z",
     "shell.execute_reply": "2025-12-12T12:01:46.895223Z"
    },
    "papermill": {
     "duration": 81.382283,
     "end_time": "2025-12-12T12:01:46.897976",
     "exception": false,
     "start_time": "2025-12-12T12:00:25.515693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing /kaggle/input ...\n",
      "Device: cuda\n",
      "[*INFO] Installing libraries...\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 287.4/287.4 kB 9.2 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 252.4 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 171.2 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 102.4 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 274.2 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 247.0 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 255.6 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 198.3 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 156.4 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 216.7 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 226.2 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*INFO] Cleaning up memory after installation...\n",
      "[*INFO] Cloning AST repo ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/ast'...\n",
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# secret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "# from huggingface_hub import HfApi, login\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import sys\n",
    "import subprocess\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "# AST Fine-tuning on UrbanSound8K (Kaggle version)\n",
    "# - Auto-detect UrbanSound8K in /kaggle/input\n",
    "# - Clone AST repo into /kaggle/working/ast\n",
    "# - Download AudioSet checkpoint\n",
    "# - 10-fold cross-validation training\n",
    "\n",
    "\n",
    "\n",
    "# 0. ENV INFO & SEED\n",
    "print(\"Listing /kaggle/input ...\")\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "# 1. INSTALL REQUIRED LIBRARIES (if needed)\n",
    "import gc # <--- Import thư viện dọn rác\n",
    "\n",
    "def pip_install(package):\n",
    "    # Thêm \"--no-cache-dir\" để không ngốn RAM lưu file tạm\n",
    "    # Thêm \"-q\" (quiet) để giảm log in ra màn hình\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"-q\", package])\n",
    "\n",
    "print(\"[*INFO] Installing libraries...\")\n",
    "# timm==0.4.5 là bản được AST repo dùng\n",
    "pip_install(\"timm==0.4.5\")\n",
    "pip_install(\"wget\")\n",
    "pip_install(\"librosa\")\n",
    "\n",
    "\n",
    "print(\"[*INFO] Cleaning up memory after installation...\")\n",
    "gc.collect() \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "# ======================================================\n",
    "\n",
    "import timm\n",
    "import wget\n",
    "\n",
    "# 2. CLONE AST REPO VÀ IMPORT ASTModel\n",
    "REPO_DIR = \"/kaggle/working/ast\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print(\"[*INFO] Cloning AST repo ...\")\n",
    "    subprocess.check_call([\"git\", \"clone\", \"https://github.com/YuanGongND/ast\", REPO_DIR])\n",
    "else:\n",
    "    print(\"[*INFO] AST repo already exists at\", REPO_DIR)\n",
    "\n",
    "sys.path.append(REPO_DIR)\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "from src.models import ASTModel  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1926138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:01:46.906931Z",
     "iopub.status.busy": "2025-12-12T12:01:46.906616Z",
     "iopub.status.idle": "2025-12-12T12:01:54.487228Z",
     "shell.execute_reply": "2025-12-12T12:01:54.486208Z"
    },
    "papermill": {
     "duration": 7.586487,
     "end_time": "2025-12-12T12:01:54.488590",
     "exception": false,
     "start_time": "2025-12-12T12:01:46.902103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*INFO] Found UrbanSound8K.csv at: /kaggle/input/urbansound8k/UrbanSound8K.csv\n",
      "[*INFO] Sample row -> fold=5, fname=100032-3-0-0.wav\n",
      "[*INFO] AUDIO_ROOT detected as: /kaggle/input/urbansound8k\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. TÌM METADATA CSV UrbanSound8K\n",
    "US8K_META_PATH = None\n",
    "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "    if \"UrbanSound8K.csv\" in files:\n",
    "        US8K_META_PATH = os.path.join(root, \"UrbanSound8K.csv\")\n",
    "        break\n",
    "\n",
    "if US8K_META_PATH is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Không tìm thấy UrbanSound8K.csv trong /kaggle/input. \"\n",
    "        \"Kiểm tra lại dataset UrbanSound8K đã add vào notebook.\"\n",
    "    )\n",
    "\n",
    "print(\"[*INFO] Found UrbanSound8K.csv at:\", US8K_META_PATH)\n",
    "METADATA_CSV = US8K_META_PATH\n",
    "\n",
    "# 4. TÌM CHÍNH XÁC AUDIO_ROOT BẰNG CÁCH DÒ FILE THẬT\n",
    "\n",
    "df_meta = pd.read_csv(METADATA_CSV)\n",
    "sample_row = df_meta.iloc[0]\n",
    "sample_fname = sample_row[\"slice_file_name\"]\n",
    "sample_fold = sample_row[\"fold\"]\n",
    "target_fold_dir = f\"fold{sample_fold}\"\n",
    "\n",
    "print(f\"[*INFO] Sample row -> fold={sample_fold}, fname={sample_fname}\")\n",
    "\n",
    "AUDIO_ROOT = None\n",
    "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "    if os.path.basename(root) == target_fold_dir and sample_fname in files:\n",
    "        # root = .../audio/foldX\n",
    "        AUDIO_ROOT = os.path.dirname(root)  # bỏ /foldX\n",
    "        break\n",
    "\n",
    "if AUDIO_ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Không tìm thấy thư mục audio chứa fold{sample_fold} và file {sample_fname} trong /kaggle/input.\"\n",
    "    )\n",
    "\n",
    "print(\"[*INFO] AUDIO_ROOT detected as:\", AUDIO_ROOT)\n",
    "\n",
    "# Thư mục lưu checkpoint\n",
    "CKPT_DIR = \"/kaggle/working/ast_us8k_checkpoints\"\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0db91176",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:01:54.497764Z",
     "iopub.status.busy": "2025-12-12T12:01:54.497523Z",
     "iopub.status.idle": "2025-12-12T12:01:54.501356Z",
     "shell.execute_reply": "2025-12-12T12:01:54.500693Z"
    },
    "papermill": {
     "duration": 0.009567,
     "end_time": "2025-12-12T12:01:54.502406",
     "exception": false,
     "start_time": "2025-12-12T12:01:54.492839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/urbansound8k\n"
     ]
    }
   ],
   "source": [
    "print(AUDIO_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b2ccf3",
   "metadata": {
    "papermill": {
     "duration": 0.003846,
     "end_time": "2025-12-12T12:01:54.509988",
     "exception": false,
     "start_time": "2025-12-12T12:01:54.506142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06fd8bd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:01:54.517807Z",
     "iopub.status.busy": "2025-12-12T12:01:54.517621Z",
     "iopub.status.idle": "2025-12-12T12:01:54.523010Z",
     "shell.execute_reply": "2025-12-12T12:01:54.522229Z"
    },
    "papermill": {
     "duration": 0.010714,
     "end_time": "2025-12-12T12:01:54.524215",
     "exception": false,
     "start_time": "2025-12-12T12:01:54.513501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /kaggle/working/ast\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "try:\n",
    "    REPO_DIR\n",
    "except NameError:\n",
    "    REPO_DIR = Path('.').resolve()\n",
    "else:\n",
    "    REPO_DIR = Path(REPO_DIR)\n",
    "TORCH_HOME = REPO_DIR / 'pretrained_models'\n",
    "os.environ['TORCH_HOME'] = str(TORCH_HOME)\n",
    "TORCH_HOME.mkdir(exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Repo root:', REPO_DIR)\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72b6448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:01:54.532381Z",
     "iopub.status.busy": "2025-12-12T12:01:54.531926Z",
     "iopub.status.idle": "2025-12-12T12:01:54.563211Z",
     "shell.execute_reply": "2025-12-12T12:01:54.562562Z"
    },
    "papermill": {
     "duration": 0.036681,
     "end_time": "2025-12-12T12:01:54.564334",
     "exception": false,
     "start_time": "2025-12-12T12:01:54.527653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label CSV written to: /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv\n"
     ]
    }
   ],
   "source": [
    "# Build label CSV (index, mid, display_name)\n",
    "meta_df = pd.read_csv(METADATA_CSV)\n",
    "label_csv = REPO_DIR / 'urban8k_data' / 'urban8k_class_labels_indices.csv'\n",
    "label_csv.parent.mkdir(exist_ok=True)\n",
    "\n",
    "unique_classes = meta_df[['classID', 'class']].drop_duplicates().sort_values('classID')\n",
    "with open(label_csv, 'w') as f:\n",
    "    f.write('index,mid,display_name\\n')\n",
    "    for _, row in unique_classes.iterrows():\n",
    "        idx = int(row['classID'])\n",
    "        mid = f\"/m/urban{idx:02d}\"\n",
    "        name = row['class']\n",
    "        f.write(f\"{idx},{mid},{name}\\n\")\n",
    "\n",
    "print('Label CSV written to:', label_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60dcf75b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:01:54.573142Z",
     "iopub.status.busy": "2025-12-12T12:01:54.572401Z",
     "iopub.status.idle": "2025-12-12T12:02:00.030720Z",
     "shell.execute_reply": "2025-12-12T12:02:00.029780Z"
    },
    "papermill": {
     "duration": 5.463881,
     "end_time": "2025-12-12T12:02:00.032015",
     "exception": false,
     "start_time": "2025-12-12T12:01:54.568134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: train 7859, eval 873\n",
      "Fold 2: train 7844, eval 888\n",
      "Fold 3: train 7807, eval 925\n",
      "Fold 4: train 7742, eval 990\n",
      "Fold 5: train 7796, eval 936\n",
      "Fold 6: train 7909, eval 823\n",
      "Fold 7: train 7894, eval 838\n",
      "Fold 8: train 7926, eval 806\n",
      "Fold 9: train 7916, eval 816\n",
      "Fold 10: train 7895, eval 837\n"
     ]
    }
   ],
   "source": [
    "import json, shutil\n",
    "\n",
    "# Create JSON datafiles per fold (ESC-50 style)\n",
    "data_dir = REPO_DIR / 'urban8k_data' / 'datafiles'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def rows_for_df(df):\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        wav_path = Path(AUDIO_ROOT) / f\"fold{int(r['fold'])}\" / r['slice_file_name']\n",
    "        rows.append({\n",
    "            'wav': str(wav_path),\n",
    "            'labels': f\"/m/urban{int(r['classID']):02d}\"\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "for fold in range(1, 11):\n",
    "    train_df = meta_df[meta_df['fold'] != fold]\n",
    "    eval_df = meta_df[meta_df['fold'] == fold]\n",
    "    train_json = {'data': rows_for_df(train_df)}\n",
    "    eval_json = {'data': rows_for_df(eval_df)}\n",
    "    with open(data_dir / f'urban_train_data_{fold}.json', 'w') as f:\n",
    "        json.dump(train_json, f, indent=1)\n",
    "    with open(data_dir / f'urban_eval_data_{fold}.json', 'w') as f:\n",
    "        json.dump(eval_json, f, indent=1)\n",
    "    print(f'Fold {fold}: train {len(train_df)}, eval {len(eval_df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8837fad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:02:00.041782Z",
     "iopub.status.busy": "2025-12-12T12:02:00.041580Z",
     "iopub.status.idle": "2025-12-12T12:02:00.051019Z",
     "shell.execute_reply": "2025-12-12T12:02:00.050136Z"
    },
    "papermill": {
     "duration": 0.015516,
     "end_time": "2025-12-12T12:02:00.052163",
     "exception": false,
     "start_time": "2025-12-12T12:02:00.036647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mean/std: -1.7362523965764032 3.2758855893221015\n"
     ]
    }
   ],
   "source": [
    "# Compute dataset mean/std over fbank features (optional; default uses AudioSet stats)\n",
    "import torchaudio\n",
    "\n",
    "def compute_norm_stats(df, target_length=1024, mel_bins=128, target_sr=16000, max_files=None):\n",
    "    total = 0.0\n",
    "    total_sq = 0.0\n",
    "    count = 0\n",
    "    rows = df if max_files is None else df.sample(n=max_files, random_state=SEED)\n",
    "    for _, r in rows.iterrows():\n",
    "        wav_path = Path(AUDIO_ROOT) / f\"fold{int(r['fold'])}\" / r['slice_file_name']\n",
    "        wav, sr = torchaudio.load(str(wav_path))\n",
    "        if wav.shape[0] > 1:\n",
    "            wav = wav.mean(dim=0, keepdim=True)\n",
    "        if sr != target_sr:\n",
    "            wav = torchaudio.transforms.Resample(sr, target_sr)(wav)\n",
    "            sr = target_sr\n",
    "        fb = torchaudio.compliance.kaldi.fbank(\n",
    "            wav, htk_compat=True, sample_frequency=sr, use_energy=False,\n",
    "            window_type='hanning', num_mel_bins=mel_bins, dither=0.0, frame_shift=10\n",
    "        )\n",
    "        p = target_length - fb.shape[0]\n",
    "        if p > 0:\n",
    "            fb = torch.nn.functional.pad(fb, (0, 0, 0, p))\n",
    "        elif p < 0:\n",
    "            fb = fb[:target_length, :]\n",
    "        total += fb.sum().item()\n",
    "        total_sq += (fb ** 2).sum().item()\n",
    "        count += fb.numel()\n",
    "    mean = total / count\n",
    "    var = total_sq / count - mean ** 2\n",
    "    std = var ** 0.5\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "try:\n",
    "    DATASET_MEAN\n",
    "    DATASET_STD\n",
    "except NameError:\n",
    "    DATASET_MEAN = -1.7362523965764032\n",
    "    DATASET_STD = 3.2758855893221015\n",
    "print('Using mean/std:', DATASET_MEAN, DATASET_STD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b984d23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:02:00.061933Z",
     "iopub.status.busy": "2025-12-12T12:02:00.061675Z",
     "iopub.status.idle": "2025-12-12T12:02:00.070060Z",
     "shell.execute_reply": "2025-12-12T12:02:00.069326Z"
    },
    "papermill": {
     "duration": 0.014567,
     "end_time": "2025-12-12T12:02:00.071164",
     "exception": false,
     "start_time": "2025-12-12T12:02:00.056597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH_HOME: /kaggle/pretrained_models\n",
      "Helper ready: run_fold(fold) to launch training\n"
     ]
    }
   ],
   "source": [
    "REPO_DIR = Path('.').resolve()\n",
    "PRETRAIN_DIR = (REPO_DIR / '../../pretrained_models').resolve()\n",
    "PRETRAIN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "os.environ['TORCH_HOME'] = str(PRETRAIN_DIR)\n",
    "print('TORCH_HOME:', PRETRAIN_DIR)\n",
    "# Helper to launch training via src/run.py with ESC-50-like hyperparameters\n",
    "def run_fold(fold, epochs=3, batch_size=12, lr=1e-5):\n",
    "    exp_dir = REPO_DIR / 'urban8k_exp' / f'fold{fold}'\n",
    "    if exp_dir.exists():\n",
    "        shutil.rmtree(exp_dir)\n",
    "    exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    train_json = data_dir / f'urban_train_data_{fold}.json'\n",
    "    eval_json = data_dir / f'urban_eval_data_{fold}.json'\n",
    "\n",
    "    cmd = [\n",
    "        sys.executable, 'src/run.py',\n",
    "        '--model', 'ast',\n",
    "        '--dataset', 'urban8k',\n",
    "        '--data-train', str(train_json),\n",
    "        '--data-val', str(eval_json),\n",
    "        '--exp-dir', str(exp_dir),\n",
    "        '--label-csv', str(label_csv),\n",
    "        '--n_class', '10',\n",
    "        '--lr', str(lr),\n",
    "        '--n-epochs', str(epochs),\n",
    "        '--batch-size', str(batch_size),\n",
    "        '--save_model', 'False',\n",
    "        '--freqm', '24',\n",
    "        '--timem', '96',\n",
    "        '--mixup', '0',\n",
    "        '--bal', 'none',\n",
    "        '--tstride', '10', '--fstride', '10',\n",
    "        '--imagenet_pretrain', 'True',\n",
    "        '--audioset_pretrain', 'False',\n",
    "        '--metrics', 'acc',\n",
    "        '--loss', 'CE',\n",
    "        '--warmup', 'False',\n",
    "        '--lrscheduler_start', '5',\n",
    "        '--lrscheduler_step', '1',\n",
    "        '--lrscheduler_decay', '0.85',\n",
    "        '--dataset_mean', str(DATASET_MEAN),\n",
    "        '--dataset_std', str(DATASET_STD),\n",
    "        '--audio_length', '1024',\n",
    "        '--noise', 'False',\n",
    "        '--num-workers', '4',\n",
    "        '--n-print-steps', '50'\n",
    "    ]\n",
    "    env = os.environ.copy()\n",
    "    env['TORCH_HOME'] = str(TORCH_HOME)\n",
    "    print(f'Running fold {fold}:', ' '.join(cmd))\n",
    "    subprocess.check_call(cmd, env=env, cwd=REPO_DIR)\n",
    "\n",
    "print('Helper ready: run_fold(fold) to launch training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0911a31b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:02:00.080986Z",
     "iopub.status.busy": "2025-12-12T12:02:00.080273Z",
     "iopub.status.idle": "2025-12-12T14:35:27.320688Z",
     "shell.execute_reply": "2025-12-12T14:35:27.319758Z"
    },
    "papermill": {
     "duration": 9207.246864,
     "end_time": "2025-12-12T14:35:27.322219",
     "exception": false,
     "start_time": "2025-12-12T12:02:00.075355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 1: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_1.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_1.json --exp-dir /kaggle/working/ast/urban8k_exp/fold1 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain False --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_384-d0272ac0.pth\" to ../../pretrained_models/hub/checkpoints/deit_base_distilled_patch16_384-d0272ac0.pth\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 88, running on b3680011ca52: starting (Fri Dec 12 12:02:04 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: False\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold1\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7a4b23d03fd0>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 12:02:07.482634\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/655]\tPer Sample Total Time 0.06889\tPer Sample Data Time 0.00141\tPer Sample DNN Time 0.06748\tTrain Loss 1.8805\t\n",
      "Epoch: [1][100/655]\tPer Sample Total Time 0.06818\tPer Sample Data Time 0.00073\tPer Sample DNN Time 0.06746\tTrain Loss 1.5086\t\n",
      "Epoch: [1][150/655]\tPer Sample Total Time 0.06980\tPer Sample Data Time 0.00050\tPer Sample DNN Time 0.06930\tTrain Loss 1.2702\t\n",
      "Epoch: [1][200/655]\tPer Sample Total Time 0.07152\tPer Sample Data Time 0.00038\tPer Sample DNN Time 0.07114\tTrain Loss 1.1106\t\n",
      "Epoch: [1][250/655]\tPer Sample Total Time 0.07217\tPer Sample Data Time 0.00031\tPer Sample DNN Time 0.07186\tTrain Loss 1.0002\t\n",
      "Epoch: [1][300/655]\tPer Sample Total Time 0.07269\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.07242\tTrain Loss 0.9039\t\n",
      "Epoch: [1][350/655]\tPer Sample Total Time 0.07295\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.07272\tTrain Loss 0.8427\t\n",
      "Epoch: [1][400/655]\tPer Sample Total Time 0.07318\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.07297\tTrain Loss 0.7948\t\n",
      "Epoch: [1][450/655]\tPer Sample Total Time 0.07335\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07316\tTrain Loss 0.7439\t\n",
      "Epoch: [1][500/655]\tPer Sample Total Time 0.07346\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.07329\tTrain Loss 0.7012\t\n",
      "Epoch: [1][550/655]\tPer Sample Total Time 0.07353\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07336\tTrain Loss 0.6676\t\n",
      "Epoch: [1][600/655]\tPer Sample Total Time 0.07361\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07346\tTrain Loss 0.6375\t\n",
      "Epoch: [1][650/655]\tPer Sample Total Time 0.07367\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07353\tTrain Loss 0.6065\t\n",
      "start validation\n",
      "acc: 0.775487\n",
      "AUC: 0.973304\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.731886\n",
      "train_loss: 0.603914\n",
      "valid_loss: 1.838867\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 607.066\n",
      "---------------\n",
      "2025-12-12 12:12:14.548967\n",
      "current #epochs=2, #steps=655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][45/655]\tPer Sample Total Time 0.07562\tPer Sample Data Time 0.00115\tPer Sample DNN Time 0.07447\tTrain Loss 0.2153\t\n",
      "Epoch: [2][95/655]\tPer Sample Total Time 0.07487\tPer Sample Data Time 0.00057\tPer Sample DNN Time 0.07430\tTrain Loss 0.2227\t\n",
      "Epoch: [2][145/655]\tPer Sample Total Time 0.07478\tPer Sample Data Time 0.00039\tPer Sample DNN Time 0.07439\tTrain Loss 0.2120\t\n",
      "Epoch: [2][195/655]\tPer Sample Total Time 0.07465\tPer Sample Data Time 0.00030\tPer Sample DNN Time 0.07435\tTrain Loss 0.1982\t\n",
      "Epoch: [2][245/655]\tPer Sample Total Time 0.07457\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.07433\tTrain Loss 0.1901\t\n",
      "Epoch: [2][295/655]\tPer Sample Total Time 0.07454\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.07433\tTrain Loss 0.1910\t\n",
      "Epoch: [2][345/655]\tPer Sample Total Time 0.07451\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.07433\tTrain Loss 0.1851\t\n",
      "Epoch: [2][395/655]\tPer Sample Total Time 0.07448\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07431\tTrain Loss 0.1830\t\n",
      "Epoch: [2][445/655]\tPer Sample Total Time 0.07446\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07431\tTrain Loss 0.1817\t\n",
      "Epoch: [2][495/655]\tPer Sample Total Time 0.07443\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07429\tTrain Loss 0.1805\t\n",
      "Epoch: [2][545/655]\tPer Sample Total Time 0.07443\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07431\tTrain Loss 0.1802\t\n",
      "Epoch: [2][595/655]\tPer Sample Total Time 0.07440\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07427\tTrain Loss 0.1759\t\n",
      "Epoch: [2][645/655]\tPer Sample Total Time 0.07437\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.07426\tTrain Loss 0.1738\t\n",
      "start validation\n",
      "acc: 0.791523\n",
      "AUC: 0.978679\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.866891\n",
      "train_loss: 0.174510\n",
      "valid_loss: 1.813477\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 613.030\n",
      "---------------\n",
      "2025-12-12 12:22:27.579146\n",
      "current #epochs=3, #steps=1310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][40/655]\tPer Sample Total Time 0.07588\tPer Sample Data Time 0.00127\tPer Sample DNN Time 0.07461\tTrain Loss 0.0932\t\n",
      "Epoch: [3][90/655]\tPer Sample Total Time 0.07469\tPer Sample Data Time 0.00059\tPer Sample DNN Time 0.07410\tTrain Loss 0.0901\t\n",
      "Epoch: [3][140/655]\tPer Sample Total Time 0.07439\tPer Sample Data Time 0.00039\tPer Sample DNN Time 0.07399\tTrain Loss 0.0953\t\n",
      "Epoch: [3][190/655]\tPer Sample Total Time 0.07433\tPer Sample Data Time 0.00030\tPer Sample DNN Time 0.07403\tTrain Loss 0.0938\t\n",
      "Epoch: [3][240/655]\tPer Sample Total Time 0.07430\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.07406\tTrain Loss 0.0907\t\n",
      "Epoch: [3][290/655]\tPer Sample Total Time 0.07428\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.07407\tTrain Loss 0.0942\t\n",
      "Epoch: [3][340/655]\tPer Sample Total Time 0.07426\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.07408\tTrain Loss 0.0961\t\n",
      "Epoch: [3][390/655]\tPer Sample Total Time 0.07425\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07409\tTrain Loss 0.0995\t\n",
      "Epoch: [3][440/655]\tPer Sample Total Time 0.07425\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07410\tTrain Loss 0.1000\t\n",
      "Epoch: [3][490/655]\tPer Sample Total Time 0.07422\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07408\tTrain Loss 0.0963\t\n",
      "Epoch: [3][540/655]\tPer Sample Total Time 0.07420\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07407\tTrain Loss 0.0952\t\n",
      "Epoch: [3][590/655]\tPer Sample Total Time 0.07418\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07406\tTrain Loss 0.0914\t\n",
      "Epoch: [3][640/655]\tPer Sample Total Time 0.07417\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.07405\tTrain Loss 0.0896\t\n",
      "start validation\n",
      "acc: 0.785796\n",
      "AUC: 0.974676\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.764004\n",
      "train_loss: 0.088060\n",
      "valid_loss: 1.810547\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 609.371\n",
      "Running fold 2: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_2.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_2.json --exp-dir /kaggle/working/ast/urban8k_exp/fold2 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain False --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 4371, running on b3680011ca52: starting (Fri Dec 12 12:32:41 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: False\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold2\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x79e12885aa90>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 12:32:43.611063\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/654]\tPer Sample Total Time 0.07961\tPer Sample Data Time 0.00112\tPer Sample DNN Time 0.07850\tTrain Loss 1.8145\t\n",
      "Epoch: [1][100/654]\tPer Sample Total Time 0.07705\tPer Sample Data Time 0.00058\tPer Sample DNN Time 0.07647\tTrain Loss 1.4486\t\n",
      "Epoch: [1][150/654]\tPer Sample Total Time 0.07652\tPer Sample Data Time 0.00040\tPer Sample DNN Time 0.07612\tTrain Loss 1.2559\t\n",
      "Epoch: [1][200/654]\tPer Sample Total Time 0.07604\tPer Sample Data Time 0.00031\tPer Sample DNN Time 0.07573\tTrain Loss 1.1082\t\n",
      "Epoch: [1][250/654]\tPer Sample Total Time 0.07586\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.07560\tTrain Loss 1.0011\t\n",
      "Epoch: [1][300/654]\tPer Sample Total Time 0.07568\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.07547\tTrain Loss 0.9066\t\n",
      "Epoch: [1][350/654]\tPer Sample Total Time 0.07557\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07538\tTrain Loss 0.8389\t\n",
      "Epoch: [1][400/654]\tPer Sample Total Time 0.07549\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07532\tTrain Loss 0.7867\t\n",
      "Epoch: [1][450/654]\tPer Sample Total Time 0.07543\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07527\tTrain Loss 0.7373\t\n",
      "Epoch: [1][500/654]\tPer Sample Total Time 0.07535\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07521\tTrain Loss 0.6986\t\n",
      "Epoch: [1][550/654]\tPer Sample Total Time 0.07531\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07517\tTrain Loss 0.6702\t\n",
      "Epoch: [1][600/654]\tPer Sample Total Time 0.07526\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07513\tTrain Loss 0.6405\t\n",
      "Epoch: [1][650/654]\tPer Sample Total Time 0.07522\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07510\tTrain Loss 0.6164\t\n",
      "start validation\n",
      "acc: 0.802928\n",
      "AUC: 0.983514\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.015694\n",
      "train_loss: 0.615801\n",
      "valid_loss: 1.835938\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 618.602\n",
      "---------------\n",
      "2025-12-12 12:43:02.212742\n",
      "current #epochs=2, #steps=654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][46/654]\tPer Sample Total Time 0.07592\tPer Sample Data Time 0.00106\tPer Sample DNN Time 0.07486\tTrain Loss 0.2260\t\n",
      "Epoch: [2][96/654]\tPer Sample Total Time 0.07503\tPer Sample Data Time 0.00053\tPer Sample DNN Time 0.07449\tTrain Loss 0.2051\t\n",
      "Epoch: [2][146/654]\tPer Sample Total Time 0.07494\tPer Sample Data Time 0.00037\tPer Sample DNN Time 0.07457\tTrain Loss 0.2089\t\n",
      "Epoch: [2][196/654]\tPer Sample Total Time 0.07484\tPer Sample Data Time 0.00028\tPer Sample DNN Time 0.07456\tTrain Loss 0.2052\t\n",
      "Epoch: [2][246/654]\tPer Sample Total Time 0.07476\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.07453\tTrain Loss 0.1956\t\n",
      "Epoch: [2][296/654]\tPer Sample Total Time 0.07471\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.07452\tTrain Loss 0.1924\t\n",
      "Epoch: [2][346/654]\tPer Sample Total Time 0.07471\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.07454\tTrain Loss 0.1942\t\n",
      "Epoch: [2][396/654]\tPer Sample Total Time 0.07468\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07452\tTrain Loss 0.1887\t\n",
      "Epoch: [2][446/654]\tPer Sample Total Time 0.07466\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07451\tTrain Loss 0.1836\t\n",
      "Epoch: [2][496/654]\tPer Sample Total Time 0.07465\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07452\tTrain Loss 0.1820\t\n",
      "Epoch: [2][546/654]\tPer Sample Total Time 0.07462\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07450\tTrain Loss 0.1823\t\n",
      "Epoch: [2][596/654]\tPer Sample Total Time 0.07460\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07448\tTrain Loss 0.1826\t\n",
      "Epoch: [2][646/654]\tPer Sample Total Time 0.07458\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.07447\tTrain Loss 0.1822\t\n",
      "start validation\n",
      "acc: 0.789414\n",
      "AUC: 0.984191\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.039447\n",
      "train_loss: 0.181961\n",
      "valid_loss: 1.819336\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 612.362\n",
      "---------------\n",
      "2025-12-12 12:53:14.575167\n",
      "current #epochs=3, #steps=1308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][42/654]\tPer Sample Total Time 0.07552\tPer Sample Data Time 0.00125\tPer Sample DNN Time 0.07427\tTrain Loss 0.1028\t\n",
      "Epoch: [3][92/654]\tPer Sample Total Time 0.07485\tPer Sample Data Time 0.00060\tPer Sample DNN Time 0.07425\tTrain Loss 0.0960\t\n",
      "Epoch: [3][142/654]\tPer Sample Total Time 0.07458\tPer Sample Data Time 0.00040\tPer Sample DNN Time 0.07418\tTrain Loss 0.0936\t\n",
      "Epoch: [3][192/654]\tPer Sample Total Time 0.07458\tPer Sample Data Time 0.00031\tPer Sample DNN Time 0.07428\tTrain Loss 0.1041\t\n",
      "Epoch: [3][242/654]\tPer Sample Total Time 0.07453\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.07428\tTrain Loss 0.1119\t\n",
      "Epoch: [3][292/654]\tPer Sample Total Time 0.07450\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.07429\tTrain Loss 0.1076\t\n",
      "Epoch: [3][342/654]\tPer Sample Total Time 0.07449\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07430\tTrain Loss 0.1040\t\n",
      "Epoch: [3][392/654]\tPer Sample Total Time 0.07446\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07429\tTrain Loss 0.1039\t\n",
      "Epoch: [3][442/654]\tPer Sample Total Time 0.07444\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07429\tTrain Loss 0.1077\t\n",
      "Epoch: [3][492/654]\tPer Sample Total Time 0.07444\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07430\tTrain Loss 0.1047\t\n",
      "Epoch: [3][542/654]\tPer Sample Total Time 0.07444\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07431\tTrain Loss 0.1026\t\n",
      "Epoch: [3][592/654]\tPer Sample Total Time 0.07441\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07429\tTrain Loss 0.1015\t\n",
      "Epoch: [3][642/654]\tPer Sample Total Time 0.07439\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07428\tTrain Loss 0.0995\t\n",
      "start validation\n",
      "acc: 0.809685\n",
      "AUC: 0.985629\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.092894\n",
      "train_loss: 0.098550\n",
      "valid_loss: 1.803711\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 613.001\n",
      "Running fold 3: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_3.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_3.json --exp-dir /kaggle/working/ast/urban8k_exp/fold3 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain False --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 8647, running on b3680011ca52: starting (Fri Dec 12 13:03:32 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: False\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold3\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7c9f6954c210>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 13:03:34.482818\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/651]\tPer Sample Total Time 0.07978\tPer Sample Data Time 0.00098\tPer Sample DNN Time 0.07880\tTrain Loss 1.7638\t\n",
      "Epoch: [1][100/651]\tPer Sample Total Time 0.07692\tPer Sample Data Time 0.00051\tPer Sample DNN Time 0.07641\tTrain Loss 1.4255\t\n",
      "Epoch: [1][150/651]\tPer Sample Total Time 0.07647\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.07612\tTrain Loss 1.2187\t\n",
      "Epoch: [1][200/651]\tPer Sample Total Time 0.07596\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.07569\tTrain Loss 1.0632\t\n",
      "Epoch: [1][250/651]\tPer Sample Total Time 0.07578\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.07555\tTrain Loss 0.9546\t\n",
      "Epoch: [1][300/651]\tPer Sample Total Time 0.07559\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07540\tTrain Loss 0.8681\t\n",
      "Epoch: [1][350/651]\tPer Sample Total Time 0.07549\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07532\tTrain Loss 0.8142\t\n",
      "Epoch: [1][400/651]\tPer Sample Total Time 0.07539\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07523\tTrain Loss 0.7577\t\n",
      "Epoch: [1][450/651]\tPer Sample Total Time 0.07533\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07519\tTrain Loss 0.7126\t\n",
      "Epoch: [1][500/651]\tPer Sample Total Time 0.07526\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07513\tTrain Loss 0.6707\t\n",
      "Epoch: [1][550/651]\tPer Sample Total Time 0.07520\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07507\tTrain Loss 0.6384\t\n",
      "Epoch: [1][600/651]\tPer Sample Total Time 0.07515\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07504\tTrain Loss 0.6138\t\n",
      "Epoch: [1][650/651]\tPer Sample Total Time 0.07512\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.07501\tTrain Loss 0.5871\t\n",
      "start validation\n",
      "acc: 0.716757\n",
      "AUC: 0.961386\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.498918\n",
      "train_loss: 0.587073\n",
      "valid_loss: 1.849609\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 615.825\n",
      "---------------\n",
      "2025-12-12 13:13:50.308170\n",
      "current #epochs=2, #steps=651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][49/651]\tPer Sample Total Time 0.07559\tPer Sample Data Time 0.00101\tPer Sample DNN Time 0.07458\tTrain Loss 0.1568\t\n",
      "Epoch: [2][99/651]\tPer Sample Total Time 0.07512\tPer Sample Data Time 0.00052\tPer Sample DNN Time 0.07460\tTrain Loss 0.1780\t\n",
      "Epoch: [2][149/651]\tPer Sample Total Time 0.07496\tPer Sample Data Time 0.00036\tPer Sample DNN Time 0.07460\tTrain Loss 0.1887\t\n",
      "Epoch: [2][199/651]\tPer Sample Total Time 0.07480\tPer Sample Data Time 0.00028\tPer Sample DNN Time 0.07452\tTrain Loss 0.2003\t\n",
      "Epoch: [2][249/651]\tPer Sample Total Time 0.07474\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.07451\tTrain Loss 0.1896\t\n",
      "Epoch: [2][299/651]\tPer Sample Total Time 0.07468\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.07448\tTrain Loss 0.1955\t\n",
      "Epoch: [2][349/651]\tPer Sample Total Time 0.07465\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.07447\tTrain Loss 0.1969\t\n",
      "Epoch: [2][399/651]\tPer Sample Total Time 0.07462\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07446\tTrain Loss 0.1914\t\n",
      "Epoch: [2][449/651]\tPer Sample Total Time 0.07457\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07443\tTrain Loss 0.1841\t\n",
      "Epoch: [2][499/651]\tPer Sample Total Time 0.07456\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07443\tTrain Loss 0.1793\t\n",
      "Epoch: [2][549/651]\tPer Sample Total Time 0.07453\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07441\tTrain Loss 0.1778\t\n",
      "Epoch: [2][599/651]\tPer Sample Total Time 0.07450\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07439\tTrain Loss 0.1758\t\n",
      "Epoch: [2][649/651]\tPer Sample Total Time 0.07449\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.07438\tTrain Loss 0.1744\t\n",
      "start validation\n",
      "acc: 0.716757\n",
      "AUC: 0.968495\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.629185\n",
      "train_loss: 0.174470\n",
      "valid_loss: 1.829102\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 609.967\n",
      "---------------\n",
      "2025-12-12 13:24:00.274692\n",
      "current #epochs=3, #steps=1302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][48/651]\tPer Sample Total Time 0.07524\tPer Sample Data Time 0.00113\tPer Sample DNN Time 0.07411\tTrain Loss 0.0705\t\n",
      "Epoch: [3][98/651]\tPer Sample Total Time 0.07456\tPer Sample Data Time 0.00058\tPer Sample DNN Time 0.07399\tTrain Loss 0.0872\t\n",
      "Epoch: [3][148/651]\tPer Sample Total Time 0.07437\tPer Sample Data Time 0.00040\tPer Sample DNN Time 0.07398\tTrain Loss 0.0874\t\n",
      "Epoch: [3][198/651]\tPer Sample Total Time 0.07438\tPer Sample Data Time 0.00030\tPer Sample DNN Time 0.07408\tTrain Loss 0.0823\t\n",
      "Epoch: [3][248/651]\tPer Sample Total Time 0.07435\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.07410\tTrain Loss 0.0857\t\n",
      "Epoch: [3][298/651]\tPer Sample Total Time 0.07434\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.07412\tTrain Loss 0.0947\t\n",
      "Epoch: [3][348/651]\tPer Sample Total Time 0.07430\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07412\tTrain Loss 0.0992\t\n",
      "Epoch: [3][398/651]\tPer Sample Total Time 0.07427\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07410\tTrain Loss 0.1002\t\n",
      "Epoch: [3][448/651]\tPer Sample Total Time 0.07426\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07410\tTrain Loss 0.1011\t\n",
      "Epoch: [3][498/651]\tPer Sample Total Time 0.07424\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07410\tTrain Loss 0.1019\t\n",
      "Epoch: [3][548/651]\tPer Sample Total Time 0.07423\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07410\tTrain Loss 0.1014\t\n",
      "Epoch: [3][598/651]\tPer Sample Total Time 0.07424\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07412\tTrain Loss 0.1012\t\n",
      "Epoch: [3][648/651]\tPer Sample Total Time 0.07422\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07410\tTrain Loss 0.1010\t\n",
      "start validation\n",
      "acc: 0.751351\n",
      "AUC: 0.974771\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.766278\n",
      "train_loss: 0.100968\n",
      "valid_loss: 1.821289\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 609.735\n",
      "Running fold 4: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_4.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_4.json --exp-dir /kaggle/working/ast/urban8k_exp/fold4 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain False --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 12917, running on b3680011ca52: starting (Fri Dec 12 13:34:15 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: False\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold4\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f90ecec5d90>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 13:34:16.861934\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/646]\tPer Sample Total Time 0.08019\tPer Sample Data Time 0.00097\tPer Sample DNN Time 0.07922\tTrain Loss 1.8138\t\n",
      "Epoch: [1][100/646]\tPer Sample Total Time 0.07711\tPer Sample Data Time 0.00051\tPer Sample DNN Time 0.07661\tTrain Loss 1.4509\t\n",
      "Epoch: [1][150/646]\tPer Sample Total Time 0.07655\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.07620\tTrain Loss 1.2276\t\n",
      "Epoch: [1][200/646]\tPer Sample Total Time 0.07606\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.07578\tTrain Loss 1.0903\t\n",
      "Epoch: [1][250/646]\tPer Sample Total Time 0.07587\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.07564\tTrain Loss 0.9795\t\n",
      "Epoch: [1][300/646]\tPer Sample Total Time 0.07570\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07550\tTrain Loss 0.8967\t\n",
      "Epoch: [1][350/646]\tPer Sample Total Time 0.07555\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07538\tTrain Loss 0.8265\t\n",
      "Epoch: [1][400/646]\tPer Sample Total Time 0.07544\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07529\tTrain Loss 0.7802\t\n",
      "Epoch: [1][450/646]\tPer Sample Total Time 0.07535\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07521\tTrain Loss 0.7339\t\n",
      "Epoch: [1][500/646]\tPer Sample Total Time 0.07527\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07514\tTrain Loss 0.6960\t\n",
      "Epoch: [1][550/646]\tPer Sample Total Time 0.07520\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07508\tTrain Loss 0.6599\t\n",
      "Epoch: [1][600/646]\tPer Sample Total Time 0.07516\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.07505\tTrain Loss 0.6292\t\n",
      "start validation\n",
      "acc: 0.803030\n",
      "AUC: 0.984039\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.034028\n",
      "train_loss: 0.603312\n",
      "valid_loss: 1.821289\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 612.938\n",
      "---------------\n",
      "2025-12-12 13:44:29.800598\n",
      "current #epochs=2, #steps=646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][4/646]\tPer Sample Total Time 0.08559\tPer Sample Data Time 0.01106\tPer Sample DNN Time 0.07453\tTrain Loss 0.1916\t\n",
      "Epoch: [2][54/646]\tPer Sample Total Time 0.07546\tPer Sample Data Time 0.00104\tPer Sample DNN Time 0.07442\tTrain Loss 0.1824\t\n",
      "Epoch: [2][104/646]\tPer Sample Total Time 0.07479\tPer Sample Data Time 0.00056\tPer Sample DNN Time 0.07423\tTrain Loss 0.1903\t\n",
      "Epoch: [2][154/646]\tPer Sample Total Time 0.07476\tPer Sample Data Time 0.00039\tPer Sample DNN Time 0.07436\tTrain Loss 0.1884\t\n",
      "Epoch: [2][204/646]\tPer Sample Total Time 0.07464\tPer Sample Data Time 0.00031\tPer Sample DNN Time 0.07433\tTrain Loss 0.1875\t\n",
      "Epoch: [2][254/646]\tPer Sample Total Time 0.07459\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.07433\tTrain Loss 0.1908\t\n",
      "Epoch: [2][304/646]\tPer Sample Total Time 0.07457\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.07435\tTrain Loss 0.1850\t\n",
      "Epoch: [2][354/646]\tPer Sample Total Time 0.07455\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07435\tTrain Loss 0.1800\t\n",
      "Epoch: [2][404/646]\tPer Sample Total Time 0.07451\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07434\tTrain Loss 0.1772\t\n",
      "Epoch: [2][454/646]\tPer Sample Total Time 0.07448\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07432\tTrain Loss 0.1822\t\n",
      "Epoch: [2][504/646]\tPer Sample Total Time 0.07447\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07432\tTrain Loss 0.1864\t\n",
      "Epoch: [2][554/646]\tPer Sample Total Time 0.07444\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07431\tTrain Loss 0.1853\t\n",
      "Epoch: [2][604/646]\tPer Sample Total Time 0.07444\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07431\tTrain Loss 0.1817\t\n",
      "start validation\n",
      "acc: 0.828283\n",
      "AUC: 0.979278\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.883675\n",
      "train_loss: 0.177487\n",
      "valid_loss: 1.807617\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 608.295\n",
      "---------------\n",
      "2025-12-12 13:54:38.095068\n",
      "current #epochs=3, #steps=1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][8/646]\tPer Sample Total Time 0.08134\tPer Sample Data Time 0.00729\tPer Sample DNN Time 0.07405\tTrain Loss 0.1347\t\n",
      "Epoch: [3][58/646]\tPer Sample Total Time 0.07526\tPer Sample Data Time 0.00114\tPer Sample DNN Time 0.07412\tTrain Loss 0.1061\t\n",
      "Epoch: [3][108/646]\tPer Sample Total Time 0.07469\tPer Sample Data Time 0.00064\tPer Sample DNN Time 0.07405\tTrain Loss 0.1006\t\n",
      "Epoch: [3][158/646]\tPer Sample Total Time 0.07451\tPer Sample Data Time 0.00045\tPer Sample DNN Time 0.07406\tTrain Loss 0.1008\t\n",
      "Epoch: [3][208/646]\tPer Sample Total Time 0.07438\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.07403\tTrain Loss 0.1027\t\n",
      "Epoch: [3][258/646]\tPer Sample Total Time 0.07436\tPer Sample Data Time 0.00029\tPer Sample DNN Time 0.07407\tTrain Loss 0.0960\t\n",
      "Epoch: [3][308/646]\tPer Sample Total Time 0.07432\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.07408\tTrain Loss 0.0965\t\n",
      "Epoch: [3][358/646]\tPer Sample Total Time 0.07428\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.07407\tTrain Loss 0.0920\t\n",
      "Epoch: [3][408/646]\tPer Sample Total Time 0.07428\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.07408\tTrain Loss 0.0898\t\n",
      "Epoch: [3][458/646]\tPer Sample Total Time 0.07427\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.07409\tTrain Loss 0.0905\t\n",
      "Epoch: [3][508/646]\tPer Sample Total Time 0.07425\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07409\tTrain Loss 0.0894\t\n",
      "Epoch: [3][558/646]\tPer Sample Total Time 0.07424\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07408\tTrain Loss 0.0873\t\n",
      "Epoch: [3][608/646]\tPer Sample Total Time 0.07420\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07406\tTrain Loss 0.0856\t\n",
      "start validation\n",
      "acc: 0.844444\n",
      "AUC: 0.984997\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.068851\n",
      "train_loss: 0.084895\n",
      "valid_loss: 1.794922\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 606.595\n",
      "Running fold 5: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_5.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_5.json --exp-dir /kaggle/working/ast/urban8k_exp/fold5 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain False --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 17175, running on b3680011ca52: starting (Fri Dec 12 14:04:49 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: False\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold5\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7acc3b562f90>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 14:04:51.455215\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/650]\tPer Sample Total Time 0.08000\tPer Sample Data Time 0.00087\tPer Sample DNN Time 0.07913\tTrain Loss 1.9684\t\n",
      "Epoch: [1][100/650]\tPer Sample Total Time 0.07703\tPer Sample Data Time 0.00046\tPer Sample DNN Time 0.07657\tTrain Loss 1.6101\t\n",
      "Epoch: [1][150/650]\tPer Sample Total Time 0.07653\tPer Sample Data Time 0.00032\tPer Sample DNN Time 0.07622\tTrain Loss 1.3421\t\n",
      "Epoch: [1][200/650]\tPer Sample Total Time 0.07604\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.07579\tTrain Loss 1.2039\t\n",
      "Epoch: [1][250/650]\tPer Sample Total Time 0.07587\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.07566\tTrain Loss 1.0760\t\n",
      "Epoch: [1][300/650]\tPer Sample Total Time 0.07567\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.07549\tTrain Loss 0.9864\t\n",
      "Epoch: [1][350/650]\tPer Sample Total Time 0.07555\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07540\tTrain Loss 0.9217\t\n",
      "Epoch: [1][400/650]\tPer Sample Total Time 0.07544\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07530\tTrain Loss 0.8684\t\n",
      "Epoch: [1][450/650]\tPer Sample Total Time 0.07536\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07523\tTrain Loss 0.8081\t\n",
      "Epoch: [1][500/650]\tPer Sample Total Time 0.07527\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07515\tTrain Loss 0.7667\t\n",
      "Epoch: [1][550/650]\tPer Sample Total Time 0.07520\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.07509\tTrain Loss 0.7341\t\n",
      "Epoch: [1][600/650]\tPer Sample Total Time 0.07515\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.07504\tTrain Loss 0.7022\t\n",
      "start validation\n",
      "acc: 0.850427\n",
      "AUC: 0.988186\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.200535\n",
      "train_loss: 0.670538\n",
      "valid_loss: 1.803711\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 614.822\n",
      "---------------\n",
      "2025-12-12 14:15:06.277141\n",
      "current #epochs=2, #steps=650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/650]\tPer Sample Total Time 0.13208\tPer Sample Data Time 0.05388\tPer Sample DNN Time 0.07820\tTrain Loss 0.1619\t\n",
      "Epoch: [2][50/650]\tPer Sample Total Time 0.07542\tPer Sample Data Time 0.00109\tPer Sample DNN Time 0.07432\tTrain Loss 0.2406\t\n",
      "Epoch: [2][100/650]\tPer Sample Total Time 0.07497\tPer Sample Data Time 0.00057\tPer Sample DNN Time 0.07440\tTrain Loss 0.2342\t\n",
      "Epoch: [2][150/650]\tPer Sample Total Time 0.07476\tPer Sample Data Time 0.00039\tPer Sample DNN Time 0.07437\tTrain Loss 0.2343\t\n",
      "Epoch: [2][200/650]\tPer Sample Total Time 0.07466\tPer Sample Data Time 0.00030\tPer Sample DNN Time 0.07435\tTrain Loss 0.2391\t\n",
      "Epoch: [2][250/650]\tPer Sample Total Time 0.07460\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.07435\tTrain Loss 0.2378\t\n",
      "Epoch: [2][300/650]\tPer Sample Total Time 0.07456\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.07435\tTrain Loss 0.2368\t\n",
      "Epoch: [2][350/650]\tPer Sample Total Time 0.07452\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07433\tTrain Loss 0.2306\t\n",
      "Epoch: [2][400/650]\tPer Sample Total Time 0.07448\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07431\tTrain Loss 0.2261\t\n",
      "Epoch: [2][450/650]\tPer Sample Total Time 0.07446\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07430\tTrain Loss 0.2210\t\n",
      "Epoch: [2][500/650]\tPer Sample Total Time 0.07447\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07432\tTrain Loss 0.2184\t\n",
      "Epoch: [2][550/650]\tPer Sample Total Time 0.07444\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07431\tTrain Loss 0.2119\t\n",
      "Epoch: [2][600/650]\tPer Sample Total Time 0.07442\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07430\tTrain Loss 0.2063\t\n",
      "start validation\n",
      "acc: 0.902778\n",
      "AUC: 0.988404\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.210642\n",
      "train_loss: 0.202493\n",
      "valid_loss: 1.794922\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 610.443\n",
      "---------------\n",
      "2025-12-12 14:25:16.720370\n",
      "current #epochs=3, #steps=1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/650]\tPer Sample Total Time 0.13107\tPer Sample Data Time 0.05024\tPer Sample DNN Time 0.08083\tTrain Loss 0.1716\t\n",
      "Epoch: [3][50/650]\tPer Sample Total Time 0.07549\tPer Sample Data Time 0.00102\tPer Sample DNN Time 0.07447\tTrain Loss 0.1416\t\n",
      "Epoch: [3][100/650]\tPer Sample Total Time 0.07455\tPer Sample Data Time 0.00054\tPer Sample DNN Time 0.07402\tTrain Loss 0.1398\t\n",
      "Epoch: [3][150/650]\tPer Sample Total Time 0.07446\tPer Sample Data Time 0.00037\tPer Sample DNN Time 0.07409\tTrain Loss 0.1342\t\n",
      "Epoch: [3][200/650]\tPer Sample Total Time 0.07438\tPer Sample Data Time 0.00029\tPer Sample DNN Time 0.07409\tTrain Loss 0.1275\t\n",
      "Epoch: [3][250/650]\tPer Sample Total Time 0.07440\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.07417\tTrain Loss 0.1212\t\n",
      "Epoch: [3][300/650]\tPer Sample Total Time 0.07439\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.07418\tTrain Loss 0.1221\t\n",
      "Epoch: [3][350/650]\tPer Sample Total Time 0.07436\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.07418\tTrain Loss 0.1189\t\n",
      "Epoch: [3][400/650]\tPer Sample Total Time 0.07433\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07417\tTrain Loss 0.1129\t\n",
      "Epoch: [3][450/650]\tPer Sample Total Time 0.07433\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07418\tTrain Loss 0.1105\t\n",
      "Epoch: [3][500/650]\tPer Sample Total Time 0.07430\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07417\tTrain Loss 0.1142\t\n",
      "Epoch: [3][550/650]\tPer Sample Total Time 0.07428\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07415\tTrain Loss 0.1136\t\n",
      "Epoch: [3][600/650]\tPer Sample Total Time 0.07428\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07416\tTrain Loss 0.1126\t\n",
      "start validation\n",
      "acc: 0.910256\n",
      "AUC: 0.990865\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.337686\n",
      "train_loss: 0.108580\n",
      "valid_loss: 1.780273\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 609.502\n",
      "Fold 1: best val acc 0.7915\n",
      "Fold 2: best val acc 0.8097\n",
      "Fold 3: best val acc 0.7514\n",
      "Fold 4: best val acc 0.8444\n",
      "Fold 5: best val acc 0.9103\n",
      "10-fold mean acc: 0.8215 +/- 0.0536\n"
     ]
    }
   ],
   "source": [
    "# Kick off full 10-fold: each fold is held out as test once\n",
    "folds_to_run = list(range(1, 6))\n",
    "for f in folds_to_run:\n",
    "    run_fold(f)\n",
    "\n",
    "# Aggregate best validation accuracy per fold (col 0 of result.csv)\n",
    "fold_acc = []\n",
    "for f in folds_to_run:\n",
    "    res_path = REPO_DIR / 'urban8k_exp' / f'fold{f}' / 'result.csv'\n",
    "    arr = np.loadtxt(res_path, delimiter=',')\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr[None, :]\n",
    "    best_acc = float(arr[:, 0].max())\n",
    "    fold_acc.append(best_acc)\n",
    "    print(f'Fold {f}: best val acc {best_acc:.4f}')\n",
    "\n",
    "mean_acc = float(np.mean(fold_acc))\n",
    "std_acc = float(np.std(fold_acc))\n",
    "print(f'10-fold mean acc: {mean_acc:.4f} +/- {std_acc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 500970,
     "sourceId": 928025,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9306.784828,
   "end_time": "2025-12-12T14:35:28.819230",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-12T12:00:22.034402",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
