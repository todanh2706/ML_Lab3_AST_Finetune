{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a2304",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-12T13:09:10.609636Z",
     "iopub.status.busy": "2025-12-12T13:09:10.609329Z",
     "iopub.status.idle": "2025-12-12T13:10:29.629379Z",
     "shell.execute_reply": "2025-12-12T13:10:29.628432Z"
    },
    "papermill": {
     "duration": 79.026018,
     "end_time": "2025-12-12T13:10:29.630675",
     "exception": false,
     "start_time": "2025-12-12T13:09:10.604657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing /kaggle/input ...\n",
      "Device: cuda\n",
      "[*INFO] Installing libraries...\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 287.4/287.4 kB 11.4 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 277.6 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 276.6 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 270.2 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 392.5 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 300.8 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 308.0 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 299.0 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 299.9 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 242.7 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 301.7 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*INFO] Cleaning up memory after installation...\n",
      "[*INFO] Cloning AST repo ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/ast'...\n",
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# secret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "# from huggingface_hub import HfApi, login\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import sys\n",
    "import subprocess\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "# AST Fine-tuning on UrbanSound8K (Kaggle version)\n",
    "# - Auto-detect UrbanSound8K in /kaggle/input\n",
    "# - Clone AST repo into /kaggle/working/ast\n",
    "# - Download AudioSet checkpoint\n",
    "# - 10-fold cross-validation training\n",
    "\n",
    "\n",
    "\n",
    "# 0. ENV INFO & SEED\n",
    "print(\"Listing /kaggle/input ...\")\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "\n",
    "# 1. INSTALL REQUIRED LIBRARIES (if needed)\n",
    "import gc # <--- Import thư viện dọn rác\n",
    "\n",
    "def pip_install(package):\n",
    "    # Thêm \"--no-cache-dir\" để không ngốn RAM lưu file tạm\n",
    "    # Thêm \"-q\" (quiet) để giảm log in ra màn hình\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"-q\", package])\n",
    "\n",
    "print(\"[*INFO] Installing libraries...\")\n",
    "# timm==0.4.5 là bản được AST repo dùng\n",
    "pip_install(\"timm==0.4.5\")\n",
    "pip_install(\"wget\")\n",
    "pip_install(\"librosa\")\n",
    "\n",
    "print(\"[*INFO] Cleaning up memory after installation...\")\n",
    "gc.collect() \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "# ======================================================\n",
    "\n",
    "import timm\n",
    "import wget\n",
    "\n",
    "# 2. CLONE AST REPO VÀ IMPORT ASTModel\n",
    "REPO_DIR = \"/kaggle/working/ast\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print(\"[*INFO] Cloning AST repo ...\")\n",
    "    subprocess.check_call([\"git\", \"clone\", \"https://github.com/YuanGongND/ast\", REPO_DIR])\n",
    "else:\n",
    "    print(\"[*INFO] AST repo already exists at\", REPO_DIR)\n",
    "\n",
    "sys.path.append(REPO_DIR)\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "from src.models import ASTModel  # sau khi đã sys.path.append\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb0b6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:10:29.639195Z",
     "iopub.status.busy": "2025-12-12T13:10:29.638537Z",
     "iopub.status.idle": "2025-12-12T13:10:33.575578Z",
     "shell.execute_reply": "2025-12-12T13:10:33.574784Z"
    },
    "papermill": {
     "duration": 3.942379,
     "end_time": "2025-12-12T13:10:33.576738",
     "exception": false,
     "start_time": "2025-12-12T13:10:29.634359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*INFO] Found UrbanSound8K.csv at: /kaggle/input/urbansound8k/UrbanSound8K.csv\n",
      "[*INFO] Sample row -> fold=5, fname=100032-3-0-0.wav\n",
      "[*INFO] AUDIO_ROOT detected as: /kaggle/input/urbansound8k\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. TÌM METADATA CSV UrbanSound8K\n",
    "US8K_META_PATH = None\n",
    "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "    if \"UrbanSound8K.csv\" in files:\n",
    "        US8K_META_PATH = os.path.join(root, \"UrbanSound8K.csv\")\n",
    "        break\n",
    "\n",
    "if US8K_META_PATH is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Không tìm thấy UrbanSound8K.csv trong /kaggle/input. \"\n",
    "        \"Kiểm tra lại dataset UrbanSound8K đã add vào notebook.\"\n",
    "    )\n",
    "\n",
    "print(\"[*INFO] Found UrbanSound8K.csv at:\", US8K_META_PATH)\n",
    "METADATA_CSV = US8K_META_PATH\n",
    "\n",
    "# 4. TÌM CHÍNH XÁC AUDIO_ROOT BẰNG CÁCH DÒ FILE THẬT\n",
    "df_meta = pd.read_csv(METADATA_CSV)\n",
    "sample_row = df_meta.iloc[0]\n",
    "sample_fname = sample_row[\"slice_file_name\"]\n",
    "sample_fold = sample_row[\"fold\"]\n",
    "target_fold_dir = f\"fold{sample_fold}\"\n",
    "\n",
    "print(f\"[*INFO] Sample row -> fold={sample_fold}, fname={sample_fname}\")\n",
    "\n",
    "AUDIO_ROOT = None\n",
    "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "    if os.path.basename(root) == target_fold_dir and sample_fname in files:\n",
    "        # root = .../audio/foldX\n",
    "        AUDIO_ROOT = os.path.dirname(root)  # bỏ /foldX\n",
    "        break\n",
    "\n",
    "if AUDIO_ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Không tìm thấy thư mục audio chứa fold{sample_fold} và file {sample_fname} trong /kaggle/input.\"\n",
    "    )\n",
    "\n",
    "print(\"[*INFO] AUDIO_ROOT detected as:\", AUDIO_ROOT)\n",
    "\n",
    "# Thư mục lưu checkpoint\n",
    "CKPT_DIR = \"/kaggle/working/ast_us8k_checkpoints\"\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e193c952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:10:33.585241Z",
     "iopub.status.busy": "2025-12-12T13:10:33.584638Z",
     "iopub.status.idle": "2025-12-12T13:10:33.588290Z",
     "shell.execute_reply": "2025-12-12T13:10:33.587649Z"
    },
    "papermill": {
     "duration": 0.008899,
     "end_time": "2025-12-12T13:10:33.589241",
     "exception": false,
     "start_time": "2025-12-12T13:10:33.580342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/urbansound8k\n"
     ]
    }
   ],
   "source": [
    "print(AUDIO_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e34954",
   "metadata": {
    "papermill": {
     "duration": 0.003253,
     "end_time": "2025-12-12T13:10:33.595910",
     "exception": false,
     "start_time": "2025-12-12T13:10:33.592657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da90b3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:10:33.603567Z",
     "iopub.status.busy": "2025-12-12T13:10:33.603346Z",
     "iopub.status.idle": "2025-12-12T13:10:33.608158Z",
     "shell.execute_reply": "2025-12-12T13:10:33.607527Z"
    },
    "papermill": {
     "duration": 0.009855,
     "end_time": "2025-12-12T13:10:33.609204",
     "exception": false,
     "start_time": "2025-12-12T13:10:33.599349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /kaggle/working/ast\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "try:\n",
    "    REPO_DIR\n",
    "except NameError:\n",
    "    REPO_DIR = Path('.').resolve()\n",
    "else:\n",
    "    REPO_DIR = Path(REPO_DIR)\n",
    "TORCH_HOME = REPO_DIR / 'pretrained_models'\n",
    "os.environ['TORCH_HOME'] = str(TORCH_HOME)\n",
    "TORCH_HOME.mkdir(exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Repo root:', REPO_DIR)\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a774d17e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:10:33.616917Z",
     "iopub.status.busy": "2025-12-12T13:10:33.616708Z",
     "iopub.status.idle": "2025-12-12T13:10:33.649021Z",
     "shell.execute_reply": "2025-12-12T13:10:33.648406Z"
    },
    "papermill": {
     "duration": 0.037368,
     "end_time": "2025-12-12T13:10:33.650041",
     "exception": false,
     "start_time": "2025-12-12T13:10:33.612673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label CSV written to: /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv\n"
     ]
    }
   ],
   "source": [
    "# Build label CSV (index, mid, display_name)\n",
    "meta_df = pd.read_csv(METADATA_CSV)\n",
    "label_csv = REPO_DIR / 'urban8k_data' / 'urban8k_class_labels_indices.csv'\n",
    "label_csv.parent.mkdir(exist_ok=True)\n",
    "\n",
    "unique_classes = meta_df[['classID', 'class']].drop_duplicates().sort_values('classID')\n",
    "with open(label_csv, 'w') as f:\n",
    "    f.write('index,mid,display_name\\n')\n",
    "    for _, row in unique_classes.iterrows():\n",
    "        idx = int(row['classID'])\n",
    "        mid = f\"/m/urban{idx:02d}\"\n",
    "        name = row['class']\n",
    "        f.write(f\"{idx},{mid},{name}\\n\")\n",
    "\n",
    "print('Label CSV written to:', label_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e05c153e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:10:33.658075Z",
     "iopub.status.busy": "2025-12-12T13:10:33.657488Z",
     "iopub.status.idle": "2025-12-12T13:10:39.059405Z",
     "shell.execute_reply": "2025-12-12T13:10:39.058567Z"
    },
    "papermill": {
     "duration": 5.407139,
     "end_time": "2025-12-12T13:10:39.060580",
     "exception": false,
     "start_time": "2025-12-12T13:10:33.653441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: train 7859, eval 873\n",
      "Fold 2: train 7844, eval 888\n",
      "Fold 3: train 7807, eval 925\n",
      "Fold 4: train 7742, eval 990\n",
      "Fold 5: train 7796, eval 936\n",
      "Fold 6: train 7909, eval 823\n",
      "Fold 7: train 7894, eval 838\n",
      "Fold 8: train 7926, eval 806\n",
      "Fold 9: train 7916, eval 816\n",
      "Fold 10: train 7895, eval 837\n"
     ]
    }
   ],
   "source": [
    "import json, shutil\n",
    "\n",
    "# Create JSON datafiles per fold (ESC-50 style)\n",
    "data_dir = REPO_DIR / 'urban8k_data' / 'datafiles'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def rows_for_df(df):\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        wav_path = Path(AUDIO_ROOT) / f\"fold{int(r['fold'])}\" / r['slice_file_name']\n",
    "        rows.append({\n",
    "            'wav': str(wav_path),\n",
    "            'labels': f\"/m/urban{int(r['classID']):02d}\"\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "for fold in range(1, 11):\n",
    "    train_df = meta_df[meta_df['fold'] != fold]\n",
    "    eval_df = meta_df[meta_df['fold'] == fold]\n",
    "    train_json = {'data': rows_for_df(train_df)}\n",
    "    eval_json = {'data': rows_for_df(eval_df)}\n",
    "    with open(data_dir / f'urban_train_data_{fold}.json', 'w') as f:\n",
    "        json.dump(train_json, f, indent=1)\n",
    "    with open(data_dir / f'urban_eval_data_{fold}.json', 'w') as f:\n",
    "        json.dump(eval_json, f, indent=1)\n",
    "    print(f'Fold {fold}: train {len(train_df)}, eval {len(eval_df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91353b91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:10:39.069514Z",
     "iopub.status.busy": "2025-12-12T13:10:39.069308Z",
     "iopub.status.idle": "2025-12-12T13:10:39.076718Z",
     "shell.execute_reply": "2025-12-12T13:10:39.075932Z"
    },
    "papermill": {
     "duration": 0.01314,
     "end_time": "2025-12-12T13:10:39.077847",
     "exception": false,
     "start_time": "2025-12-12T13:10:39.064707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mean/std: -1.7362523965764032 3.2758855893221015\n"
     ]
    }
   ],
   "source": [
    "# Compute dataset mean/std over fbank features (optional; default uses AudioSet stats)\n",
    "import torchaudio\n",
    "\n",
    "def compute_norm_stats(df, target_length=1024, mel_bins=128, target_sr=16000, max_files=None):\n",
    "    total = 0.0\n",
    "    total_sq = 0.0\n",
    "    count = 0\n",
    "    rows = df if max_files is None else df.sample(n=max_files, random_state=SEED)\n",
    "    for _, r in rows.iterrows():\n",
    "        wav_path = Path(AUDIO_ROOT) / f\"fold{int(r['fold'])}\" / r['slice_file_name']\n",
    "        wav, sr = torchaudio.load(str(wav_path))\n",
    "        if wav.shape[0] > 1:\n",
    "            wav = wav.mean(dim=0, keepdim=True)\n",
    "        if sr != target_sr:\n",
    "            wav = torchaudio.transforms.Resample(sr, target_sr)(wav)\n",
    "            sr = target_sr\n",
    "        fb = torchaudio.compliance.kaldi.fbank(\n",
    "            wav, htk_compat=True, sample_frequency=sr, use_energy=False,\n",
    "            window_type='hanning', num_mel_bins=mel_bins, dither=0.0, frame_shift=10\n",
    "        )\n",
    "        p = target_length - fb.shape[0]\n",
    "        if p > 0:\n",
    "            fb = torch.nn.functional.pad(fb, (0, 0, 0, p))\n",
    "        elif p < 0:\n",
    "            fb = fb[:target_length, :]\n",
    "        total += fb.sum().item()\n",
    "        total_sq += (fb ** 2).sum().item()\n",
    "        count += fb.numel()\n",
    "    mean = total / count\n",
    "    var = total_sq / count - mean ** 2\n",
    "    std = var ** 0.5\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "try:\n",
    "    DATASET_MEAN\n",
    "    DATASET_STD\n",
    "except NameError:\n",
    "    DATASET_MEAN = -1.7362523965764032\n",
    "    DATASET_STD = 3.2758855893221015\n",
    "print('Using mean/std:', DATASET_MEAN, DATASET_STD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25bf4ef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:10:39.086919Z",
     "iopub.status.busy": "2025-12-12T13:10:39.086696Z",
     "iopub.status.idle": "2025-12-12T13:10:39.094260Z",
     "shell.execute_reply": "2025-12-12T13:10:39.093558Z"
    },
    "papermill": {
     "duration": 0.013471,
     "end_time": "2025-12-12T13:10:39.095283",
     "exception": false,
     "start_time": "2025-12-12T13:10:39.081812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH_HOME: /kaggle/pretrained_models\n",
      "Helper ready: run_fold(fold) to launch training\n"
     ]
    }
   ],
   "source": [
    "REPO_DIR = Path('.').resolve()\n",
    "PRETRAIN_DIR = (REPO_DIR / '../../pretrained_models').resolve()\n",
    "PRETRAIN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "os.environ['TORCH_HOME'] = str(PRETRAIN_DIR)\n",
    "print('TORCH_HOME:', PRETRAIN_DIR)\n",
    "# Helper to launch training via src/run.py with ESC-50-like hyperparameters\n",
    "def run_fold(fold, epochs=3, batch_size=12, lr=1e-5):\n",
    "    exp_dir = REPO_DIR / 'urban8k_exp' / f'fold{fold}'\n",
    "    if exp_dir.exists():\n",
    "        shutil.rmtree(exp_dir)\n",
    "    exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    train_json = data_dir / f'urban_train_data_{fold}.json'\n",
    "    eval_json = data_dir / f'urban_eval_data_{fold}.json'\n",
    "\n",
    "    cmd = [\n",
    "        sys.executable, 'src/run.py',\n",
    "        '--model', 'ast',\n",
    "        '--dataset', 'urban8k',\n",
    "        '--data-train', str(train_json),\n",
    "        '--data-val', str(eval_json),\n",
    "        '--exp-dir', str(exp_dir),\n",
    "        '--label-csv', str(label_csv),\n",
    "        '--n_class', '10',\n",
    "        '--lr', str(lr),\n",
    "        '--n-epochs', str(epochs),\n",
    "        '--batch-size', str(batch_size),\n",
    "        '--save_model', 'False',\n",
    "        '--freqm', '24',\n",
    "        '--timem', '96',\n",
    "        '--mixup', '0',\n",
    "        '--bal', 'none',\n",
    "        '--tstride', '10', '--fstride', '10',\n",
    "        '--imagenet_pretrain', 'True',\n",
    "        '--audioset_pretrain', 'True',\n",
    "        '--metrics', 'acc',\n",
    "        '--loss', 'CE',\n",
    "        '--warmup', 'False',\n",
    "        '--lrscheduler_start', '5',\n",
    "        '--lrscheduler_step', '1',\n",
    "        '--lrscheduler_decay', '0.85',\n",
    "        '--dataset_mean', str(DATASET_MEAN),\n",
    "        '--dataset_std', str(DATASET_STD),\n",
    "        '--audio_length', '1024',\n",
    "        '--noise', 'False',\n",
    "        '--num-workers', '4',\n",
    "        '--n-print-steps', '50'\n",
    "    ]\n",
    "    env = os.environ.copy()\n",
    "    env['TORCH_HOME'] = str(TORCH_HOME)\n",
    "    print(f'Running fold {fold}:', ' '.join(cmd))\n",
    "    subprocess.check_call(cmd, env=env, cwd=REPO_DIR)\n",
    "\n",
    "print('Helper ready: run_fold(fold) to launch training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3789a34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:10:39.104030Z",
     "iopub.status.busy": "2025-12-12T13:10:39.103538Z",
     "iopub.status.idle": "2025-12-12T15:38:34.033835Z",
     "shell.execute_reply": "2025-12-12T15:38:34.032936Z"
    },
    "papermill": {
     "duration": 8874.936004,
     "end_time": "2025-12-12T15:38:34.035160",
     "exception": false,
     "start_time": "2025-12-12T13:10:39.099156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 6: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_6.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_6.json --exp-dir /kaggle/working/ast/urban8k_exp/fold6 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain True --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 88, running on f48cdd07b02b: starting (Fri Dec 12 13:10:43 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold6\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7acf2e5ae150>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 13:10:50.417448\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/660]\tPer Sample Total Time 0.06789\tPer Sample Data Time 0.00156\tPer Sample DNN Time 0.06633\tTrain Loss 1.4389\t\n",
      "Epoch: [1][100/660]\tPer Sample Total Time 0.06652\tPer Sample Data Time 0.00080\tPer Sample DNN Time 0.06572\tTrain Loss 1.0084\t\n",
      "Epoch: [1][150/660]\tPer Sample Total Time 0.06725\tPer Sample Data Time 0.00055\tPer Sample DNN Time 0.06670\tTrain Loss 0.8044\t\n",
      "Epoch: [1][200/660]\tPer Sample Total Time 0.06868\tPer Sample Data Time 0.00042\tPer Sample DNN Time 0.06826\tTrain Loss 0.6665\t\n",
      "Epoch: [1][250/660]\tPer Sample Total Time 0.06913\tPer Sample Data Time 0.00034\tPer Sample DNN Time 0.06878\tTrain Loss 0.5911\t\n",
      "Epoch: [1][300/660]\tPer Sample Total Time 0.06960\tPer Sample Data Time 0.00029\tPer Sample DNN Time 0.06931\tTrain Loss 0.5315\t\n",
      "Epoch: [1][350/660]\tPer Sample Total Time 0.06982\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.06957\tTrain Loss 0.4796\t\n",
      "Epoch: [1][400/660]\tPer Sample Total Time 0.07006\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.06983\tTrain Loss 0.4478\t\n",
      "Epoch: [1][450/660]\tPer Sample Total Time 0.07023\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.07003\tTrain Loss 0.4158\t\n",
      "Epoch: [1][500/660]\tPer Sample Total Time 0.07032\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07013\tTrain Loss 0.3906\t\n",
      "Epoch: [1][550/660]\tPer Sample Total Time 0.07038\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07021\tTrain Loss 0.3665\t\n",
      "Epoch: [1][600/660]\tPer Sample Total Time 0.07048\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07032\tTrain Loss 0.3456\t\n",
      "Epoch: [1][650/660]\tPer Sample Total Time 0.07056\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07041\tTrain Loss 0.3310\t\n",
      "start validation\n",
      "acc: 0.810450\n",
      "AUC: 0.978565\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.863744\n",
      "train_loss: 0.328706\n",
      "valid_loss: 1.801758\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 584.020\n",
      "---------------\n",
      "2025-12-12 13:20:34.437318\n",
      "current #epochs=2, #steps=660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][40/660]\tPer Sample Total Time 0.07283\tPer Sample Data Time 0.00138\tPer Sample DNN Time 0.07145\tTrain Loss 0.0678\t\n",
      "Epoch: [2][90/660]\tPer Sample Total Time 0.07175\tPer Sample Data Time 0.00064\tPer Sample DNN Time 0.07112\tTrain Loss 0.0656\t\n",
      "Epoch: [2][140/660]\tPer Sample Total Time 0.07165\tPer Sample Data Time 0.00042\tPer Sample DNN Time 0.07122\tTrain Loss 0.0707\t\n",
      "Epoch: [2][190/660]\tPer Sample Total Time 0.07156\tPer Sample Data Time 0.00032\tPer Sample DNN Time 0.07124\tTrain Loss 0.0821\t\n",
      "Epoch: [2][240/660]\tPer Sample Total Time 0.07143\tPer Sample Data Time 0.00026\tPer Sample DNN Time 0.07117\tTrain Loss 0.0802\t\n",
      "Epoch: [2][290/660]\tPer Sample Total Time 0.07138\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.07116\tTrain Loss 0.0778\t\n",
      "Epoch: [2][340/660]\tPer Sample Total Time 0.07134\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07115\tTrain Loss 0.0753\t\n",
      "Epoch: [2][390/660]\tPer Sample Total Time 0.07131\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07114\tTrain Loss 0.0726\t\n",
      "Epoch: [2][440/660]\tPer Sample Total Time 0.07129\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07113\tTrain Loss 0.0738\t\n",
      "Epoch: [2][490/660]\tPer Sample Total Time 0.07127\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07113\tTrain Loss 0.0749\t\n",
      "Epoch: [2][540/660]\tPer Sample Total Time 0.07126\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07113\tTrain Loss 0.0750\t\n",
      "Epoch: [2][590/660]\tPer Sample Total Time 0.07122\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07110\tTrain Loss 0.0759\t\n",
      "Epoch: [2][640/660]\tPer Sample Total Time 0.07121\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07109\tTrain Loss 0.0762\t\n",
      "start validation\n",
      "acc: 0.838396\n",
      "AUC: 0.986871\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.142907\n",
      "train_loss: 0.075822\n",
      "valid_loss: 1.791016\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 589.565\n",
      "---------------\n",
      "2025-12-12 13:30:24.002333\n",
      "current #epochs=3, #steps=1320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][30/660]\tPer Sample Total Time 0.07343\tPer Sample Data Time 0.00175\tPer Sample DNN Time 0.07168\tTrain Loss 0.0442\t\n",
      "Epoch: [3][80/660]\tPer Sample Total Time 0.07184\tPer Sample Data Time 0.00069\tPer Sample DNN Time 0.07115\tTrain Loss 0.0409\t\n",
      "Epoch: [3][130/660]\tPer Sample Total Time 0.07136\tPer Sample Data Time 0.00044\tPer Sample DNN Time 0.07092\tTrain Loss 0.0442\t\n",
      "Epoch: [3][180/660]\tPer Sample Total Time 0.07121\tPer Sample Data Time 0.00033\tPer Sample DNN Time 0.07088\tTrain Loss 0.0455\t\n",
      "Epoch: [3][230/660]\tPer Sample Total Time 0.07119\tPer Sample Data Time 0.00026\tPer Sample DNN Time 0.07093\tTrain Loss 0.0446\t\n",
      "Epoch: [3][280/660]\tPer Sample Total Time 0.07113\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.07090\tTrain Loss 0.0464\t\n",
      "Epoch: [3][330/660]\tPer Sample Total Time 0.07109\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07090\tTrain Loss 0.0475\t\n",
      "Epoch: [3][380/660]\tPer Sample Total Time 0.07106\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07089\tTrain Loss 0.0461\t\n",
      "Epoch: [3][430/660]\tPer Sample Total Time 0.07103\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07088\tTrain Loss 0.0436\t\n",
      "Epoch: [3][480/660]\tPer Sample Total Time 0.07102\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07087\tTrain Loss 0.0424\t\n",
      "Epoch: [3][530/660]\tPer Sample Total Time 0.07100\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07086\tTrain Loss 0.0419\t\n",
      "Epoch: [3][580/660]\tPer Sample Total Time 0.07097\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07085\tTrain Loss 0.0429\t\n",
      "Epoch: [3][630/660]\tPer Sample Total Time 0.07095\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07084\tTrain Loss 0.0445\t\n",
      "start validation\n",
      "acc: 0.840826\n",
      "AUC: 0.984160\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.038325\n",
      "train_loss: 0.045364\n",
      "valid_loss: 1.791992\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 587.450\n",
      "Running fold 7: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_7.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_7.json --exp-dir /kaggle/working/ast/urban8k_exp/fold7 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain True --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 4387, running on f48cdd07b02b: starting (Fri Dec 12 13:40:16 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold7\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7ee3d0279d90>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 13:40:18.329980\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/658]\tPer Sample Total Time 0.07709\tPer Sample Data Time 0.00125\tPer Sample DNN Time 0.07584\tTrain Loss 1.2991\t\n",
      "Epoch: [1][100/658]\tPer Sample Total Time 0.07430\tPer Sample Data Time 0.00065\tPer Sample DNN Time 0.07365\tTrain Loss 0.9047\t\n",
      "Epoch: [1][150/658]\tPer Sample Total Time 0.07359\tPer Sample Data Time 0.00044\tPer Sample DNN Time 0.07315\tTrain Loss 0.7162\t\n",
      "Epoch: [1][200/658]\tPer Sample Total Time 0.07307\tPer Sample Data Time 0.00034\tPer Sample DNN Time 0.07273\tTrain Loss 0.6075\t\n",
      "Epoch: [1][250/658]\tPer Sample Total Time 0.07287\tPer Sample Data Time 0.00028\tPer Sample DNN Time 0.07259\tTrain Loss 0.5339\t\n",
      "Epoch: [1][300/658]\tPer Sample Total Time 0.07270\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.07246\tTrain Loss 0.4847\t\n",
      "Epoch: [1][350/658]\tPer Sample Total Time 0.07258\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.07237\tTrain Loss 0.4431\t\n",
      "Epoch: [1][400/658]\tPer Sample Total Time 0.07250\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07231\tTrain Loss 0.4078\t\n",
      "Epoch: [1][450/658]\tPer Sample Total Time 0.07241\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07224\tTrain Loss 0.3826\t\n",
      "Epoch: [1][500/658]\tPer Sample Total Time 0.07234\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07218\tTrain Loss 0.3611\t\n",
      "Epoch: [1][550/658]\tPer Sample Total Time 0.07230\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07215\tTrain Loss 0.3426\t\n",
      "Epoch: [1][600/658]\tPer Sample Total Time 0.07222\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07208\tTrain Loss 0.3233\t\n",
      "Epoch: [1][650/658]\tPer Sample Total Time 0.07218\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07205\tTrain Loss 0.3097\t\n",
      "start validation\n",
      "acc: 0.900955\n",
      "AUC: 0.988696\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.224384\n",
      "train_loss: 0.307673\n",
      "valid_loss: 1.796875\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 595.949\n",
      "---------------\n",
      "2025-12-12 13:50:14.278009\n",
      "current #epochs=2, #steps=658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][42/658]\tPer Sample Total Time 0.07215\tPer Sample Data Time 0.00124\tPer Sample DNN Time 0.07091\tTrain Loss 0.0738\t\n",
      "Epoch: [2][92/658]\tPer Sample Total Time 0.07207\tPer Sample Data Time 0.00059\tPer Sample DNN Time 0.07148\tTrain Loss 0.0687\t\n",
      "Epoch: [2][142/658]\tPer Sample Total Time 0.07164\tPer Sample Data Time 0.00040\tPer Sample DNN Time 0.07125\tTrain Loss 0.0800\t\n",
      "Epoch: [2][192/658]\tPer Sample Total Time 0.07152\tPer Sample Data Time 0.00030\tPer Sample DNN Time 0.07122\tTrain Loss 0.0773\t\n",
      "Epoch: [2][242/658]\tPer Sample Total Time 0.07139\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.07115\tTrain Loss 0.0713\t\n",
      "Epoch: [2][292/658]\tPer Sample Total Time 0.07131\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.07110\tTrain Loss 0.0725\t\n",
      "Epoch: [2][342/658]\tPer Sample Total Time 0.07129\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.07110\tTrain Loss 0.0710\t\n",
      "Epoch: [2][392/658]\tPer Sample Total Time 0.07125\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07109\tTrain Loss 0.0693\t\n",
      "Epoch: [2][442/658]\tPer Sample Total Time 0.07121\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07106\tTrain Loss 0.0681\t\n",
      "Epoch: [2][492/658]\tPer Sample Total Time 0.07120\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07106\tTrain Loss 0.0709\t\n",
      "Epoch: [2][542/658]\tPer Sample Total Time 0.07119\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07106\tTrain Loss 0.0733\t\n",
      "Epoch: [2][592/658]\tPer Sample Total Time 0.07117\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07105\tTrain Loss 0.0727\t\n",
      "Epoch: [2][642/658]\tPer Sample Total Time 0.07115\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.07104\tTrain Loss 0.0720\t\n",
      "start validation\n",
      "acc: 0.846062\n",
      "AUC: 0.985903\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.103582\n",
      "train_loss: 0.071761\n",
      "valid_loss: 1.793945\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 586.551\n",
      "---------------\n",
      "2025-12-12 14:00:00.829436\n",
      "current #epochs=3, #steps=1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][34/658]\tPer Sample Total Time 0.07296\tPer Sample Data Time 0.00168\tPer Sample DNN Time 0.07128\tTrain Loss 0.0411\t\n",
      "Epoch: [3][84/658]\tPer Sample Total Time 0.07150\tPer Sample Data Time 0.00071\tPer Sample DNN Time 0.07078\tTrain Loss 0.0363\t\n",
      "Epoch: [3][134/658]\tPer Sample Total Time 0.07103\tPer Sample Data Time 0.00046\tPer Sample DNN Time 0.07057\tTrain Loss 0.0302\t\n",
      "Epoch: [3][184/658]\tPer Sample Total Time 0.07092\tPer Sample Data Time 0.00034\tPer Sample DNN Time 0.07058\tTrain Loss 0.0310\t\n",
      "Epoch: [3][234/658]\tPer Sample Total Time 0.07092\tPer Sample Data Time 0.00028\tPer Sample DNN Time 0.07064\tTrain Loss 0.0370\t\n",
      "Epoch: [3][284/658]\tPer Sample Total Time 0.07090\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.07066\tTrain Loss 0.0373\t\n",
      "Epoch: [3][334/658]\tPer Sample Total Time 0.07093\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.07072\tTrain Loss 0.0470\t\n",
      "Epoch: [3][384/658]\tPer Sample Total Time 0.07091\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.07073\tTrain Loss 0.0446\t\n",
      "Epoch: [3][434/658]\tPer Sample Total Time 0.07090\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07073\tTrain Loss 0.0438\t\n",
      "Epoch: [3][484/658]\tPer Sample Total Time 0.07089\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07074\tTrain Loss 0.0412\t\n",
      "Epoch: [3][534/658]\tPer Sample Total Time 0.07090\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07076\tTrain Loss 0.0446\t\n",
      "Epoch: [3][584/658]\tPer Sample Total Time 0.07089\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07076\tTrain Loss 0.0448\t\n",
      "Epoch: [3][634/658]\tPer Sample Total Time 0.07089\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07077\tTrain Loss 0.0454\t\n",
      "start validation\n",
      "acc: 0.865155\n",
      "AUC: 0.987898\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.187460\n",
      "train_loss: 0.044858\n",
      "valid_loss: 1.780273\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 584.776\n",
      "Running fold 8: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_8.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_8.json --exp-dir /kaggle/working/ast/urban8k_exp/fold8 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain True --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 8675, running on f48cdd07b02b: starting (Fri Dec 12 14:09:50 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold8\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x79a6e086c1d0>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 14:09:52.501998\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/661]\tPer Sample Total Time 0.07654\tPer Sample Data Time 0.00111\tPer Sample DNN Time 0.07542\tTrain Loss 1.3134\t\n",
      "Epoch: [1][100/661]\tPer Sample Total Time 0.07405\tPer Sample Data Time 0.00058\tPer Sample DNN Time 0.07347\tTrain Loss 0.9137\t\n",
      "Epoch: [1][150/661]\tPer Sample Total Time 0.07340\tPer Sample Data Time 0.00040\tPer Sample DNN Time 0.07300\tTrain Loss 0.7190\t\n",
      "Epoch: [1][200/661]\tPer Sample Total Time 0.07293\tPer Sample Data Time 0.00031\tPer Sample DNN Time 0.07262\tTrain Loss 0.6068\t\n",
      "Epoch: [1][250/661]\tPer Sample Total Time 0.07277\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.07251\tTrain Loss 0.5381\t\n",
      "Epoch: [1][300/661]\tPer Sample Total Time 0.07262\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.07240\tTrain Loss 0.4783\t\n",
      "Epoch: [1][350/661]\tPer Sample Total Time 0.07252\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07233\tTrain Loss 0.4356\t\n",
      "Epoch: [1][400/661]\tPer Sample Total Time 0.07244\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07227\tTrain Loss 0.4079\t\n",
      "Epoch: [1][450/661]\tPer Sample Total Time 0.07238\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07223\tTrain Loss 0.3821\t\n",
      "Epoch: [1][500/661]\tPer Sample Total Time 0.07230\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07215\tTrain Loss 0.3602\t\n",
      "Epoch: [1][550/661]\tPer Sample Total Time 0.07221\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07208\tTrain Loss 0.3401\t\n",
      "Epoch: [1][600/661]\tPer Sample Total Time 0.07213\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07201\tTrain Loss 0.3250\t\n",
      "Epoch: [1][650/661]\tPer Sample Total Time 0.07208\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07196\tTrain Loss 0.3137\t\n",
      "start validation\n",
      "acc: 0.830025\n",
      "AUC: 0.963565\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.536600\n",
      "train_loss: 0.312660\n",
      "valid_loss: 1.833984\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 596.613\n",
      "---------------\n",
      "2025-12-12 14:19:49.115037\n",
      "current #epochs=2, #steps=661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][39/661]\tPer Sample Total Time 0.07276\tPer Sample Data Time 0.00142\tPer Sample DNN Time 0.07135\tTrain Loss 0.1116\t\n",
      "Epoch: [2][89/661]\tPer Sample Total Time 0.07174\tPer Sample Data Time 0.00065\tPer Sample DNN Time 0.07109\tTrain Loss 0.1009\t\n",
      "Epoch: [2][139/661]\tPer Sample Total Time 0.07145\tPer Sample Data Time 0.00043\tPer Sample DNN Time 0.07102\tTrain Loss 0.0941\t\n",
      "Epoch: [2][189/661]\tPer Sample Total Time 0.07141\tPer Sample Data Time 0.00032\tPer Sample DNN Time 0.07109\tTrain Loss 0.0886\t\n",
      "Epoch: [2][239/661]\tPer Sample Total Time 0.07133\tPer Sample Data Time 0.00026\tPer Sample DNN Time 0.07106\tTrain Loss 0.0936\t\n",
      "Epoch: [2][289/661]\tPer Sample Total Time 0.07127\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.07104\tTrain Loss 0.0916\t\n",
      "Epoch: [2][339/661]\tPer Sample Total Time 0.07121\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.07102\tTrain Loss 0.0880\t\n",
      "Epoch: [2][389/661]\tPer Sample Total Time 0.07122\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.07104\tTrain Loss 0.0851\t\n",
      "Epoch: [2][439/661]\tPer Sample Total Time 0.07119\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07103\tTrain Loss 0.0818\t\n",
      "Epoch: [2][489/661]\tPer Sample Total Time 0.07117\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07103\tTrain Loss 0.0778\t\n",
      "Epoch: [2][539/661]\tPer Sample Total Time 0.07117\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07103\tTrain Loss 0.0797\t\n",
      "Epoch: [2][589/661]\tPer Sample Total Time 0.07114\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07101\tTrain Loss 0.0783\t\n",
      "Epoch: [2][639/661]\tPer Sample Total Time 0.07112\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07100\tTrain Loss 0.0764\t\n",
      "start validation\n",
      "acc: 0.839950\n",
      "AUC: 0.970545\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.671249\n",
      "train_loss: 0.075606\n",
      "valid_loss: 1.808594\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 589.733\n",
      "---------------\n",
      "2025-12-12 14:29:38.848358\n",
      "current #epochs=3, #steps=1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][28/661]\tPer Sample Total Time 0.07298\tPer Sample Data Time 0.00210\tPer Sample DNN Time 0.07088\tTrain Loss 0.0729\t\n",
      "Epoch: [3][78/661]\tPer Sample Total Time 0.07147\tPer Sample Data Time 0.00079\tPer Sample DNN Time 0.07068\tTrain Loss 0.0651\t\n",
      "Epoch: [3][128/661]\tPer Sample Total Time 0.07122\tPer Sample Data Time 0.00050\tPer Sample DNN Time 0.07072\tTrain Loss 0.0664\t\n",
      "Epoch: [3][178/661]\tPer Sample Total Time 0.07112\tPer Sample Data Time 0.00037\tPer Sample DNN Time 0.07075\tTrain Loss 0.0615\t\n",
      "Epoch: [3][228/661]\tPer Sample Total Time 0.07104\tPer Sample Data Time 0.00030\tPer Sample DNN Time 0.07074\tTrain Loss 0.0582\t\n",
      "Epoch: [3][278/661]\tPer Sample Total Time 0.07100\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.07075\tTrain Loss 0.0555\t\n",
      "Epoch: [3][328/661]\tPer Sample Total Time 0.07099\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.07077\tTrain Loss 0.0532\t\n",
      "Epoch: [3][378/661]\tPer Sample Total Time 0.07096\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07077\tTrain Loss 0.0493\t\n",
      "Epoch: [3][428/661]\tPer Sample Total Time 0.07094\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07076\tTrain Loss 0.0480\t\n",
      "Epoch: [3][478/661]\tPer Sample Total Time 0.07090\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07075\tTrain Loss 0.0481\t\n",
      "Epoch: [3][528/661]\tPer Sample Total Time 0.07090\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07076\tTrain Loss 0.0528\t\n",
      "Epoch: [3][578/661]\tPer Sample Total Time 0.07088\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07074\tTrain Loss 0.0535\t\n",
      "Epoch: [3][628/661]\tPer Sample Total Time 0.07087\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07074\tTrain Loss 0.0543\t\n",
      "start validation\n",
      "acc: 0.831266\n",
      "AUC: 0.965348\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.568833\n",
      "train_loss: 0.055300\n",
      "valid_loss: 1.808594\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 585.902\n",
      "Running fold 9: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_9.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_9.json --exp-dir /kaggle/working/ast/urban8k_exp/fold9 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain True --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 12975, running on f48cdd07b02b: starting (Fri Dec 12 14:39:29 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold9\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x79c3e76b8290>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 14:39:31.303299\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/660]\tPer Sample Total Time 0.07653\tPer Sample Data Time 0.00106\tPer Sample DNN Time 0.07547\tTrain Loss 1.2994\t\n",
      "Epoch: [1][100/660]\tPer Sample Total Time 0.07393\tPer Sample Data Time 0.00055\tPer Sample DNN Time 0.07338\tTrain Loss 0.9321\t\n",
      "Epoch: [1][150/660]\tPer Sample Total Time 0.07330\tPer Sample Data Time 0.00038\tPer Sample DNN Time 0.07292\tTrain Loss 0.7524\t\n",
      "Epoch: [1][200/660]\tPer Sample Total Time 0.07281\tPer Sample Data Time 0.00029\tPer Sample DNN Time 0.07251\tTrain Loss 0.6388\t\n",
      "Epoch: [1][250/660]\tPer Sample Total Time 0.07256\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.07232\tTrain Loss 0.5674\t\n",
      "Epoch: [1][300/660]\tPer Sample Total Time 0.07240\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.07219\tTrain Loss 0.5121\t\n",
      "Epoch: [1][350/660]\tPer Sample Total Time 0.07229\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.07211\tTrain Loss 0.4736\t\n",
      "Epoch: [1][400/660]\tPer Sample Total Time 0.07218\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07202\tTrain Loss 0.4331\t\n",
      "Epoch: [1][450/660]\tPer Sample Total Time 0.07211\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07197\tTrain Loss 0.4036\t\n",
      "Epoch: [1][500/660]\tPer Sample Total Time 0.07205\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07191\tTrain Loss 0.3806\t\n",
      "Epoch: [1][550/660]\tPer Sample Total Time 0.07195\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07183\tTrain Loss 0.3588\t\n",
      "Epoch: [1][600/660]\tPer Sample Total Time 0.07186\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07174\tTrain Loss 0.3360\t\n",
      "Epoch: [1][650/660]\tPer Sample Total Time 0.07182\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.07170\tTrain Loss 0.3220\t\n",
      "start validation\n",
      "acc: 0.894608\n",
      "AUC: 0.988322\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.206826\n",
      "train_loss: 0.319596\n",
      "valid_loss: 1.784180\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 593.941\n",
      "---------------\n",
      "2025-12-12 14:49:25.244384\n",
      "current #epochs=2, #steps=660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][40/660]\tPer Sample Total Time 0.07295\tPer Sample Data Time 0.00141\tPer Sample DNN Time 0.07155\tTrain Loss 0.0925\t\n",
      "Epoch: [2][90/660]\tPer Sample Total Time 0.07152\tPer Sample Data Time 0.00065\tPer Sample DNN Time 0.07087\tTrain Loss 0.0836\t\n",
      "Epoch: [2][140/660]\tPer Sample Total Time 0.07146\tPer Sample Data Time 0.00043\tPer Sample DNN Time 0.07103\tTrain Loss 0.0748\t\n",
      "Epoch: [2][190/660]\tPer Sample Total Time 0.07130\tPer Sample Data Time 0.00033\tPer Sample DNN Time 0.07097\tTrain Loss 0.0742\t\n",
      "Epoch: [2][240/660]\tPer Sample Total Time 0.07129\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.07103\tTrain Loss 0.0776\t\n",
      "Epoch: [2][290/660]\tPer Sample Total Time 0.07121\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.07098\tTrain Loss 0.0810\t\n",
      "Epoch: [2][340/660]\tPer Sample Total Time 0.07116\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.07097\tTrain Loss 0.0805\t\n",
      "Epoch: [2][390/660]\tPer Sample Total Time 0.07116\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.07098\tTrain Loss 0.0779\t\n",
      "Epoch: [2][440/660]\tPer Sample Total Time 0.07114\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07098\tTrain Loss 0.0775\t\n",
      "Epoch: [2][490/660]\tPer Sample Total Time 0.07112\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07097\tTrain Loss 0.0762\t\n",
      "Epoch: [2][540/660]\tPer Sample Total Time 0.07110\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07097\tTrain Loss 0.0757\t\n",
      "Epoch: [2][590/660]\tPer Sample Total Time 0.07111\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07098\tTrain Loss 0.0747\t\n",
      "Epoch: [2][640/660]\tPer Sample Total Time 0.07109\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07097\tTrain Loss 0.0765\t\n",
      "start validation\n",
      "acc: 0.897059\n",
      "AUC: 0.992535\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.442271\n",
      "train_loss: 0.076278\n",
      "valid_loss: 1.755859\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 588.705\n",
      "---------------\n",
      "2025-12-12 14:59:13.949645\n",
      "current #epochs=3, #steps=1320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][30/660]\tPer Sample Total Time 0.07279\tPer Sample Data Time 0.00172\tPer Sample DNN Time 0.07107\tTrain Loss 0.0659\t\n",
      "Epoch: [3][80/660]\tPer Sample Total Time 0.07179\tPer Sample Data Time 0.00068\tPer Sample DNN Time 0.07111\tTrain Loss 0.0529\t\n",
      "Epoch: [3][130/660]\tPer Sample Total Time 0.07124\tPer Sample Data Time 0.00043\tPer Sample DNN Time 0.07081\tTrain Loss 0.0419\t\n",
      "Epoch: [3][180/660]\tPer Sample Total Time 0.07112\tPer Sample Data Time 0.00032\tPer Sample DNN Time 0.07080\tTrain Loss 0.0397\t\n",
      "Epoch: [3][230/660]\tPer Sample Total Time 0.07099\tPer Sample Data Time 0.00026\tPer Sample DNN Time 0.07073\tTrain Loss 0.0358\t\n",
      "Epoch: [3][280/660]\tPer Sample Total Time 0.07100\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.07078\tTrain Loss 0.0416\t\n",
      "Epoch: [3][330/660]\tPer Sample Total Time 0.07098\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07079\tTrain Loss 0.0461\t\n",
      "Epoch: [3][380/660]\tPer Sample Total Time 0.07096\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07079\tTrain Loss 0.0466\t\n",
      "Epoch: [3][430/660]\tPer Sample Total Time 0.07095\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07080\tTrain Loss 0.0482\t\n",
      "Epoch: [3][480/660]\tPer Sample Total Time 0.07096\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07082\tTrain Loss 0.0493\t\n",
      "Epoch: [3][530/660]\tPer Sample Total Time 0.07095\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07082\tTrain Loss 0.0477\t\n",
      "Epoch: [3][580/660]\tPer Sample Total Time 0.07095\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07082\tTrain Loss 0.0476\t\n",
      "Epoch: [3][630/660]\tPer Sample Total Time 0.07092\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.07081\tTrain Loss 0.0494\t\n",
      "start validation\n",
      "acc: 0.878676\n",
      "AUC: 0.983424\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.012599\n",
      "train_loss: 0.050251\n",
      "valid_loss: 1.771484\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 585.571\n",
      "Running fold 10: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_10.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_10.json --exp-dir /kaggle/working/ast/urban8k_exp/fold10 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain True --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 17269, running on f48cdd07b02b: starting (Fri Dec 12 15:09:04 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold10\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x79224a4af050>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 15:09:06.295512\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/658]\tPer Sample Total Time 0.07674\tPer Sample Data Time 0.00123\tPer Sample DNN Time 0.07551\tTrain Loss 1.3386\t\n",
      "Epoch: [1][100/658]\tPer Sample Total Time 0.07406\tPer Sample Data Time 0.00064\tPer Sample DNN Time 0.07342\tTrain Loss 0.9493\t\n",
      "Epoch: [1][150/658]\tPer Sample Total Time 0.07342\tPer Sample Data Time 0.00044\tPer Sample DNN Time 0.07298\tTrain Loss 0.7352\t\n",
      "Epoch: [1][200/658]\tPer Sample Total Time 0.07299\tPer Sample Data Time 0.00034\tPer Sample DNN Time 0.07265\tTrain Loss 0.6336\t\n",
      "Epoch: [1][250/658]\tPer Sample Total Time 0.07277\tPer Sample Data Time 0.00028\tPer Sample DNN Time 0.07250\tTrain Loss 0.5685\t\n",
      "Epoch: [1][300/658]\tPer Sample Total Time 0.07262\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.07238\tTrain Loss 0.5083\t\n",
      "Epoch: [1][350/658]\tPer Sample Total Time 0.07247\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.07226\tTrain Loss 0.4626\t\n",
      "Epoch: [1][400/658]\tPer Sample Total Time 0.07232\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07214\tTrain Loss 0.4258\t\n",
      "Epoch: [1][450/658]\tPer Sample Total Time 0.07226\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07209\tTrain Loss 0.3996\t\n",
      "Epoch: [1][500/658]\tPer Sample Total Time 0.07213\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07197\tTrain Loss 0.3803\t\n",
      "Epoch: [1][550/658]\tPer Sample Total Time 0.07203\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07188\tTrain Loss 0.3583\t\n",
      "Epoch: [1][600/658]\tPer Sample Total Time 0.07195\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07181\tTrain Loss 0.3429\t\n",
      "Epoch: [1][650/658]\tPer Sample Total Time 0.07189\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07176\tTrain Loss 0.3300\t\n",
      "start validation\n",
      "acc: 0.892473\n",
      "AUC: 0.992773\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.458838\n",
      "train_loss: 0.328286\n",
      "valid_loss: 1.765625\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 593.467\n",
      "---------------\n",
      "2025-12-12 15:18:59.762708\n",
      "current #epochs=2, #steps=658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][42/658]\tPer Sample Total Time 0.07278\tPer Sample Data Time 0.00147\tPer Sample DNN Time 0.07131\tTrain Loss 0.0842\t\n",
      "Epoch: [2][92/658]\tPer Sample Total Time 0.07172\tPer Sample Data Time 0.00070\tPer Sample DNN Time 0.07102\tTrain Loss 0.0799\t\n",
      "Epoch: [2][142/658]\tPer Sample Total Time 0.07158\tPer Sample Data Time 0.00047\tPer Sample DNN Time 0.07111\tTrain Loss 0.0879\t\n",
      "Epoch: [2][192/658]\tPer Sample Total Time 0.07145\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.07109\tTrain Loss 0.0878\t\n",
      "Epoch: [2][242/658]\tPer Sample Total Time 0.07137\tPer Sample Data Time 0.00029\tPer Sample DNN Time 0.07108\tTrain Loss 0.0872\t\n",
      "Epoch: [2][292/658]\tPer Sample Total Time 0.07128\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.07104\tTrain Loss 0.0823\t\n",
      "Epoch: [2][342/658]\tPer Sample Total Time 0.07126\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.07105\tTrain Loss 0.0765\t\n",
      "Epoch: [2][392/658]\tPer Sample Total Time 0.07121\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.07102\tTrain Loss 0.0743\t\n",
      "Epoch: [2][442/658]\tPer Sample Total Time 0.07117\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.07099\tTrain Loss 0.0783\t\n",
      "Epoch: [2][492/658]\tPer Sample Total Time 0.07116\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07100\tTrain Loss 0.0787\t\n",
      "Epoch: [2][542/658]\tPer Sample Total Time 0.07113\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07099\tTrain Loss 0.0764\t\n",
      "Epoch: [2][592/658]\tPer Sample Total Time 0.07110\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07096\tTrain Loss 0.0778\t\n",
      "Epoch: [2][642/658]\tPer Sample Total Time 0.07108\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07095\tTrain Loss 0.0770\t\n",
      "start validation\n",
      "acc: 0.909200\n",
      "AUC: 0.994742\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.618133\n",
      "train_loss: 0.078717\n",
      "valid_loss: 1.750977\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 587.841\n",
      "---------------\n",
      "2025-12-12 15:28:47.603490\n",
      "current #epochs=3, #steps=1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][34/658]\tPer Sample Total Time 0.07311\tPer Sample Data Time 0.00184\tPer Sample DNN Time 0.07128\tTrain Loss 0.0389\t\n",
      "Epoch: [3][84/658]\tPer Sample Total Time 0.07157\tPer Sample Data Time 0.00078\tPer Sample DNN Time 0.07079\tTrain Loss 0.0461\t\n",
      "Epoch: [3][134/658]\tPer Sample Total Time 0.07112\tPer Sample Data Time 0.00050\tPer Sample DNN Time 0.07062\tTrain Loss 0.0469\t\n",
      "Epoch: [3][184/658]\tPer Sample Total Time 0.07095\tPer Sample Data Time 0.00037\tPer Sample DNN Time 0.07058\tTrain Loss 0.0475\t\n",
      "Epoch: [3][234/658]\tPer Sample Total Time 0.07086\tPer Sample Data Time 0.00030\tPer Sample DNN Time 0.07056\tTrain Loss 0.0499\t\n",
      "Epoch: [3][284/658]\tPer Sample Total Time 0.07083\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.07058\tTrain Loss 0.0514\t\n",
      "Epoch: [3][334/658]\tPer Sample Total Time 0.07080\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.07058\tTrain Loss 0.0535\t\n",
      "Epoch: [3][384/658]\tPer Sample Total Time 0.07076\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.07057\tTrain Loss 0.0538\t\n",
      "Epoch: [3][434/658]\tPer Sample Total Time 0.07077\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.07059\tTrain Loss 0.0530\t\n",
      "Epoch: [3][484/658]\tPer Sample Total Time 0.07076\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.07059\tTrain Loss 0.0530\t\n",
      "Epoch: [3][534/658]\tPer Sample Total Time 0.07075\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.07060\tTrain Loss 0.0525\t\n",
      "Epoch: [3][584/658]\tPer Sample Total Time 0.07075\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.07061\tTrain Loss 0.0512\t\n",
      "Epoch: [3][634/658]\tPer Sample Total Time 0.07074\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.07061\tTrain Loss 0.0521\t\n",
      "start validation\n",
      "acc: 0.923536\n",
      "AUC: 0.995361\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.679312\n",
      "train_loss: 0.051906\n",
      "valid_loss: 1.732422\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 585.305\n",
      "Fold 6: best val acc 0.8408\n",
      "Fold 7: best val acc 0.9010\n",
      "Fold 8: best val acc 0.8400\n",
      "Fold 9: best val acc 0.8971\n",
      "Fold 10: best val acc 0.9235\n",
      "10-fold mean acc: 0.8805 +/- 0.0339\n"
     ]
    }
   ],
   "source": [
    "# Kick off full 10-fold: each fold is held out as test once\n",
    "folds_to_run = list(range(6, 11))\n",
    "for f in folds_to_run:\n",
    "    run_fold(f)\n",
    "\n",
    "# Aggregate best validation accuracy per fold (col 0 of result.csv)\n",
    "fold_acc = []\n",
    "for f in folds_to_run:\n",
    "    res_path = REPO_DIR / 'urban8k_exp' / f'fold{f}' / 'result.csv'\n",
    "    arr = np.loadtxt(res_path, delimiter=',')\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr[None, :]\n",
    "    best_acc = float(arr[:, 0].max())\n",
    "    fold_acc.append(best_acc)\n",
    "    print(f'Fold {f}: best val acc {best_acc:.4f}')\n",
    "\n",
    "mean_acc = float(np.mean(fold_acc))\n",
    "std_acc = float(np.std(fold_acc))\n",
    "print(f'10-fold mean acc: {mean_acc:.4f} +/- {std_acc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 500970,
     "sourceId": 928025,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8969.039562,
   "end_time": "2025-12-12T15:38:35.731762",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-12T13:09:06.692200",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
