{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1842c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-12T11:08:07.850040Z",
     "iopub.status.busy": "2025-12-12T11:08:07.849800Z",
     "iopub.status.idle": "2025-12-12T11:09:23.425057Z",
     "shell.execute_reply": "2025-12-12T11:09:23.424188Z"
    },
    "papermill": {
     "duration": 75.581318,
     "end_time": "2025-12-12T11:09:23.426377",
     "exception": false,
     "start_time": "2025-12-12T11:08:07.845059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing /kaggle/input ...\n",
      "Device: cuda\n",
      "[*INFO] Installing libraries...\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 287.4/287.4 kB 10.1 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 323.4 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 263.6 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 325.8 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 194.1 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 325.3 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 327.8 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 332.3 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 316.8 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 329.6 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 328.1 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*INFO] Cleaning up memory after installation...\n",
      "[*INFO] Cloning AST repo ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/ast'...\n",
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# secret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "# from huggingface_hub import HfApi, login\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import sys\n",
    "import subprocess\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torchaudio\n",
    "\n",
    "# AST Fine-tuning on UrbanSound8K (Kaggle version)\n",
    "# - Auto-detect UrbanSound8K in /kaggle/input\n",
    "# - Clone AST repo into /kaggle/working/ast\n",
    "# - Download AudioSet checkpoint\n",
    "# - 10-fold cross-validation training\n",
    "\n",
    "\n",
    "\n",
    "# 0. ENV INFO & SEED\n",
    "\n",
    "print(\"Listing /kaggle/input ...\")\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "\n",
    "# 1. INSTALL REQUIRED LIBRARIES (if needed)\n",
    "import gc # <--- Import thư viện dọn rác\n",
    "\n",
    "def pip_install(package):\n",
    "    # Thêm \"--no-cache-dir\" để không ngốn RAM lưu file tạm\n",
    "    # Thêm \"-q\" (quiet) để giảm log in ra màn hình\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"-q\", package])\n",
    "\n",
    "print(\"[*INFO] Installing libraries...\")\n",
    "# timm==0.4.5 là bản được AST repo dùng\n",
    "pip_install(\"timm==0.4.5\")\n",
    "pip_install(\"wget\")\n",
    "pip_install(\"librosa\")  \n",
    "\n",
    "\n",
    "print(\"[*INFO] Cleaning up memory after installation...\")\n",
    "gc.collect() \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "# ======================================================\n",
    "\n",
    "import timm\n",
    "import wget\n",
    "\n",
    "# 2. CLONE AST REPO VÀ IMPORT ASTModel\n",
    "REPO_DIR = \"/kaggle/working/ast\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print(\"[*INFO] Cloning AST repo ...\")\n",
    "    subprocess.check_call([\"git\", \"clone\", \"https://github.com/YuanGongND/ast\", REPO_DIR])\n",
    "else:\n",
    "    print(\"[*INFO] AST repo already exists at\", REPO_DIR)\n",
    "\n",
    "sys.path.append(REPO_DIR)\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "from src.models import ASTModel  # AST model class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8647bc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:09:23.435047Z",
     "iopub.status.busy": "2025-12-12T11:09:23.434313Z",
     "iopub.status.idle": "2025-12-12T11:09:28.346108Z",
     "shell.execute_reply": "2025-12-12T11:09:28.345266Z"
    },
    "papermill": {
     "duration": 4.917099,
     "end_time": "2025-12-12T11:09:28.347275",
     "exception": false,
     "start_time": "2025-12-12T11:09:23.430176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*INFO] Found UrbanSound8K.csv at: /kaggle/input/urbansound8k/UrbanSound8K.csv\n",
      "[*INFO] Sample row -> fold=5, fname=100032-3-0-0.wav\n",
      "[*INFO] AUDIO_ROOT detected as: /kaggle/input/urbansound8k\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. TÌM METADATA CSV UrbanSound8K\n",
    "\n",
    "US8K_META_PATH = None\n",
    "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "    if \"UrbanSound8K.csv\" in files:\n",
    "        US8K_META_PATH = os.path.join(root, \"UrbanSound8K.csv\")\n",
    "        break\n",
    "\n",
    "if US8K_META_PATH is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Không tìm thấy UrbanSound8K.csv trong /kaggle/input. \"\n",
    "        \"Kiểm tra lại dataset UrbanSound8K đã add vào notebook.\"\n",
    "    )\n",
    "\n",
    "print(\"[*INFO] Found UrbanSound8K.csv at:\", US8K_META_PATH)\n",
    "METADATA_CSV = US8K_META_PATH\n",
    "\n",
    "\n",
    "# 4. TÌM CHÍNH XÁC AUDIO_ROOT BẰNG CÁCH DÒ FILE THẬT\n",
    "\n",
    "df_meta = pd.read_csv(METADATA_CSV)\n",
    "sample_row = df_meta.iloc[0]\n",
    "sample_fname = sample_row[\"slice_file_name\"]\n",
    "sample_fold = sample_row[\"fold\"]\n",
    "target_fold_dir = f\"fold{sample_fold}\"\n",
    "\n",
    "print(f\"[*INFO] Sample row -> fold={sample_fold}, fname={sample_fname}\")\n",
    "\n",
    "AUDIO_ROOT = None\n",
    "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "    if os.path.basename(root) == target_fold_dir and sample_fname in files:\n",
    "        # root = .../audio/foldX\n",
    "        AUDIO_ROOT = os.path.dirname(root)  # bỏ /foldX\n",
    "        break\n",
    "\n",
    "if AUDIO_ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Không tìm thấy thư mục audio chứa fold{sample_fold} và file {sample_fname} trong /kaggle/input.\"\n",
    "    )\n",
    "\n",
    "print(\"[*INFO] AUDIO_ROOT detected as:\", AUDIO_ROOT)\n",
    "\n",
    "# Thư mục lưu checkpoint\n",
    "CKPT_DIR = \"/kaggle/working/ast_us8k_checkpoints\"\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2413419d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:09:28.356755Z",
     "iopub.status.busy": "2025-12-12T11:09:28.356340Z",
     "iopub.status.idle": "2025-12-12T11:09:28.359983Z",
     "shell.execute_reply": "2025-12-12T11:09:28.359329Z"
    },
    "papermill": {
     "duration": 0.009575,
     "end_time": "2025-12-12T11:09:28.361076",
     "exception": false,
     "start_time": "2025-12-12T11:09:28.351501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/urbansound8k\n"
     ]
    }
   ],
   "source": [
    "print(AUDIO_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3cab39",
   "metadata": {
    "papermill": {
     "duration": 0.003298,
     "end_time": "2025-12-12T11:09:28.367760",
     "exception": false,
     "start_time": "2025-12-12T11:09:28.364462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111d1b4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:09:28.375587Z",
     "iopub.status.busy": "2025-12-12T11:09:28.375066Z",
     "iopub.status.idle": "2025-12-12T11:09:28.379914Z",
     "shell.execute_reply": "2025-12-12T11:09:28.379274Z"
    },
    "papermill": {
     "duration": 0.009693,
     "end_time": "2025-12-12T11:09:28.380876",
     "exception": false,
     "start_time": "2025-12-12T11:09:28.371183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /kaggle/working/ast\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "try:\n",
    "    REPO_DIR\n",
    "except NameError:\n",
    "    REPO_DIR = Path('.').resolve()\n",
    "else:\n",
    "    REPO_DIR = Path(REPO_DIR)\n",
    "TORCH_HOME = REPO_DIR / 'pretrained_models'\n",
    "os.environ['TORCH_HOME'] = str(TORCH_HOME)\n",
    "TORCH_HOME.mkdir(exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Repo root:', REPO_DIR)\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e8f374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:09:28.388894Z",
     "iopub.status.busy": "2025-12-12T11:09:28.388713Z",
     "iopub.status.idle": "2025-12-12T11:09:28.420293Z",
     "shell.execute_reply": "2025-12-12T11:09:28.419637Z"
    },
    "papermill": {
     "duration": 0.036948,
     "end_time": "2025-12-12T11:09:28.421310",
     "exception": false,
     "start_time": "2025-12-12T11:09:28.384362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label CSV written to: /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv\n"
     ]
    }
   ],
   "source": [
    "# Build label CSV (index, mid, display_name)\n",
    "meta_df = pd.read_csv(METADATA_CSV)\n",
    "label_csv = REPO_DIR / 'urban8k_data' / 'urban8k_class_labels_indices.csv'\n",
    "label_csv.parent.mkdir(exist_ok=True)\n",
    "\n",
    "unique_classes = meta_df[['classID', 'class']].drop_duplicates().sort_values('classID')\n",
    "with open(label_csv, 'w') as f:\n",
    "    f.write('index,mid,display_name\\n')\n",
    "    for _, row in unique_classes.iterrows():\n",
    "        idx = int(row['classID'])\n",
    "        mid = f\"/m/urban{idx:02d}\"\n",
    "        name = row['class']\n",
    "        f.write(f\"{idx},{mid},{name}\\n\")\n",
    "\n",
    "print('Label CSV written to:', label_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120bb785",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:09:28.428785Z",
     "iopub.status.busy": "2025-12-12T11:09:28.428547Z",
     "iopub.status.idle": "2025-12-12T11:09:33.441152Z",
     "shell.execute_reply": "2025-12-12T11:09:33.440406Z"
    },
    "papermill": {
     "duration": 5.017954,
     "end_time": "2025-12-12T11:09:33.442603",
     "exception": false,
     "start_time": "2025-12-12T11:09:28.424649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: train 7859, eval 873\n",
      "Fold 2: train 7844, eval 888\n",
      "Fold 3: train 7807, eval 925\n",
      "Fold 4: train 7742, eval 990\n",
      "Fold 5: train 7796, eval 936\n",
      "Fold 6: train 7909, eval 823\n",
      "Fold 7: train 7894, eval 838\n",
      "Fold 8: train 7926, eval 806\n",
      "Fold 9: train 7916, eval 816\n",
      "Fold 10: train 7895, eval 837\n"
     ]
    }
   ],
   "source": [
    "import json, shutil\n",
    "\n",
    "# Create JSON datafiles per fold (ESC-50 style)\n",
    "data_dir = REPO_DIR / 'urban8k_data' / 'datafiles'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def rows_for_df(df):\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        wav_path = Path(AUDIO_ROOT) / f\"fold{int(r['fold'])}\" / r['slice_file_name']\n",
    "        rows.append({\n",
    "            'wav': str(wav_path),\n",
    "            'labels': f\"/m/urban{int(r['classID']):02d}\"\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "for fold in range(1, 11):\n",
    "    train_df = meta_df[meta_df['fold'] != fold]\n",
    "    eval_df = meta_df[meta_df['fold'] == fold]\n",
    "    train_json = {'data': rows_for_df(train_df)}\n",
    "    eval_json = {'data': rows_for_df(eval_df)}\n",
    "    with open(data_dir / f'urban_train_data_{fold}.json', 'w') as f:\n",
    "        json.dump(train_json, f, indent=1)\n",
    "    with open(data_dir / f'urban_eval_data_{fold}.json', 'w') as f:\n",
    "        json.dump(eval_json, f, indent=1)\n",
    "    print(f'Fold {fold}: train {len(train_df)}, eval {len(eval_df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b46754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:09:33.452611Z",
     "iopub.status.busy": "2025-12-12T11:09:33.451863Z",
     "iopub.status.idle": "2025-12-12T11:09:33.459737Z",
     "shell.execute_reply": "2025-12-12T11:09:33.459206Z"
    },
    "papermill": {
     "duration": 0.013405,
     "end_time": "2025-12-12T11:09:33.460653",
     "exception": false,
     "start_time": "2025-12-12T11:09:33.447248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mean/std: -1.7362523965764032 3.2758855893221015\n"
     ]
    }
   ],
   "source": [
    "# Compute dataset mean/std over fbank features (optional; default uses AudioSet stats)\n",
    "import torchaudio\n",
    "\n",
    "def compute_norm_stats(df, target_length=1024, mel_bins=128, target_sr=16000, max_files=None):\n",
    "    total = 0.0\n",
    "    total_sq = 0.0\n",
    "    count = 0\n",
    "    rows = df if max_files is None else df.sample(n=max_files, random_state=SEED)\n",
    "    for _, r in rows.iterrows():\n",
    "        wav_path = Path(AUDIO_ROOT) / f\"fold{int(r['fold'])}\" / r['slice_file_name']\n",
    "        wav, sr = torchaudio.load(str(wav_path))\n",
    "        if wav.shape[0] > 1:\n",
    "            wav = wav.mean(dim=0, keepdim=True)\n",
    "        if sr != target_sr:\n",
    "            wav = torchaudio.transforms.Resample(sr, target_sr)(wav)\n",
    "            sr = target_sr\n",
    "        fb = torchaudio.compliance.kaldi.fbank(\n",
    "            wav, htk_compat=True, sample_frequency=sr, use_energy=False,\n",
    "            window_type='hanning', num_mel_bins=mel_bins, dither=0.0, frame_shift=10\n",
    "        )\n",
    "        p = target_length - fb.shape[0]\n",
    "        if p > 0:\n",
    "            fb = torch.nn.functional.pad(fb, (0, 0, 0, p))\n",
    "        elif p < 0:\n",
    "            fb = fb[:target_length, :]\n",
    "        total += fb.sum().item()\n",
    "        total_sq += (fb ** 2).sum().item()\n",
    "        count += fb.numel()\n",
    "    mean = total / count\n",
    "    var = total_sq / count - mean ** 2\n",
    "    std = var ** 0.5\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "try:\n",
    "    DATASET_MEAN\n",
    "    DATASET_STD\n",
    "except NameError:\n",
    "    DATASET_MEAN = -1.7362523965764032\n",
    "    DATASET_STD = 3.2758855893221015\n",
    "print('Using mean/std:', DATASET_MEAN, DATASET_STD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed694d9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:09:33.469402Z",
     "iopub.status.busy": "2025-12-12T11:09:33.469075Z",
     "iopub.status.idle": "2025-12-12T11:09:33.476534Z",
     "shell.execute_reply": "2025-12-12T11:09:33.475817Z"
    },
    "papermill": {
     "duration": 0.013032,
     "end_time": "2025-12-12T11:09:33.477522",
     "exception": false,
     "start_time": "2025-12-12T11:09:33.464490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH_HOME: /kaggle/pretrained_models\n",
      "Helper ready: run_fold(fold) to launch training\n"
     ]
    }
   ],
   "source": [
    "REPO_DIR = Path('.').resolve()\n",
    "PRETRAIN_DIR = (REPO_DIR / '../../pretrained_models').resolve()\n",
    "PRETRAIN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "os.environ['TORCH_HOME'] = str(PRETRAIN_DIR)\n",
    "print('TORCH_HOME:', PRETRAIN_DIR)\n",
    "# Helper to launch training via src/run.py with ESC-50-like hyperparameters\n",
    "def run_fold(fold, epochs=3, batch_size=12, lr=1e-5):\n",
    "    exp_dir = REPO_DIR / 'urban8k_exp' / f'fold{fold}'\n",
    "    if exp_dir.exists():\n",
    "        shutil.rmtree(exp_dir)\n",
    "    exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    train_json = data_dir / f'urban_train_data_{fold}.json'\n",
    "    eval_json = data_dir / f'urban_eval_data_{fold}.json'\n",
    "\n",
    "    cmd = [\n",
    "        sys.executable, 'src/run.py',\n",
    "        '--model', 'ast',\n",
    "        '--dataset', 'urban8k',\n",
    "        '--data-train', str(train_json),\n",
    "        '--data-val', str(eval_json),\n",
    "        '--exp-dir', str(exp_dir),\n",
    "        '--label-csv', str(label_csv),\n",
    "        '--n_class', '10',\n",
    "        '--lr', str(lr),\n",
    "        '--n-epochs', str(epochs),\n",
    "        '--batch-size', str(batch_size),\n",
    "        '--save_model', 'False',\n",
    "        '--freqm', '24',\n",
    "        '--timem', '96',\n",
    "        '--mixup', '0',\n",
    "        '--bal', 'none',\n",
    "        '--tstride', '10', '--fstride', '10',\n",
    "        '--imagenet_pretrain', 'True',\n",
    "        '--audioset_pretrain', 'True',\n",
    "        '--metrics', 'acc',\n",
    "        '--loss', 'CE',\n",
    "        '--warmup', 'False',\n",
    "        '--lrscheduler_start', '5',\n",
    "        '--lrscheduler_step', '1',\n",
    "        '--lrscheduler_decay', '0.85',\n",
    "        '--dataset_mean', str(DATASET_MEAN),\n",
    "        '--dataset_std', str(DATASET_STD),\n",
    "        '--audio_length', '1024',\n",
    "        '--noise', 'False',\n",
    "        '--num-workers', '4',\n",
    "        '--n-print-steps', '50'\n",
    "    ]\n",
    "    env = os.environ.copy()\n",
    "    env['TORCH_HOME'] = str(TORCH_HOME)\n",
    "    print(f'Running fold {fold}:', ' '.join(cmd))\n",
    "    subprocess.check_call(cmd, env=env, cwd=REPO_DIR)\n",
    "\n",
    "print('Helper ready: run_fold(fold) to launch training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e01c534a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:09:33.486088Z",
     "iopub.status.busy": "2025-12-12T11:09:33.485883Z",
     "iopub.status.idle": "2025-12-12T13:30:44.547136Z",
     "shell.execute_reply": "2025-12-12T13:30:44.546260Z"
    },
    "papermill": {
     "duration": 8471.067036,
     "end_time": "2025-12-12T13:30:44.548446",
     "exception": false,
     "start_time": "2025-12-12T11:09:33.481410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 1: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_1.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_1.json --exp-dir /kaggle/working/ast/urban8k_exp/fold1 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain True --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 88, running on 22c3b1e9ac95: starting (Fri Dec 12 11:09:37 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold1\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7b0accc3cbd0>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 11:09:43.743162\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/655]\tPer Sample Total Time 0.06713\tPer Sample Data Time 0.00125\tPer Sample DNN Time 0.06587\tTrain Loss 1.2545\t\n",
      "Epoch: [1][100/655]\tPer Sample Total Time 0.06590\tPer Sample Data Time 0.00065\tPer Sample DNN Time 0.06525\tTrain Loss 0.9013\t\n",
      "Epoch: [1][150/655]\tPer Sample Total Time 0.06645\tPer Sample Data Time 0.00044\tPer Sample DNN Time 0.06601\tTrain Loss 0.7116\t\n",
      "Epoch: [1][200/655]\tPer Sample Total Time 0.06709\tPer Sample Data Time 0.00034\tPer Sample DNN Time 0.06675\tTrain Loss 0.6116\t\n",
      "Epoch: [1][250/655]\tPer Sample Total Time 0.06733\tPer Sample Data Time 0.00028\tPer Sample DNN Time 0.06706\tTrain Loss 0.5353\t\n",
      "Epoch: [1][300/655]\tPer Sample Total Time 0.06757\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.06733\tTrain Loss 0.4872\t\n",
      "Epoch: [1][350/655]\tPer Sample Total Time 0.06768\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.06747\tTrain Loss 0.4447\t\n",
      "Epoch: [1][400/655]\tPer Sample Total Time 0.06775\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.06757\tTrain Loss 0.4188\t\n",
      "Epoch: [1][450/655]\tPer Sample Total Time 0.06784\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06767\tTrain Loss 0.3903\t\n",
      "Epoch: [1][500/655]\tPer Sample Total Time 0.06792\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06776\tTrain Loss 0.3650\t\n",
      "Epoch: [1][550/655]\tPer Sample Total Time 0.06795\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06781\tTrain Loss 0.3446\t\n",
      "Epoch: [1][600/655]\tPer Sample Total Time 0.06799\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06786\tTrain Loss 0.3283\t\n",
      "Epoch: [1][650/655]\tPer Sample Total Time 0.06803\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06790\tTrain Loss 0.3161\t\n",
      "start validation\n",
      "acc: 0.823597\n",
      "AUC: 0.982555\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.983461\n",
      "train_loss: 0.315040\n",
      "valid_loss: 1.799805\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 560.816\n",
      "---------------\n",
      "2025-12-12 11:19:04.559014\n",
      "current #epochs=2, #steps=655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][45/655]\tPer Sample Total Time 0.06993\tPer Sample Data Time 0.00142\tPer Sample DNN Time 0.06851\tTrain Loss 0.1016\t\n",
      "Epoch: [2][95/655]\tPer Sample Total Time 0.06893\tPer Sample Data Time 0.00070\tPer Sample DNN Time 0.06823\tTrain Loss 0.0848\t\n",
      "Epoch: [2][145/655]\tPer Sample Total Time 0.06865\tPer Sample Data Time 0.00047\tPer Sample DNN Time 0.06818\tTrain Loss 0.0773\t\n",
      "Epoch: [2][195/655]\tPer Sample Total Time 0.06851\tPer Sample Data Time 0.00036\tPer Sample DNN Time 0.06816\tTrain Loss 0.0772\t\n",
      "Epoch: [2][245/655]\tPer Sample Total Time 0.06840\tPer Sample Data Time 0.00029\tPer Sample DNN Time 0.06811\tTrain Loss 0.0813\t\n",
      "Epoch: [2][295/655]\tPer Sample Total Time 0.06831\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.06807\tTrain Loss 0.0816\t\n",
      "Epoch: [2][345/655]\tPer Sample Total Time 0.06827\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.06806\tTrain Loss 0.0775\t\n",
      "Epoch: [2][395/655]\tPer Sample Total Time 0.06822\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06803\tTrain Loss 0.0798\t\n",
      "Epoch: [2][445/655]\tPer Sample Total Time 0.06817\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06799\tTrain Loss 0.0818\t\n",
      "Epoch: [2][495/655]\tPer Sample Total Time 0.06814\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.06798\tTrain Loss 0.0799\t\n",
      "Epoch: [2][545/655]\tPer Sample Total Time 0.06813\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06798\tTrain Loss 0.0822\t\n",
      "Epoch: [2][595/655]\tPer Sample Total Time 0.06811\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06797\tTrain Loss 0.0799\t\n",
      "Epoch: [2][645/655]\tPer Sample Total Time 0.06807\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06795\tTrain Loss 0.0775\t\n",
      "start validation\n",
      "acc: 0.823597\n",
      "AUC: 0.983337\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.009637\n",
      "train_loss: 0.078586\n",
      "valid_loss: 1.778320\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 559.633\n",
      "---------------\n",
      "2025-12-12 11:28:24.192139\n",
      "current #epochs=3, #steps=1310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][40/655]\tPer Sample Total Time 0.06937\tPer Sample Data Time 0.00112\tPer Sample DNN Time 0.06825\tTrain Loss 0.0522\t\n",
      "Epoch: [3][90/655]\tPer Sample Total Time 0.06847\tPer Sample Data Time 0.00052\tPer Sample DNN Time 0.06795\tTrain Loss 0.0460\t\n",
      "Epoch: [3][140/655]\tPer Sample Total Time 0.06816\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.06782\tTrain Loss 0.0431\t\n",
      "Epoch: [3][190/655]\tPer Sample Total Time 0.06806\tPer Sample Data Time 0.00026\tPer Sample DNN Time 0.06779\tTrain Loss 0.0434\t\n",
      "Epoch: [3][240/655]\tPer Sample Total Time 0.06800\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.06779\tTrain Loss 0.0428\t\n",
      "Epoch: [3][290/655]\tPer Sample Total Time 0.06796\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.06778\tTrain Loss 0.0473\t\n",
      "Epoch: [3][340/655]\tPer Sample Total Time 0.06793\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.06777\tTrain Loss 0.0466\t\n",
      "Epoch: [3][390/655]\tPer Sample Total Time 0.06792\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06777\tTrain Loss 0.0472\t\n",
      "Epoch: [3][440/655]\tPer Sample Total Time 0.06787\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06774\tTrain Loss 0.0493\t\n",
      "Epoch: [3][490/655]\tPer Sample Total Time 0.06785\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06773\tTrain Loss 0.0473\t\n",
      "Epoch: [3][540/655]\tPer Sample Total Time 0.06784\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06772\tTrain Loss 0.0456\t\n",
      "Epoch: [3][590/655]\tPer Sample Total Time 0.06781\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.06771\tTrain Loss 0.0448\t\n",
      "Epoch: [3][640/655]\tPer Sample Total Time 0.06779\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.06769\tTrain Loss 0.0445\t\n",
      "start validation\n",
      "acc: 0.851088\n",
      "AUC: 0.986516\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.128216\n",
      "train_loss: 0.044198\n",
      "valid_loss: 1.765625\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 559.246\n",
      "Running fold 2: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_2.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_2.json --exp-dir /kaggle/working/ast/urban8k_exp/fold2 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain True --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 4370, running on 22c3b1e9ac95: starting (Fri Dec 12 11:37:48 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold2\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fac3e340990>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 11:37:50.093611\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/654]\tPer Sample Total Time 0.07348\tPer Sample Data Time 0.00104\tPer Sample DNN Time 0.07244\tTrain Loss 1.3355\t\n",
      "Epoch: [1][100/654]\tPer Sample Total Time 0.07093\tPer Sample Data Time 0.00054\tPer Sample DNN Time 0.07039\tTrain Loss 0.9613\t\n",
      "Epoch: [1][150/654]\tPer Sample Total Time 0.07027\tPer Sample Data Time 0.00037\tPer Sample DNN Time 0.06990\tTrain Loss 0.7775\t\n",
      "Epoch: [1][200/654]\tPer Sample Total Time 0.06984\tPer Sample Data Time 0.00029\tPer Sample DNN Time 0.06955\tTrain Loss 0.6593\t\n",
      "Epoch: [1][250/654]\tPer Sample Total Time 0.06960\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.06937\tTrain Loss 0.5756\t\n",
      "Epoch: [1][300/654]\tPer Sample Total Time 0.06944\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.06924\tTrain Loss 0.5145\t\n",
      "Epoch: [1][350/654]\tPer Sample Total Time 0.06928\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.06910\tTrain Loss 0.4700\t\n",
      "Epoch: [1][400/654]\tPer Sample Total Time 0.06914\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.06898\tTrain Loss 0.4330\t\n",
      "Epoch: [1][450/654]\tPer Sample Total Time 0.06907\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06893\tTrain Loss 0.3993\t\n",
      "Epoch: [1][500/654]\tPer Sample Total Time 0.06900\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06887\tTrain Loss 0.3812\t\n",
      "Epoch: [1][550/654]\tPer Sample Total Time 0.06893\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06881\tTrain Loss 0.3621\t\n",
      "Epoch: [1][600/654]\tPer Sample Total Time 0.06886\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06875\tTrain Loss 0.3435\t\n",
      "Epoch: [1][650/654]\tPer Sample Total Time 0.06883\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06872\tTrain Loss 0.3297\t\n",
      "start validation\n",
      "acc: 0.888514\n",
      "AUC: 0.987904\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.187742\n",
      "train_loss: 0.329149\n",
      "valid_loss: 1.780273\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 566.225\n",
      "---------------\n",
      "2025-12-12 11:47:16.318846\n",
      "current #epochs=2, #steps=654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][46/654]\tPer Sample Total Time 0.06965\tPer Sample Data Time 0.00122\tPer Sample DNN Time 0.06843\tTrain Loss 0.0740\t\n",
      "Epoch: [2][96/654]\tPer Sample Total Time 0.06887\tPer Sample Data Time 0.00061\tPer Sample DNN Time 0.06826\tTrain Loss 0.0648\t\n",
      "Epoch: [2][146/654]\tPer Sample Total Time 0.06857\tPer Sample Data Time 0.00041\tPer Sample DNN Time 0.06816\tTrain Loss 0.0703\t\n",
      "Epoch: [2][196/654]\tPer Sample Total Time 0.06852\tPer Sample Data Time 0.00031\tPer Sample DNN Time 0.06820\tTrain Loss 0.0703\t\n",
      "Epoch: [2][246/654]\tPer Sample Total Time 0.06841\tPer Sample Data Time 0.00026\tPer Sample DNN Time 0.06816\tTrain Loss 0.0681\t\n",
      "Epoch: [2][296/654]\tPer Sample Total Time 0.06833\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.06812\tTrain Loss 0.0720\t\n",
      "Epoch: [2][346/654]\tPer Sample Total Time 0.06829\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06810\tTrain Loss 0.0715\t\n",
      "Epoch: [2][396/654]\tPer Sample Total Time 0.06825\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06808\tTrain Loss 0.0716\t\n",
      "Epoch: [2][446/654]\tPer Sample Total Time 0.06823\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06807\tTrain Loss 0.0759\t\n",
      "Epoch: [2][496/654]\tPer Sample Total Time 0.06820\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06806\tTrain Loss 0.0774\t\n",
      "Epoch: [2][546/654]\tPer Sample Total Time 0.06817\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06804\tTrain Loss 0.0738\t\n",
      "Epoch: [2][596/654]\tPer Sample Total Time 0.06814\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06802\tTrain Loss 0.0720\t\n",
      "Epoch: [2][646/654]\tPer Sample Total Time 0.06813\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06801\tTrain Loss 0.0737\t\n",
      "start validation\n",
      "acc: 0.853604\n",
      "AUC: 0.989144\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.246131\n",
      "train_loss: 0.074387\n",
      "valid_loss: 1.789062\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 559.667\n",
      "---------------\n",
      "2025-12-12 11:56:35.985632\n",
      "current #epochs=3, #steps=1308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][42/654]\tPer Sample Total Time 0.06961\tPer Sample Data Time 0.00146\tPer Sample DNN Time 0.06815\tTrain Loss 0.0645\t\n",
      "Epoch: [3][92/654]\tPer Sample Total Time 0.06864\tPer Sample Data Time 0.00069\tPer Sample DNN Time 0.06795\tTrain Loss 0.0564\t\n",
      "Epoch: [3][142/654]\tPer Sample Total Time 0.06841\tPer Sample Data Time 0.00046\tPer Sample DNN Time 0.06795\tTrain Loss 0.0525\t\n",
      "Epoch: [3][192/654]\tPer Sample Total Time 0.06826\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.06791\tTrain Loss 0.0536\t\n",
      "Epoch: [3][242/654]\tPer Sample Total Time 0.06817\tPer Sample Data Time 0.00028\tPer Sample DNN Time 0.06789\tTrain Loss 0.0483\t\n",
      "Epoch: [3][292/654]\tPer Sample Total Time 0.06810\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.06786\tTrain Loss 0.0473\t\n",
      "Epoch: [3][342/654]\tPer Sample Total Time 0.06807\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.06786\tTrain Loss 0.0455\t\n",
      "Epoch: [3][392/654]\tPer Sample Total Time 0.06805\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06787\tTrain Loss 0.0465\t\n",
      "Epoch: [3][442/654]\tPer Sample Total Time 0.06803\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06786\tTrain Loss 0.0470\t\n",
      "Epoch: [3][492/654]\tPer Sample Total Time 0.06800\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06784\tTrain Loss 0.0500\t\n",
      "Epoch: [3][542/654]\tPer Sample Total Time 0.06799\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06784\tTrain Loss 0.0517\t\n",
      "Epoch: [3][592/654]\tPer Sample Total Time 0.06799\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06785\tTrain Loss 0.0503\t\n",
      "Epoch: [3][642/654]\tPer Sample Total Time 0.06796\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06784\tTrain Loss 0.0518\t\n",
      "start validation\n",
      "acc: 0.885135\n",
      "AUC: 0.988881\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.233271\n",
      "train_loss: 0.051457\n",
      "valid_loss: 1.769531\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 558.445\n",
      "Running fold 3: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_3.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_3.json --exp-dir /kaggle/working/ast/urban8k_exp/fold3 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain True --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 8646, running on 22c3b1e9ac95: starting (Fri Dec 12 12:05:58 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold3\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7ba1648a2990>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 12:06:00.768760\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/651]\tPer Sample Total Time 0.07346\tPer Sample Data Time 0.00108\tPer Sample DNN Time 0.07238\tTrain Loss 1.4164\t\n",
      "Epoch: [1][100/651]\tPer Sample Total Time 0.07100\tPer Sample Data Time 0.00056\tPer Sample DNN Time 0.07044\tTrain Loss 0.9922\t\n",
      "Epoch: [1][150/651]\tPer Sample Total Time 0.07037\tPer Sample Data Time 0.00039\tPer Sample DNN Time 0.06998\tTrain Loss 0.7733\t\n",
      "Epoch: [1][200/651]\tPer Sample Total Time 0.06997\tPer Sample Data Time 0.00030\tPer Sample DNN Time 0.06967\tTrain Loss 0.6520\t\n",
      "Epoch: [1][250/651]\tPer Sample Total Time 0.06975\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.06951\tTrain Loss 0.5817\t\n",
      "Epoch: [1][300/651]\tPer Sample Total Time 0.06961\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.06940\tTrain Loss 0.5259\t\n",
      "Epoch: [1][350/651]\tPer Sample Total Time 0.06950\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.06931\tTrain Loss 0.4773\t\n",
      "Epoch: [1][400/651]\tPer Sample Total Time 0.06940\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.06923\tTrain Loss 0.4398\t\n",
      "Epoch: [1][450/651]\tPer Sample Total Time 0.06934\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06919\tTrain Loss 0.4084\t\n",
      "Epoch: [1][500/651]\tPer Sample Total Time 0.06928\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06914\tTrain Loss 0.3830\t\n",
      "Epoch: [1][550/651]\tPer Sample Total Time 0.06922\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06910\tTrain Loss 0.3599\t\n",
      "Epoch: [1][600/651]\tPer Sample Total Time 0.06918\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06906\tTrain Loss 0.3379\t\n",
      "Epoch: [1][650/651]\tPer Sample Total Time 0.06917\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06906\tTrain Loss 0.3226\t\n",
      "start validation\n",
      "acc: 0.769730\n",
      "AUC: 0.975217\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.777073\n",
      "train_loss: 0.322606\n",
      "valid_loss: 1.817383\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 567.606\n",
      "---------------\n",
      "2025-12-12 12:15:28.375275\n",
      "current #epochs=2, #steps=651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][49/651]\tPer Sample Total Time 0.06986\tPer Sample Data Time 0.00102\tPer Sample DNN Time 0.06883\tTrain Loss 0.0901\t\n",
      "Epoch: [2][99/651]\tPer Sample Total Time 0.06914\tPer Sample Data Time 0.00053\tPer Sample DNN Time 0.06861\tTrain Loss 0.0968\t\n",
      "Epoch: [2][149/651]\tPer Sample Total Time 0.06900\tPer Sample Data Time 0.00036\tPer Sample DNN Time 0.06864\tTrain Loss 0.0824\t\n",
      "Epoch: [2][199/651]\tPer Sample Total Time 0.06886\tPer Sample Data Time 0.00028\tPer Sample DNN Time 0.06858\tTrain Loss 0.0762\t\n",
      "Epoch: [2][249/651]\tPer Sample Total Time 0.06872\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.06849\tTrain Loss 0.0749\t\n",
      "Epoch: [2][299/651]\tPer Sample Total Time 0.06867\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.06847\tTrain Loss 0.0676\t\n",
      "Epoch: [2][349/651]\tPer Sample Total Time 0.06860\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06843\tTrain Loss 0.0702\t\n",
      "Epoch: [2][399/651]\tPer Sample Total Time 0.06861\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06846\tTrain Loss 0.0753\t\n",
      "Epoch: [2][449/651]\tPer Sample Total Time 0.06859\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06845\tTrain Loss 0.0770\t\n",
      "Epoch: [2][499/651]\tPer Sample Total Time 0.06859\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06846\tTrain Loss 0.0773\t\n",
      "Epoch: [2][549/651]\tPer Sample Total Time 0.06859\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06847\tTrain Loss 0.0793\t\n",
      "Epoch: [2][599/651]\tPer Sample Total Time 0.06857\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06846\tTrain Loss 0.0794\t\n",
      "Epoch: [2][649/651]\tPer Sample Total Time 0.06856\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06845\tTrain Loss 0.0783\t\n",
      "start validation\n",
      "acc: 0.766486\n",
      "AUC: 0.978021\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.848930\n",
      "train_loss: 0.078237\n",
      "valid_loss: 1.794922\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 561.692\n",
      "---------------\n",
      "2025-12-12 12:24:50.067425\n",
      "current #epochs=3, #steps=1302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][48/651]\tPer Sample Total Time 0.06966\tPer Sample Data Time 0.00101\tPer Sample DNN Time 0.06865\tTrain Loss 0.0562\t\n",
      "Epoch: [3][98/651]\tPer Sample Total Time 0.06905\tPer Sample Data Time 0.00052\tPer Sample DNN Time 0.06853\tTrain Loss 0.0503\t\n",
      "Epoch: [3][148/651]\tPer Sample Total Time 0.06873\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.06838\tTrain Loss 0.0448\t\n",
      "Epoch: [3][198/651]\tPer Sample Total Time 0.06870\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.06842\tTrain Loss 0.0398\t\n",
      "Epoch: [3][248/651]\tPer Sample Total Time 0.06859\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.06837\tTrain Loss 0.0423\t\n",
      "Epoch: [3][298/651]\tPer Sample Total Time 0.06850\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06831\tTrain Loss 0.0443\t\n",
      "Epoch: [3][348/651]\tPer Sample Total Time 0.06846\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06830\tTrain Loss 0.0478\t\n",
      "Epoch: [3][398/651]\tPer Sample Total Time 0.06845\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06830\tTrain Loss 0.0467\t\n",
      "Epoch: [3][448/651]\tPer Sample Total Time 0.06839\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06826\tTrain Loss 0.0480\t\n",
      "Epoch: [3][498/651]\tPer Sample Total Time 0.06836\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06823\tTrain Loss 0.0507\t\n",
      "Epoch: [3][548/651]\tPer Sample Total Time 0.06834\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06822\tTrain Loss 0.0505\t\n",
      "Epoch: [3][598/651]\tPer Sample Total Time 0.06834\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06823\tTrain Loss 0.0505\t\n",
      "Epoch: [3][648/651]\tPer Sample Total Time 0.06832\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.06822\tTrain Loss 0.0502\t\n",
      "start validation\n",
      "acc: 0.775135\n",
      "AUC: 0.978625\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.865397\n",
      "train_loss: 0.050161\n",
      "valid_loss: 1.800781\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 561.693\n",
      "Running fold 4: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_4.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_4.json --exp-dir /kaggle/working/ast/urban8k_exp/fold4 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain True --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 12916, running on 22c3b1e9ac95: starting (Fri Dec 12 12:34:16 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold4\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7e9de28dddd0>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 12:34:18.296002\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/646]\tPer Sample Total Time 0.07451\tPer Sample Data Time 0.00099\tPer Sample DNN Time 0.07351\tTrain Loss 1.3749\t\n",
      "Epoch: [1][100/646]\tPer Sample Total Time 0.07168\tPer Sample Data Time 0.00052\tPer Sample DNN Time 0.07116\tTrain Loss 0.9473\t\n",
      "Epoch: [1][150/646]\tPer Sample Total Time 0.07096\tPer Sample Data Time 0.00036\tPer Sample DNN Time 0.07061\tTrain Loss 0.7587\t\n",
      "Epoch: [1][200/646]\tPer Sample Total Time 0.07051\tPer Sample Data Time 0.00028\tPer Sample DNN Time 0.07024\tTrain Loss 0.6484\t\n",
      "Epoch: [1][250/646]\tPer Sample Total Time 0.07024\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.07002\tTrain Loss 0.5723\t\n",
      "Epoch: [1][300/646]\tPer Sample Total Time 0.07007\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06987\tTrain Loss 0.5147\t\n",
      "Epoch: [1][350/646]\tPer Sample Total Time 0.06993\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06976\tTrain Loss 0.4736\t\n",
      "Epoch: [1][400/646]\tPer Sample Total Time 0.06982\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06967\tTrain Loss 0.4357\t\n",
      "Epoch: [1][450/646]\tPer Sample Total Time 0.06976\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06962\tTrain Loss 0.4042\t\n",
      "Epoch: [1][500/646]\tPer Sample Total Time 0.06968\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06955\tTrain Loss 0.3782\t\n",
      "Epoch: [1][550/646]\tPer Sample Total Time 0.06960\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06948\tTrain Loss 0.3577\t\n",
      "Epoch: [1][600/646]\tPer Sample Total Time 0.06954\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06943\tTrain Loss 0.3405\t\n",
      "start validation\n",
      "acc: 0.838384\n",
      "AUC: 0.985895\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.103276\n",
      "train_loss: 0.329141\n",
      "valid_loss: 1.794922\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 567.576\n",
      "---------------\n",
      "2025-12-12 12:43:45.872500\n",
      "current #epochs=2, #steps=646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][4/646]\tPer Sample Total Time 0.07943\tPer Sample Data Time 0.00955\tPer Sample DNN Time 0.06988\tTrain Loss 0.1141\t\n",
      "Epoch: [2][54/646]\tPer Sample Total Time 0.06984\tPer Sample Data Time 0.00090\tPer Sample DNN Time 0.06894\tTrain Loss 0.1119\t\n",
      "Epoch: [2][104/646]\tPer Sample Total Time 0.06930\tPer Sample Data Time 0.00049\tPer Sample DNN Time 0.06881\tTrain Loss 0.0970\t\n",
      "Epoch: [2][154/646]\tPer Sample Total Time 0.06914\tPer Sample Data Time 0.00034\tPer Sample DNN Time 0.06880\tTrain Loss 0.0827\t\n",
      "Epoch: [2][204/646]\tPer Sample Total Time 0.06902\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.06875\tTrain Loss 0.0872\t\n",
      "Epoch: [2][254/646]\tPer Sample Total Time 0.06898\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.06875\tTrain Loss 0.0923\t\n",
      "Epoch: [2][304/646]\tPer Sample Total Time 0.06891\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06872\tTrain Loss 0.0894\t\n",
      "Epoch: [2][354/646]\tPer Sample Total Time 0.06885\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06868\tTrain Loss 0.0855\t\n",
      "Epoch: [2][404/646]\tPer Sample Total Time 0.06879\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06864\tTrain Loss 0.0833\t\n",
      "Epoch: [2][454/646]\tPer Sample Total Time 0.06877\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06863\tTrain Loss 0.0825\t\n",
      "Epoch: [2][504/646]\tPer Sample Total Time 0.06873\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06860\tTrain Loss 0.0814\t\n",
      "Epoch: [2][554/646]\tPer Sample Total Time 0.06870\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06858\tTrain Loss 0.0809\t\n",
      "Epoch: [2][604/646]\tPer Sample Total Time 0.06869\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06857\tTrain Loss 0.0803\t\n",
      "start validation\n",
      "acc: 0.905051\n",
      "AUC: 0.993616\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.521654\n",
      "train_loss: 0.078829\n",
      "valid_loss: 1.759766\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 561.607\n",
      "---------------\n",
      "2025-12-12 12:53:07.479309\n",
      "current #epochs=3, #steps=1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][8/646]\tPer Sample Total Time 0.07432\tPer Sample Data Time 0.00553\tPer Sample DNN Time 0.06878\tTrain Loss 0.0602\t\n",
      "Epoch: [3][58/646]\tPer Sample Total Time 0.06959\tPer Sample Data Time 0.00087\tPer Sample DNN Time 0.06872\tTrain Loss 0.0571\t\n",
      "Epoch: [3][108/646]\tPer Sample Total Time 0.06907\tPer Sample Data Time 0.00048\tPer Sample DNN Time 0.06859\tTrain Loss 0.0436\t\n",
      "Epoch: [3][158/646]\tPer Sample Total Time 0.06880\tPer Sample Data Time 0.00034\tPer Sample DNN Time 0.06846\tTrain Loss 0.0412\t\n",
      "Epoch: [3][208/646]\tPer Sample Total Time 0.06868\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.06841\tTrain Loss 0.0467\t\n",
      "Epoch: [3][258/646]\tPer Sample Total Time 0.06862\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.06840\tTrain Loss 0.0472\t\n",
      "Epoch: [3][308/646]\tPer Sample Total Time 0.06854\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06835\tTrain Loss 0.0538\t\n",
      "Epoch: [3][358/646]\tPer Sample Total Time 0.06849\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06832\tTrain Loss 0.0551\t\n",
      "Epoch: [3][408/646]\tPer Sample Total Time 0.06848\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06833\tTrain Loss 0.0544\t\n",
      "Epoch: [3][458/646]\tPer Sample Total Time 0.06845\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06831\tTrain Loss 0.0528\t\n",
      "Epoch: [3][508/646]\tPer Sample Total Time 0.06842\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06829\tTrain Loss 0.0532\t\n",
      "Epoch: [3][558/646]\tPer Sample Total Time 0.06841\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06829\tTrain Loss 0.0549\t\n",
      "Epoch: [3][608/646]\tPer Sample Total Time 0.06840\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06829\tTrain Loss 0.0558\t\n",
      "start validation\n",
      "acc: 0.906061\n",
      "AUC: 0.993125\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.484233\n",
      "train_loss: 0.055050\n",
      "valid_loss: 1.751953\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 559.425\n",
      "Running fold 5: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_5.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_5.json --exp-dir /kaggle/working/ast/urban8k_exp/fold5 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain True --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 17174, running on 22c3b1e9ac95: starting (Fri Dec 12 13:02:31 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold5\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7a52841977d0>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 13:02:33.712096\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/650]\tPer Sample Total Time 0.07456\tPer Sample Data Time 0.00099\tPer Sample DNN Time 0.07357\tTrain Loss 1.3771\t\n",
      "Epoch: [1][100/650]\tPer Sample Total Time 0.07179\tPer Sample Data Time 0.00051\tPer Sample DNN Time 0.07128\tTrain Loss 0.9386\t\n",
      "Epoch: [1][150/650]\tPer Sample Total Time 0.07100\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.07065\tTrain Loss 0.7561\t\n",
      "Epoch: [1][200/650]\tPer Sample Total Time 0.07054\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.07026\tTrain Loss 0.6493\t\n",
      "Epoch: [1][250/650]\tPer Sample Total Time 0.07031\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.07008\tTrain Loss 0.5625\t\n",
      "Epoch: [1][300/650]\tPer Sample Total Time 0.07012\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06993\tTrain Loss 0.5053\t\n",
      "Epoch: [1][350/650]\tPer Sample Total Time 0.06998\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06981\tTrain Loss 0.4618\t\n",
      "Epoch: [1][400/650]\tPer Sample Total Time 0.06987\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06972\tTrain Loss 0.4273\t\n",
      "Epoch: [1][450/650]\tPer Sample Total Time 0.06980\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06967\tTrain Loss 0.3989\t\n",
      "Epoch: [1][500/650]\tPer Sample Total Time 0.06971\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06959\tTrain Loss 0.3772\t\n",
      "Epoch: [1][550/650]\tPer Sample Total Time 0.06963\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06951\tTrain Loss 0.3560\t\n",
      "Epoch: [1][600/650]\tPer Sample Total Time 0.06955\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06944\tTrain Loss 0.3420\t\n",
      "start validation\n",
      "acc: 0.885684\n",
      "AUC: 0.986711\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.136230\n",
      "train_loss: 0.330844\n",
      "valid_loss: 1.805664\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 569.656\n",
      "---------------\n",
      "2025-12-12 13:12:03.368014\n",
      "current #epochs=2, #steps=650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/650]\tPer Sample Total Time 0.12411\tPer Sample Data Time 0.04890\tPer Sample DNN Time 0.07521\tTrain Loss 0.0274\t\n",
      "Epoch: [2][50/650]\tPer Sample Total Time 0.06988\tPer Sample Data Time 0.00099\tPer Sample DNN Time 0.06889\tTrain Loss 0.0760\t\n",
      "Epoch: [2][100/650]\tPer Sample Total Time 0.06924\tPer Sample Data Time 0.00051\tPer Sample DNN Time 0.06872\tTrain Loss 0.0695\t\n",
      "Epoch: [2][150/650]\tPer Sample Total Time 0.06910\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.06875\tTrain Loss 0.0798\t\n",
      "Epoch: [2][200/650]\tPer Sample Total Time 0.06894\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.06867\tTrain Loss 0.0817\t\n",
      "Epoch: [2][250/650]\tPer Sample Total Time 0.06887\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.06864\tTrain Loss 0.0805\t\n",
      "Epoch: [2][300/650]\tPer Sample Total Time 0.06882\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06863\tTrain Loss 0.0828\t\n",
      "Epoch: [2][350/650]\tPer Sample Total Time 0.06875\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06858\tTrain Loss 0.0868\t\n",
      "Epoch: [2][400/650]\tPer Sample Total Time 0.06869\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06854\tTrain Loss 0.0886\t\n",
      "Epoch: [2][450/650]\tPer Sample Total Time 0.06862\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06848\tTrain Loss 0.0887\t\n",
      "Epoch: [2][500/650]\tPer Sample Total Time 0.06859\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06846\tTrain Loss 0.0893\t\n",
      "Epoch: [2][550/650]\tPer Sample Total Time 0.06856\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06844\tTrain Loss 0.0868\t\n",
      "Epoch: [2][600/650]\tPer Sample Total Time 0.06853\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06842\tTrain Loss 0.0846\t\n",
      "start validation\n",
      "acc: 0.905983\n",
      "AUC: 0.994784\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.622014\n",
      "train_loss: 0.082446\n",
      "valid_loss: 1.774414\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 562.472\n",
      "---------------\n",
      "2025-12-12 13:21:25.839797\n",
      "current #epochs=3, #steps=1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/650]\tPer Sample Total Time 0.13092\tPer Sample Data Time 0.05805\tPer Sample DNN Time 0.07288\tTrain Loss 0.1105\t\n",
      "Epoch: [3][50/650]\tPer Sample Total Time 0.06980\tPer Sample Data Time 0.00117\tPer Sample DNN Time 0.06863\tTrain Loss 0.0613\t\n",
      "Epoch: [3][100/650]\tPer Sample Total Time 0.06882\tPer Sample Data Time 0.00061\tPer Sample DNN Time 0.06822\tTrain Loss 0.0603\t\n",
      "Epoch: [3][150/650]\tPer Sample Total Time 0.06861\tPer Sample Data Time 0.00041\tPer Sample DNN Time 0.06819\tTrain Loss 0.0698\t\n",
      "Epoch: [3][200/650]\tPer Sample Total Time 0.06847\tPer Sample Data Time 0.00032\tPer Sample DNN Time 0.06815\tTrain Loss 0.0622\t\n",
      "Epoch: [3][250/650]\tPer Sample Total Time 0.06838\tPer Sample Data Time 0.00026\tPer Sample DNN Time 0.06812\tTrain Loss 0.0589\t\n",
      "Epoch: [3][300/650]\tPer Sample Total Time 0.06828\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.06805\tTrain Loss 0.0545\t\n",
      "Epoch: [3][350/650]\tPer Sample Total Time 0.06824\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.06804\tTrain Loss 0.0565\t\n",
      "Epoch: [3][400/650]\tPer Sample Total Time 0.06819\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.06802\tTrain Loss 0.0545\t\n",
      "Epoch: [3][450/650]\tPer Sample Total Time 0.06818\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.06802\tTrain Loss 0.0537\t\n",
      "Epoch: [3][500/650]\tPer Sample Total Time 0.06815\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06801\tTrain Loss 0.0531\t\n",
      "Epoch: [3][550/650]\tPer Sample Total Time 0.06813\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06799\tTrain Loss 0.0534\t\n",
      "Epoch: [3][600/650]\tPer Sample Total Time 0.06811\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06799\tTrain Loss 0.0544\t\n",
      "start validation\n",
      "acc: 0.865385\n",
      "AUC: 0.985859\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.101872\n",
      "train_loss: 0.053715\n",
      "valid_loss: 1.799805\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 557.628\n",
      "Fold 1: best val acc 0.8511\n",
      "Fold 2: best val acc 0.8885\n",
      "Fold 3: best val acc 0.7751\n",
      "Fold 4: best val acc 0.9061\n",
      "Fold 5: best val acc 0.9060\n",
      "10-fold mean acc: 0.8654 +/- 0.0494\n"
     ]
    }
   ],
   "source": [
    "# Kick off full 10-fold: each fold is held out as test once\n",
    "folds_to_run = list(range(1, 6))\n",
    "for f in folds_to_run:\n",
    "    run_fold(f)\n",
    "\n",
    "# Aggregate best validation accuracy per fold (col 0 of result.csv)\n",
    "fold_acc = []\n",
    "for f in folds_to_run:\n",
    "    res_path = REPO_DIR / 'urban8k_exp' / f'fold{f}' / 'result.csv'\n",
    "    arr = np.loadtxt(res_path, delimiter=',')\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr[None, :]\n",
    "    best_acc = float(arr[:, 0].max())\n",
    "    fold_acc.append(best_acc)\n",
    "    print(f'Fold {f}: best val acc {best_acc:.4f}')\n",
    "\n",
    "mean_acc = float(np.mean(fold_acc))\n",
    "std_acc = float(np.std(fold_acc))\n",
    "print(f'10-fold mean acc: {mean_acc:.4f} +/- {std_acc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 500970,
     "sourceId": 928025,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8561.692291,
   "end_time": "2025-12-12T13:30:46.039482",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-12T11:08:04.347191",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
