{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-12T11:47:17.634901Z",
     "iopub.status.busy": "2025-12-12T11:47:17.634675Z",
     "iopub.status.idle": "2025-12-12T11:48:48.391315Z",
     "shell.execute_reply": "2025-12-12T11:48:48.390599Z",
     "shell.execute_reply.started": "2025-12-12T11:47:17.634883Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing /kaggle/input ...\n",
      "Device: cuda\n",
      "[*INFO] Installing libraries...\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 287.4/287.4 kB 10.6 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 304.8 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 293.9 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 311.1 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 381.7 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 269.5 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 267.0 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 211.7 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 261.8 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 159.2 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 157.2 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*INFO] Cleaning up memory after installation...\n",
      "[*INFO] Cloning AST repo ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/ast'...\n",
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# secret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "# from huggingface_hub import HfApi, login\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import sys\n",
    "import subprocess\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "# AST Fine-tuning on UrbanSound8K (Kaggle version)\n",
    "# - Auto-detect UrbanSound8K in /kaggle/input\n",
    "# - Clone AST repo into /kaggle/working/ast\n",
    "# - Download AudioSet checkpoint\n",
    "# - 10-fold cross-validation training\n",
    "\n",
    "\n",
    "# 0. ENV INFO & SEED\n",
    "\n",
    "print(\"Listing /kaggle/input ...\")\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "# 1. INSTALL REQUIRED LIBRARIES (if needed)\n",
    "\n",
    "import gc # <--- Import thư viện dọn rác\n",
    "\n",
    "def pip_install(package):\n",
    "    # Thêm \"--no-cache-dir\" để không ngốn RAM lưu file tạm\n",
    "    # Thêm \"-q\" (quiet) để giảm log in ra màn hình\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"-q\", package])\n",
    "\n",
    "print(\"[*INFO] Installing libraries...\")\n",
    "# timm==0.4.5 là bản được AST repo dùng\n",
    "pip_install(\"timm==0.4.5\")\n",
    "pip_install(\"wget\")\n",
    "pip_install(\"librosa\")\n",
    "\n",
    "\n",
    "print(\"[*INFO] Cleaning up memory after installation...\")\n",
    "gc.collect() \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "# ======================================================\n",
    "\n",
    "import timm\n",
    "import wget\n",
    "\n",
    "\n",
    "# 2. CLONE AST REPO VÀ IMPORT ASTModel\n",
    "\n",
    "REPO_DIR = \"/kaggle/working/ast\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print(\"[*INFO] Cloning AST repo ...\")\n",
    "    subprocess.check_call([\"git\", \"clone\", \"https://github.com/YuanGongND/ast\", REPO_DIR])\n",
    "else:\n",
    "    print(\"[*INFO] AST repo already exists at\", REPO_DIR)\n",
    "\n",
    "sys.path.append(REPO_DIR)\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "from src.models import ASTModel  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:48:48.393039Z",
     "iopub.status.busy": "2025-12-12T11:48:48.392716Z",
     "iopub.status.idle": "2025-12-12T11:48:54.943528Z",
     "shell.execute_reply": "2025-12-12T11:48:54.942912Z",
     "shell.execute_reply.started": "2025-12-12T11:48:48.393021Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*INFO] Found UrbanSound8K.csv at: /kaggle/input/urbansound8k/UrbanSound8K.csv\n",
      "[*INFO] Sample row -> fold=5, fname=100032-3-0-0.wav\n",
      "[*INFO] AUDIO_ROOT detected as: /kaggle/input/urbansound8k\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. TÌM METADATA CSV UrbanSound8K\n",
    "\n",
    "US8K_META_PATH = None\n",
    "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "    if \"UrbanSound8K.csv\" in files:\n",
    "        US8K_META_PATH = os.path.join(root, \"UrbanSound8K.csv\")\n",
    "        break\n",
    "\n",
    "if US8K_META_PATH is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Không tìm thấy UrbanSound8K.csv trong /kaggle/input. \"\n",
    "        \"Kiểm tra lại dataset UrbanSound8K đã add vào notebook.\"\n",
    "    )\n",
    "\n",
    "print(\"[*INFO] Found UrbanSound8K.csv at:\", US8K_META_PATH)\n",
    "METADATA_CSV = US8K_META_PATH\n",
    "\n",
    "# 4. TÌM CHÍNH XÁC AUDIO_ROOT BẰNG CÁCH DÒ FILE THẬT\n",
    "\n",
    "df_meta = pd.read_csv(METADATA_CSV)\n",
    "sample_row = df_meta.iloc[0]\n",
    "sample_fname = sample_row[\"slice_file_name\"]\n",
    "sample_fold = sample_row[\"fold\"]\n",
    "target_fold_dir = f\"fold{sample_fold}\"\n",
    "\n",
    "print(f\"[*INFO] Sample row -> fold={sample_fold}, fname={sample_fname}\")\n",
    "\n",
    "AUDIO_ROOT = None\n",
    "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "    if os.path.basename(root) == target_fold_dir and sample_fname in files:\n",
    "        # root = .../audio/foldX\n",
    "        AUDIO_ROOT = os.path.dirname(root)  # bỏ /foldX\n",
    "        break\n",
    "\n",
    "if AUDIO_ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Không tìm thấy thư mục audio chứa fold{sample_fold} và file {sample_fname} trong /kaggle/input.\"\n",
    "    )\n",
    "\n",
    "print(\"[*INFO] AUDIO_ROOT detected as:\", AUDIO_ROOT)\n",
    "\n",
    "# Thư mục lưu checkpoint\n",
    "CKPT_DIR = \"/kaggle/working/ast_us8k_checkpoints\"\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:48:54.944423Z",
     "iopub.status.busy": "2025-12-12T11:48:54.944218Z",
     "iopub.status.idle": "2025-12-12T11:48:54.948190Z",
     "shell.execute_reply": "2025-12-12T11:48:54.947455Z",
     "shell.execute_reply.started": "2025-12-12T11:48:54.944404Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/urbansound8k\n"
     ]
    }
   ],
   "source": [
    "print(AUDIO_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:48:54.949854Z",
     "iopub.status.busy": "2025-12-12T11:48:54.948979Z",
     "iopub.status.idle": "2025-12-12T11:48:54.966032Z",
     "shell.execute_reply": "2025-12-12T11:48:54.965281Z",
     "shell.execute_reply.started": "2025-12-12T11:48:54.949829Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /kaggle/working/ast\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "try:\n",
    "    REPO_DIR\n",
    "except NameError:\n",
    "    REPO_DIR = Path('.').resolve()\n",
    "else:\n",
    "    REPO_DIR = Path(REPO_DIR)\n",
    "TORCH_HOME = REPO_DIR / 'pretrained_models'\n",
    "os.environ['TORCH_HOME'] = str(TORCH_HOME)\n",
    "TORCH_HOME.mkdir(exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Repo root:', REPO_DIR)\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:48:54.967142Z",
     "iopub.status.busy": "2025-12-12T11:48:54.966841Z",
     "iopub.status.idle": "2025-12-12T11:48:55.019196Z",
     "shell.execute_reply": "2025-12-12T11:48:55.018661Z",
     "shell.execute_reply.started": "2025-12-12T11:48:54.967116Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label CSV written to: /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv\n"
     ]
    }
   ],
   "source": [
    "# Build label CSV (index, mid, display_name)\n",
    "meta_df = pd.read_csv(METADATA_CSV)\n",
    "label_csv = REPO_DIR / 'urban8k_data' / 'urban8k_class_labels_indices.csv'\n",
    "label_csv.parent.mkdir(exist_ok=True)\n",
    "\n",
    "unique_classes = meta_df[['classID', 'class']].drop_duplicates().sort_values('classID')\n",
    "with open(label_csv, 'w') as f:\n",
    "    f.write('index,mid,display_name\\n')\n",
    "    for _, row in unique_classes.iterrows():\n",
    "        idx = int(row['classID'])\n",
    "        mid = f\"/m/urban{idx:02d}\"\n",
    "        name = row['class']\n",
    "        f.write(f\"{idx},{mid},{name}\\n\")\n",
    "\n",
    "print('Label CSV written to:', label_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:48:55.020103Z",
     "iopub.status.busy": "2025-12-12T11:48:55.019837Z",
     "iopub.status.idle": "2025-12-12T11:49:00.171435Z",
     "shell.execute_reply": "2025-12-12T11:49:00.170806Z",
     "shell.execute_reply.started": "2025-12-12T11:48:55.020084Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: train 7859, eval 873\n",
      "Fold 2: train 7844, eval 888\n",
      "Fold 3: train 7807, eval 925\n",
      "Fold 4: train 7742, eval 990\n",
      "Fold 5: train 7796, eval 936\n",
      "Fold 6: train 7909, eval 823\n",
      "Fold 7: train 7894, eval 838\n",
      "Fold 8: train 7926, eval 806\n",
      "Fold 9: train 7916, eval 816\n",
      "Fold 10: train 7895, eval 837\n"
     ]
    }
   ],
   "source": [
    "import json, shutil\n",
    "\n",
    "# Create JSON datafiles per fold (ESC-50 style)\n",
    "data_dir = REPO_DIR / 'urban8k_data' / 'datafiles'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def rows_for_df(df):\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        wav_path = Path(AUDIO_ROOT) / f\"fold{int(r['fold'])}\" / r['slice_file_name']\n",
    "        rows.append({\n",
    "            'wav': str(wav_path),\n",
    "            'labels': f\"/m/urban{int(r['classID']):02d}\"\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "for fold in range(1, 11):\n",
    "    train_df = meta_df[meta_df['fold'] != fold]\n",
    "    eval_df = meta_df[meta_df['fold'] == fold]\n",
    "    train_json = {'data': rows_for_df(train_df)}\n",
    "    eval_json = {'data': rows_for_df(eval_df)}\n",
    "    with open(data_dir / f'urban_train_data_{fold}.json', 'w') as f:\n",
    "        json.dump(train_json, f, indent=1)\n",
    "    with open(data_dir / f'urban_eval_data_{fold}.json', 'w') as f:\n",
    "        json.dump(eval_json, f, indent=1)\n",
    "    print(f'Fold {fold}: train {len(train_df)}, eval {len(eval_df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:49:00.173737Z",
     "iopub.status.busy": "2025-12-12T11:49:00.173472Z",
     "iopub.status.idle": "2025-12-12T11:49:00.182150Z",
     "shell.execute_reply": "2025-12-12T11:49:00.181569Z",
     "shell.execute_reply.started": "2025-12-12T11:49:00.173718Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mean/std: -1.7362523965764032 3.2758855893221015\n"
     ]
    }
   ],
   "source": [
    "# Compute dataset mean/std over fbank features (optional; default uses AudioSet stats)\n",
    "import torchaudio\n",
    "\n",
    "def compute_norm_stats(df, target_length=1024, mel_bins=128, target_sr=16000, max_files=None):\n",
    "    total = 0.0\n",
    "    total_sq = 0.0\n",
    "    count = 0\n",
    "    rows = df if max_files is None else df.sample(n=max_files, random_state=SEED)\n",
    "    for _, r in rows.iterrows():\n",
    "        wav_path = Path(AUDIO_ROOT) / f\"fold{int(r['fold'])}\" / r['slice_file_name']\n",
    "        wav, sr = torchaudio.load(str(wav_path))\n",
    "        if wav.shape[0] > 1:\n",
    "            wav = wav.mean(dim=0, keepdim=True)\n",
    "        if sr != target_sr:\n",
    "            wav = torchaudio.transforms.Resample(sr, target_sr)(wav)\n",
    "            sr = target_sr\n",
    "        fb = torchaudio.compliance.kaldi.fbank(\n",
    "            wav, htk_compat=True, sample_frequency=sr, use_energy=False,\n",
    "            window_type='hanning', num_mel_bins=mel_bins, dither=0.0, frame_shift=10\n",
    "        )\n",
    "        p = target_length - fb.shape[0]\n",
    "        if p > 0:\n",
    "            fb = torch.nn.functional.pad(fb, (0, 0, 0, p))\n",
    "        elif p < 0:\n",
    "            fb = fb[:target_length, :]\n",
    "        total += fb.sum().item()\n",
    "        total_sq += (fb ** 2).sum().item()\n",
    "        count += fb.numel()\n",
    "    mean = total / count\n",
    "    var = total_sq / count - mean ** 2\n",
    "    std = var ** 0.5\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "try:\n",
    "    DATASET_MEAN\n",
    "    DATASET_STD\n",
    "except NameError:\n",
    "    DATASET_MEAN = -1.7362523965764032\n",
    "    DATASET_STD = 3.2758855893221015\n",
    "print('Using mean/std:', DATASET_MEAN, DATASET_STD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:49:00.183045Z",
     "iopub.status.busy": "2025-12-12T11:49:00.182799Z",
     "iopub.status.idle": "2025-12-12T11:49:01.634027Z",
     "shell.execute_reply": "2025-12-12T11:49:01.633379Z",
     "shell.execute_reply.started": "2025-12-12T11:49:00.183017Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH_HOME: /kaggle/pretrained_models\n",
      "Helper ready: run_fold(fold) to launch training\n"
     ]
    }
   ],
   "source": [
    "REPO_DIR = Path('.').resolve()\n",
    "PRETRAIN_DIR = (REPO_DIR / '../../pretrained_models').resolve()\n",
    "PRETRAIN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "os.environ['TORCH_HOME'] = str(PRETRAIN_DIR)\n",
    "print('TORCH_HOME:', PRETRAIN_DIR)\n",
    "# Helper to launch training via src/run.py with ESC-50-like hyperparameters\n",
    "def run_fold(fold, epochs=3, batch_size=12, lr=1e-5):\n",
    "    exp_dir = REPO_DIR / 'urban8k_exp' / f'fold{fold}'\n",
    "    if exp_dir.exists():\n",
    "        shutil.rmtree(exp_dir)\n",
    "    exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    train_json = data_dir / f'urban_train_data_{fold}.json'\n",
    "    eval_json = data_dir / f'urban_eval_data_{fold}.json'\n",
    "\n",
    "    cmd = [\n",
    "        sys.executable, 'src/run.py',\n",
    "        '--model', 'ast',\n",
    "        '--dataset', 'urban8k',\n",
    "        '--data-train', str(train_json),\n",
    "        '--data-val', str(eval_json),\n",
    "        '--exp-dir', str(exp_dir),\n",
    "        '--label-csv', str(label_csv),\n",
    "        '--n_class', '10',\n",
    "        '--lr', str(lr),\n",
    "        '--n-epochs', str(epochs),\n",
    "        '--batch-size', str(batch_size),\n",
    "        '--save_model', 'False',\n",
    "        '--freqm', '24',\n",
    "        '--timem', '96',\n",
    "        '--mixup', '0',\n",
    "        '--bal', 'none',\n",
    "        '--tstride', '10', '--fstride', '10',\n",
    "        '--imagenet_pretrain', 'True',\n",
    "        '--audioset_pretrain', 'False',\n",
    "        '--metrics', 'acc',\n",
    "        '--loss', 'CE',\n",
    "        '--warmup', 'False',\n",
    "        '--lrscheduler_start', '5',\n",
    "        '--lrscheduler_step', '1',\n",
    "        '--lrscheduler_decay', '0.85',\n",
    "        '--dataset_mean', str(DATASET_MEAN),\n",
    "        '--dataset_std', str(DATASET_STD),\n",
    "        '--audio_length', '1024',\n",
    "        '--noise', 'False',\n",
    "        '--num-workers', '4',\n",
    "        '--n-print-steps', '50'\n",
    "    ]\n",
    "    env = os.environ.copy()\n",
    "    env['TORCH_HOME'] = str(TORCH_HOME)\n",
    "    print(f'Running fold {fold}:', ' '.join(cmd))\n",
    "    subprocess.check_call(cmd, env=env, cwd=REPO_DIR)\n",
    "\n",
    "print('Helper ready: run_fold(fold) to launch training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:49:01.635103Z",
     "iopub.status.busy": "2025-12-12T11:49:01.634848Z",
     "iopub.status.idle": "2025-12-12T14:11:40.670371Z",
     "shell.execute_reply": "2025-12-12T14:11:40.669697Z",
     "shell.execute_reply.started": "2025-12-12T11:49:01.635078Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 6: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_6.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_6.json --exp-dir /kaggle/working/ast/urban8k_exp/fold6 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain False --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_384-d0272ac0.pth\" to ../../pretrained_models/hub/checkpoints/deit_base_distilled_patch16_384-d0272ac0.pth\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 133, running on 8b7e52d8b72d: starting (Fri Dec 12 11:49:05 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: False\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold6\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7dd74b2c0650>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 11:49:08.609094\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/660]\tPer Sample Total Time 0.06827\tPer Sample Data Time 0.00160\tPer Sample DNN Time 0.06666\tTrain Loss 1.7765\t\n",
      "Epoch: [1][100/660]\tPer Sample Total Time 0.06689\tPer Sample Data Time 0.00082\tPer Sample DNN Time 0.06607\tTrain Loss 1.4574\t\n",
      "Epoch: [1][150/660]\tPer Sample Total Time 0.06759\tPer Sample Data Time 0.00056\tPer Sample DNN Time 0.06703\tTrain Loss 1.2651\t\n",
      "Epoch: [1][200/660]\tPer Sample Total Time 0.06780\tPer Sample Data Time 0.00043\tPer Sample DNN Time 0.06737\tTrain Loss 1.1111\t\n",
      "Epoch: [1][250/660]\tPer Sample Total Time 0.06799\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.06764\tTrain Loss 1.0101\t\n",
      "Epoch: [1][300/660]\tPer Sample Total Time 0.06810\tPer Sample Data Time 0.00030\tPer Sample DNN Time 0.06780\tTrain Loss 0.9232\t\n",
      "Epoch: [1][350/660]\tPer Sample Total Time 0.06814\tPer Sample Data Time 0.00026\tPer Sample DNN Time 0.06788\tTrain Loss 0.8582\t\n",
      "Epoch: [1][400/660]\tPer Sample Total Time 0.06821\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.06798\tTrain Loss 0.8095\t\n",
      "Epoch: [1][450/660]\tPer Sample Total Time 0.06827\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.06806\tTrain Loss 0.7574\t\n",
      "Epoch: [1][500/660]\tPer Sample Total Time 0.06828\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06809\tTrain Loss 0.7121\t\n",
      "Epoch: [1][550/660]\tPer Sample Total Time 0.06830\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.06812\tTrain Loss 0.6748\t\n",
      "Epoch: [1][600/660]\tPer Sample Total Time 0.06833\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.06817\tTrain Loss 0.6432\t\n",
      "Epoch: [1][650/660]\tPer Sample Total Time 0.06834\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06819\tTrain Loss 0.6148\t\n",
      "start validation\n",
      "acc: 0.761847\n",
      "AUC: 0.933356\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.123105\n",
      "train_loss: 0.610624\n",
      "valid_loss: 1.862305\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 565.759\n",
      "---------------\n",
      "2025-12-12 11:58:34.367870\n",
      "current #epochs=2, #steps=660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][40/660]\tPer Sample Total Time 0.06973\tPer Sample Data Time 0.00119\tPer Sample DNN Time 0.06854\tTrain Loss 0.2076\t\n",
      "Epoch: [2][90/660]\tPer Sample Total Time 0.06906\tPer Sample Data Time 0.00055\tPer Sample DNN Time 0.06851\tTrain Loss 0.2175\t\n",
      "Epoch: [2][140/660]\tPer Sample Total Time 0.06886\tPer Sample Data Time 0.00037\tPer Sample DNN Time 0.06849\tTrain Loss 0.2191\t\n",
      "Epoch: [2][190/660]\tPer Sample Total Time 0.06870\tPer Sample Data Time 0.00028\tPer Sample DNN Time 0.06842\tTrain Loss 0.2182\t\n",
      "Epoch: [2][240/660]\tPer Sample Total Time 0.06861\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.06838\tTrain Loss 0.2216\t\n",
      "Epoch: [2][290/660]\tPer Sample Total Time 0.06856\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06836\tTrain Loss 0.2107\t\n",
      "Epoch: [2][340/660]\tPer Sample Total Time 0.06856\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06839\tTrain Loss 0.2062\t\n",
      "Epoch: [2][390/660]\tPer Sample Total Time 0.06856\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06841\tTrain Loss 0.2078\t\n",
      "Epoch: [2][440/660]\tPer Sample Total Time 0.06856\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06842\tTrain Loss 0.2011\t\n",
      "Epoch: [2][490/660]\tPer Sample Total Time 0.06855\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06842\tTrain Loss 0.1912\t\n",
      "Epoch: [2][540/660]\tPer Sample Total Time 0.06855\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06843\tTrain Loss 0.1911\t\n",
      "Epoch: [2][590/660]\tPer Sample Total Time 0.06852\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06841\tTrain Loss 0.1890\t\n",
      "Epoch: [2][640/660]\tPer Sample Total Time 0.06851\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.06840\tTrain Loss 0.1883\t\n",
      "start validation\n",
      "acc: 0.797084\n",
      "AUC: 0.950146\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.328182\n",
      "train_loss: 0.187696\n",
      "valid_loss: 1.840820\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 567.449\n",
      "---------------\n",
      "2025-12-12 12:08:01.816968\n",
      "current #epochs=3, #steps=1320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][30/660]\tPer Sample Total Time 0.07067\tPer Sample Data Time 0.00169\tPer Sample DNN Time 0.06898\tTrain Loss 0.0687\t\n",
      "Epoch: [3][80/660]\tPer Sample Total Time 0.06934\tPer Sample Data Time 0.00067\tPer Sample DNN Time 0.06867\tTrain Loss 0.1023\t\n",
      "Epoch: [3][130/660]\tPer Sample Total Time 0.06893\tPer Sample Data Time 0.00042\tPer Sample DNN Time 0.06850\tTrain Loss 0.1097\t\n",
      "Epoch: [3][180/660]\tPer Sample Total Time 0.06875\tPer Sample Data Time 0.00032\tPer Sample DNN Time 0.06844\tTrain Loss 0.1146\t\n",
      "Epoch: [3][230/660]\tPer Sample Total Time 0.06872\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.06846\tTrain Loss 0.1050\t\n",
      "Epoch: [3][280/660]\tPer Sample Total Time 0.06867\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.06846\tTrain Loss 0.1015\t\n",
      "Epoch: [3][330/660]\tPer Sample Total Time 0.06863\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06845\tTrain Loss 0.0973\t\n",
      "Epoch: [3][380/660]\tPer Sample Total Time 0.06860\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06844\tTrain Loss 0.0978\t\n",
      "Epoch: [3][430/660]\tPer Sample Total Time 0.06858\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06843\tTrain Loss 0.0963\t\n",
      "Epoch: [3][480/660]\tPer Sample Total Time 0.06856\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06843\tTrain Loss 0.0982\t\n",
      "Epoch: [3][530/660]\tPer Sample Total Time 0.06855\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06842\tTrain Loss 0.0976\t\n",
      "Epoch: [3][580/660]\tPer Sample Total Time 0.06852\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06840\tTrain Loss 0.0981\t\n",
      "Epoch: [3][630/660]\tPer Sample Total Time 0.06851\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06840\tTrain Loss 0.0988\t\n",
      "start validation\n",
      "acc: 0.826245\n",
      "AUC: 0.947458\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.292009\n",
      "train_loss: 0.097906\n",
      "valid_loss: 1.839844\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 567.634\n",
      "Running fold 7: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_7.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_7.json --exp-dir /kaggle/working/ast/urban8k_exp/fold7 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain False --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 4433, running on 8b7e52d8b72d: starting (Fri Dec 12 12:17:34 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: False\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold7\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7bacec8a5e90>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 12:17:36.664360\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/658]\tPer Sample Total Time 0.07322\tPer Sample Data Time 0.00118\tPer Sample DNN Time 0.07204\tTrain Loss 1.8697\t\n",
      "Epoch: [1][100/658]\tPer Sample Total Time 0.07084\tPer Sample Data Time 0.00061\tPer Sample DNN Time 0.07023\tTrain Loss 1.5122\t\n",
      "Epoch: [1][150/658]\tPer Sample Total Time 0.07024\tPer Sample Data Time 0.00042\tPer Sample DNN Time 0.06982\tTrain Loss 1.2863\t\n",
      "Epoch: [1][200/658]\tPer Sample Total Time 0.06982\tPer Sample Data Time 0.00032\tPer Sample DNN Time 0.06950\tTrain Loss 1.1245\t\n",
      "Epoch: [1][250/658]\tPer Sample Total Time 0.06969\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.06942\tTrain Loss 1.0087\t\n",
      "Epoch: [1][300/658]\tPer Sample Total Time 0.06952\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.06930\tTrain Loss 0.9190\t\n",
      "Epoch: [1][350/658]\tPer Sample Total Time 0.06939\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.06919\tTrain Loss 0.8456\t\n",
      "Epoch: [1][400/658]\tPer Sample Total Time 0.06930\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.06912\tTrain Loss 0.7875\t\n",
      "Epoch: [1][450/658]\tPer Sample Total Time 0.06925\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.06909\tTrain Loss 0.7417\t\n",
      "Epoch: [1][500/658]\tPer Sample Total Time 0.06921\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06906\tTrain Loss 0.7066\t\n",
      "Epoch: [1][550/658]\tPer Sample Total Time 0.06916\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06902\tTrain Loss 0.6741\t\n",
      "Epoch: [1][600/658]\tPer Sample Total Time 0.06911\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06899\tTrain Loss 0.6423\t\n",
      "Epoch: [1][650/658]\tPer Sample Total Time 0.06907\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06895\tTrain Loss 0.6151\t\n",
      "start validation\n",
      "acc: 0.774463\n",
      "AUC: 0.975397\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.781483\n",
      "train_loss: 0.610340\n",
      "valid_loss: 1.847656\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 570.726\n",
      "---------------\n",
      "2025-12-12 12:27:07.390599\n",
      "current #epochs=2, #steps=658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][42/658]\tPer Sample Total Time 0.06985\tPer Sample Data Time 0.00108\tPer Sample DNN Time 0.06877\tTrain Loss 0.2191\t\n",
      "Epoch: [2][92/658]\tPer Sample Total Time 0.06928\tPer Sample Data Time 0.00052\tPer Sample DNN Time 0.06876\tTrain Loss 0.2197\t\n",
      "Epoch: [2][142/658]\tPer Sample Total Time 0.06891\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.06856\tTrain Loss 0.2282\t\n",
      "Epoch: [2][192/658]\tPer Sample Total Time 0.06875\tPer Sample Data Time 0.00026\tPer Sample DNN Time 0.06849\tTrain Loss 0.2196\t\n",
      "Epoch: [2][242/658]\tPer Sample Total Time 0.06872\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.06850\tTrain Loss 0.2105\t\n",
      "Epoch: [2][292/658]\tPer Sample Total Time 0.06870\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06851\tTrain Loss 0.2073\t\n",
      "Epoch: [2][342/658]\tPer Sample Total Time 0.06865\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.06848\tTrain Loss 0.2032\t\n",
      "Epoch: [2][392/658]\tPer Sample Total Time 0.06859\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06845\tTrain Loss 0.2055\t\n",
      "Epoch: [2][442/658]\tPer Sample Total Time 0.06854\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06841\tTrain Loss 0.1974\t\n",
      "Epoch: [2][492/658]\tPer Sample Total Time 0.06855\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06843\tTrain Loss 0.1928\t\n",
      "Epoch: [2][542/658]\tPer Sample Total Time 0.06854\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06843\tTrain Loss 0.1864\t\n",
      "Epoch: [2][592/658]\tPer Sample Total Time 0.06851\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06840\tTrain Loss 0.1798\t\n",
      "Epoch: [2][642/658]\tPer Sample Total Time 0.06851\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.06840\tTrain Loss 0.1761\t\n",
      "start validation\n",
      "acc: 0.837709\n",
      "AUC: 0.980338\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.914390\n",
      "train_loss: 0.175469\n",
      "valid_loss: 1.825195\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 567.317\n",
      "---------------\n",
      "2025-12-12 12:36:34.707842\n",
      "current #epochs=3, #steps=1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][34/658]\tPer Sample Total Time 0.07006\tPer Sample Data Time 0.00147\tPer Sample DNN Time 0.06859\tTrain Loss 0.1035\t\n",
      "Epoch: [3][84/658]\tPer Sample Total Time 0.06903\tPer Sample Data Time 0.00062\tPer Sample DNN Time 0.06841\tTrain Loss 0.0900\t\n",
      "Epoch: [3][134/658]\tPer Sample Total Time 0.06870\tPer Sample Data Time 0.00040\tPer Sample DNN Time 0.06829\tTrain Loss 0.1247\t\n",
      "Epoch: [3][184/658]\tPer Sample Total Time 0.06858\tPer Sample Data Time 0.00030\tPer Sample DNN Time 0.06828\tTrain Loss 0.1263\t\n",
      "Epoch: [3][234/658]\tPer Sample Total Time 0.06857\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.06833\tTrain Loss 0.1198\t\n",
      "Epoch: [3][284/658]\tPer Sample Total Time 0.06849\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.06829\tTrain Loss 0.1139\t\n",
      "Epoch: [3][334/658]\tPer Sample Total Time 0.06845\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.06827\tTrain Loss 0.1095\t\n",
      "Epoch: [3][384/658]\tPer Sample Total Time 0.06843\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.06827\tTrain Loss 0.1060\t\n",
      "Epoch: [3][434/658]\tPer Sample Total Time 0.06843\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06828\tTrain Loss 0.1050\t\n",
      "Epoch: [3][484/658]\tPer Sample Total Time 0.06842\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06829\tTrain Loss 0.1077\t\n",
      "Epoch: [3][534/658]\tPer Sample Total Time 0.06840\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06827\tTrain Loss 0.1066\t\n",
      "Epoch: [3][584/658]\tPer Sample Total Time 0.06837\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06825\tTrain Loss 0.1046\t\n",
      "Epoch: [3][634/658]\tPer Sample Total Time 0.06837\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06826\tTrain Loss 0.1051\t\n",
      "start validation\n",
      "acc: 0.865155\n",
      "AUC: 0.987153\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.154842\n",
      "train_loss: 0.103868\n",
      "valid_loss: 1.786133\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 566.076\n",
      "Running fold 8: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_8.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_8.json --exp-dir /kaggle/working/ast/urban8k_exp/fold8 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain False --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 8724, running on 8b7e52d8b72d: starting (Fri Dec 12 12:46:07 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: False\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold8\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7da8a8a6cd90>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 12:46:09.363319\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/661]\tPer Sample Total Time 0.07368\tPer Sample Data Time 0.00098\tPer Sample DNN Time 0.07269\tTrain Loss 1.8728\t\n",
      "Epoch: [1][100/661]\tPer Sample Total Time 0.07104\tPer Sample Data Time 0.00051\tPer Sample DNN Time 0.07053\tTrain Loss 1.5458\t\n",
      "Epoch: [1][150/661]\tPer Sample Total Time 0.07038\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.07002\tTrain Loss 1.3409\t\n",
      "Epoch: [1][200/661]\tPer Sample Total Time 0.06998\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.06971\tTrain Loss 1.1716\t\n",
      "Epoch: [1][250/661]\tPer Sample Total Time 0.06981\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.06958\tTrain Loss 1.0569\t\n",
      "Epoch: [1][300/661]\tPer Sample Total Time 0.06965\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06946\tTrain Loss 0.9711\t\n",
      "Epoch: [1][350/661]\tPer Sample Total Time 0.06949\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06932\tTrain Loss 0.9014\t\n",
      "Epoch: [1][400/661]\tPer Sample Total Time 0.06939\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06924\tTrain Loss 0.8455\t\n",
      "Epoch: [1][450/661]\tPer Sample Total Time 0.06933\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06919\tTrain Loss 0.7919\t\n",
      "Epoch: [1][500/661]\tPer Sample Total Time 0.06925\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06912\tTrain Loss 0.7471\t\n",
      "Epoch: [1][550/661]\tPer Sample Total Time 0.06920\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06908\tTrain Loss 0.7137\t\n",
      "Epoch: [1][600/661]\tPer Sample Total Time 0.06916\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06905\tTrain Loss 0.6796\t\n",
      "Epoch: [1][650/661]\tPer Sample Total Time 0.06912\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06901\tTrain Loss 0.6481\t\n",
      "start validation\n",
      "acc: 0.714640\n",
      "AUC: 0.916701\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 1.956161\n",
      "train_loss: 0.643731\n",
      "valid_loss: 1.910156\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 572.210\n",
      "---------------\n",
      "2025-12-12 12:55:41.573089\n",
      "current #epochs=2, #steps=661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][39/661]\tPer Sample Total Time 0.07007\tPer Sample Data Time 0.00144\tPer Sample DNN Time 0.06863\tTrain Loss 0.2991\t\n",
      "Epoch: [2][89/661]\tPer Sample Total Time 0.06921\tPer Sample Data Time 0.00066\tPer Sample DNN Time 0.06855\tTrain Loss 0.2421\t\n",
      "Epoch: [2][139/661]\tPer Sample Total Time 0.06898\tPer Sample Data Time 0.00043\tPer Sample DNN Time 0.06855\tTrain Loss 0.2159\t\n",
      "Epoch: [2][189/661]\tPer Sample Total Time 0.06886\tPer Sample Data Time 0.00033\tPer Sample DNN Time 0.06853\tTrain Loss 0.2089\t\n",
      "Epoch: [2][239/661]\tPer Sample Total Time 0.06876\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.06850\tTrain Loss 0.2121\t\n",
      "Epoch: [2][289/661]\tPer Sample Total Time 0.06869\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.06847\tTrain Loss 0.2088\t\n",
      "Epoch: [2][339/661]\tPer Sample Total Time 0.06865\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.06845\tTrain Loss 0.2044\t\n",
      "Epoch: [2][389/661]\tPer Sample Total Time 0.06862\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06845\tTrain Loss 0.2039\t\n",
      "Epoch: [2][439/661]\tPer Sample Total Time 0.06859\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.06843\tTrain Loss 0.2023\t\n",
      "Epoch: [2][489/661]\tPer Sample Total Time 0.06855\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06841\tTrain Loss 0.1962\t\n",
      "Epoch: [2][539/661]\tPer Sample Total Time 0.06856\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06843\tTrain Loss 0.1933\t\n",
      "Epoch: [2][589/661]\tPer Sample Total Time 0.06855\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06843\tTrain Loss 0.1938\t\n",
      "Epoch: [2][639/661]\tPer Sample Total Time 0.06853\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06842\tTrain Loss 0.1936\t\n",
      "start validation\n",
      "acc: 0.741935\n",
      "AUC: 0.931710\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.105265\n",
      "train_loss: 0.191130\n",
      "valid_loss: 1.882812\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 568.556\n",
      "---------------\n",
      "2025-12-12 13:05:10.128936\n",
      "current #epochs=3, #steps=1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][28/661]\tPer Sample Total Time 0.07045\tPer Sample Data Time 0.00180\tPer Sample DNN Time 0.06865\tTrain Loss 0.1211\t\n",
      "Epoch: [3][78/661]\tPer Sample Total Time 0.06940\tPer Sample Data Time 0.00068\tPer Sample DNN Time 0.06872\tTrain Loss 0.1371\t\n",
      "Epoch: [3][128/661]\tPer Sample Total Time 0.06897\tPer Sample Data Time 0.00043\tPer Sample DNN Time 0.06854\tTrain Loss 0.1363\t\n",
      "Epoch: [3][178/661]\tPer Sample Total Time 0.06879\tPer Sample Data Time 0.00032\tPer Sample DNN Time 0.06848\tTrain Loss 0.1283\t\n",
      "Epoch: [3][228/661]\tPer Sample Total Time 0.06872\tPer Sample Data Time 0.00026\tPer Sample DNN Time 0.06847\tTrain Loss 0.1278\t\n",
      "Epoch: [3][278/661]\tPer Sample Total Time 0.06863\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.06842\tTrain Loss 0.1340\t\n",
      "Epoch: [3][328/661]\tPer Sample Total Time 0.06860\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06841\tTrain Loss 0.1305\t\n",
      "Epoch: [3][378/661]\tPer Sample Total Time 0.06855\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06838\tTrain Loss 0.1233\t\n",
      "Epoch: [3][428/661]\tPer Sample Total Time 0.06853\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06838\tTrain Loss 0.1172\t\n",
      "Epoch: [3][478/661]\tPer Sample Total Time 0.06852\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06838\tTrain Loss 0.1123\t\n",
      "Epoch: [3][528/661]\tPer Sample Total Time 0.06850\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06838\tTrain Loss 0.1080\t\n",
      "Epoch: [3][578/661]\tPer Sample Total Time 0.06848\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06836\tTrain Loss 0.1090\t\n",
      "Epoch: [3][628/661]\tPer Sample Total Time 0.06847\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06836\tTrain Loss 0.1090\t\n",
      "start validation\n",
      "acc: 0.687345\n",
      "AUC: 0.950918\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.338858\n",
      "train_loss: 0.107302\n",
      "valid_loss: 1.861328\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 566.177\n",
      "Running fold 9: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_9.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_9.json --exp-dir /kaggle/working/ast/urban8k_exp/fold9 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain False --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 13024, running on 8b7e52d8b72d: starting (Fri Dec 12 13:14:41 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: False\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold9\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7cf592e2e390>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 13:14:42.931195\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/660]\tPer Sample Total Time 0.07338\tPer Sample Data Time 0.00105\tPer Sample DNN Time 0.07233\tTrain Loss 1.8391\t\n",
      "Epoch: [1][100/660]\tPer Sample Total Time 0.07106\tPer Sample Data Time 0.00054\tPer Sample DNN Time 0.07052\tTrain Loss 1.4263\t\n",
      "Epoch: [1][150/660]\tPer Sample Total Time 0.07044\tPer Sample Data Time 0.00037\tPer Sample DNN Time 0.07006\tTrain Loss 1.2056\t\n",
      "Epoch: [1][200/660]\tPer Sample Total Time 0.07005\tPer Sample Data Time 0.00029\tPer Sample DNN Time 0.06977\tTrain Loss 1.0567\t\n",
      "Epoch: [1][250/660]\tPer Sample Total Time 0.06982\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.06959\tTrain Loss 0.9621\t\n",
      "Epoch: [1][300/660]\tPer Sample Total Time 0.06966\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.06946\tTrain Loss 0.8830\t\n",
      "Epoch: [1][350/660]\tPer Sample Total Time 0.06956\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.06939\tTrain Loss 0.8250\t\n",
      "Epoch: [1][400/660]\tPer Sample Total Time 0.06946\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.06930\tTrain Loss 0.7701\t\n",
      "Epoch: [1][450/660]\tPer Sample Total Time 0.06940\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06926\tTrain Loss 0.7278\t\n",
      "Epoch: [1][500/660]\tPer Sample Total Time 0.06935\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06922\tTrain Loss 0.6936\t\n",
      "Epoch: [1][550/660]\tPer Sample Total Time 0.06929\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06917\tTrain Loss 0.6587\t\n",
      "Epoch: [1][600/660]\tPer Sample Total Time 0.06925\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06914\tTrain Loss 0.6318\t\n",
      "Epoch: [1][650/660]\tPer Sample Total Time 0.06922\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06911\tTrain Loss 0.6088\t\n",
      "start validation\n",
      "acc: 0.834559\n",
      "AUC: 0.982101\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.968750\n",
      "train_loss: 0.605566\n",
      "valid_loss: 1.808594\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 572.694\n",
      "---------------\n",
      "2025-12-12 13:24:15.625433\n",
      "current #epochs=2, #steps=660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][40/660]\tPer Sample Total Time 0.07020\tPer Sample Data Time 0.00130\tPer Sample DNN Time 0.06890\tTrain Loss 0.2272\t\n",
      "Epoch: [2][90/660]\tPer Sample Total Time 0.06956\tPer Sample Data Time 0.00060\tPer Sample DNN Time 0.06896\tTrain Loss 0.2209\t\n",
      "Epoch: [2][140/660]\tPer Sample Total Time 0.06915\tPer Sample Data Time 0.00040\tPer Sample DNN Time 0.06875\tTrain Loss 0.2355\t\n",
      "Epoch: [2][190/660]\tPer Sample Total Time 0.06903\tPer Sample Data Time 0.00030\tPer Sample DNN Time 0.06873\tTrain Loss 0.2272\t\n",
      "Epoch: [2][240/660]\tPer Sample Total Time 0.06894\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.06869\tTrain Loss 0.2095\t\n",
      "Epoch: [2][290/660]\tPer Sample Total Time 0.06889\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.06868\tTrain Loss 0.2062\t\n",
      "Epoch: [2][340/660]\tPer Sample Total Time 0.06883\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.06865\tTrain Loss 0.1992\t\n",
      "Epoch: [2][390/660]\tPer Sample Total Time 0.06879\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.06863\tTrain Loss 0.1926\t\n",
      "Epoch: [2][440/660]\tPer Sample Total Time 0.06877\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06862\tTrain Loss 0.1888\t\n",
      "Epoch: [2][490/660]\tPer Sample Total Time 0.06876\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06862\tTrain Loss 0.1877\t\n",
      "Epoch: [2][540/660]\tPer Sample Total Time 0.06872\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06860\tTrain Loss 0.1890\t\n",
      "Epoch: [2][590/660]\tPer Sample Total Time 0.06870\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06858\tTrain Loss 0.1894\t\n",
      "Epoch: [2][640/660]\tPer Sample Total Time 0.06868\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06857\tTrain Loss 0.1851\t\n",
      "start validation\n",
      "acc: 0.866422\n",
      "AUC: 0.984491\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.050249\n",
      "train_loss: 0.183014\n",
      "valid_loss: 1.797852\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 568.950\n",
      "---------------\n",
      "2025-12-12 13:33:44.575700\n",
      "current #epochs=3, #steps=1320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][30/660]\tPer Sample Total Time 0.07078\tPer Sample Data Time 0.00172\tPer Sample DNN Time 0.06906\tTrain Loss 0.1226\t\n",
      "Epoch: [3][80/660]\tPer Sample Total Time 0.06933\tPer Sample Data Time 0.00068\tPer Sample DNN Time 0.06865\tTrain Loss 0.1018\t\n",
      "Epoch: [3][130/660]\tPer Sample Total Time 0.06888\tPer Sample Data Time 0.00043\tPer Sample DNN Time 0.06845\tTrain Loss 0.0935\t\n",
      "Epoch: [3][180/660]\tPer Sample Total Time 0.06881\tPer Sample Data Time 0.00032\tPer Sample DNN Time 0.06849\tTrain Loss 0.0936\t\n",
      "Epoch: [3][230/660]\tPer Sample Total Time 0.06871\tPer Sample Data Time 0.00026\tPer Sample DNN Time 0.06845\tTrain Loss 0.0976\t\n",
      "Epoch: [3][280/660]\tPer Sample Total Time 0.06863\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.06841\tTrain Loss 0.0960\t\n",
      "Epoch: [3][330/660]\tPer Sample Total Time 0.06862\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06843\tTrain Loss 0.1028\t\n",
      "Epoch: [3][380/660]\tPer Sample Total Time 0.06861\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06844\tTrain Loss 0.1016\t\n",
      "Epoch: [3][430/660]\tPer Sample Total Time 0.06858\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06843\tTrain Loss 0.0990\t\n",
      "Epoch: [3][480/660]\tPer Sample Total Time 0.06855\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06841\tTrain Loss 0.1000\t\n",
      "Epoch: [3][530/660]\tPer Sample Total Time 0.06853\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06840\tTrain Loss 0.1018\t\n",
      "Epoch: [3][580/660]\tPer Sample Total Time 0.06852\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06840\tTrain Loss 0.1003\t\n",
      "Epoch: [3][630/660]\tPer Sample Total Time 0.06851\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06840\tTrain Loss 0.1019\t\n",
      "start validation\n",
      "acc: 0.850490\n",
      "AUC: 0.978309\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.856717\n",
      "train_loss: 0.102678\n",
      "valid_loss: 1.797852\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 565.542\n",
      "Running fold 10: /usr/bin/python3 src/run.py --model ast --dataset urban8k --data-train /kaggle/working/ast/urban8k_data/datafiles/urban_train_data_10.json --data-val /kaggle/working/ast/urban8k_data/datafiles/urban_eval_data_10.json --exp-dir /kaggle/working/ast/urban8k_exp/fold10 --label-csv /kaggle/working/ast/urban8k_data/urban8k_class_labels_indices.csv --n_class 10 --lr 1e-05 --n-epochs 3 --batch-size 12 --save_model False --freqm 24 --timem 96 --mixup 0 --bal none --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain False --metrics acc --loss CE --warmup False --lrscheduler_start 5 --lrscheduler_step 1 --lrscheduler_decay 0.85 --dataset_mean -1.7362523965764032 --dataset_std 3.2758855893221015 --audio_length 1024 --noise False --num-workers 4 --n-print-steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/models/ast_models.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/kaggle/working/ast/src/traintest.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 17318, running on 8b7e52d8b72d: starting (Fri Dec 12 13:43:14 2025)\n",
      "now train a audio spectrogram transformer model\n",
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 24 freq, 96 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process urban8k\n",
      "use dataset mean -1.736 and std 3.276 to normalize the input.\n",
      "number of classes is 10\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: False\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1212\n",
      "\n",
      "Creating experiment directory: /kaggle/working/ast/urban8k_exp/fold10\n",
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 87.734 million\n",
      "Total trainable parameter number is : 87.734 million\n",
      "now training with urban8k, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7d7aa251ab90>\n",
      "The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2025-12-12 13:43:16.569751\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][50/658]\tPer Sample Total Time 0.07296\tPer Sample Data Time 0.00097\tPer Sample DNN Time 0.07199\tTrain Loss 1.8669\t\n",
      "Epoch: [1][100/658]\tPer Sample Total Time 0.07082\tPer Sample Data Time 0.00050\tPer Sample DNN Time 0.07031\tTrain Loss 1.5028\t\n",
      "Epoch: [1][150/658]\tPer Sample Total Time 0.07026\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.06992\tTrain Loss 1.2903\t\n",
      "Epoch: [1][200/658]\tPer Sample Total Time 0.06993\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.06966\tTrain Loss 1.1530\t\n",
      "Epoch: [1][250/658]\tPer Sample Total Time 0.06972\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.06950\tTrain Loss 1.0562\t\n",
      "Epoch: [1][300/658]\tPer Sample Total Time 0.06955\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.06936\tTrain Loss 0.9684\t\n",
      "Epoch: [1][350/658]\tPer Sample Total Time 0.06944\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.06927\tTrain Loss 0.8957\t\n",
      "Epoch: [1][400/658]\tPer Sample Total Time 0.06936\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06921\tTrain Loss 0.8325\t\n",
      "Epoch: [1][450/658]\tPer Sample Total Time 0.06932\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06918\tTrain Loss 0.7864\t\n",
      "Epoch: [1][500/658]\tPer Sample Total Time 0.06925\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06912\tTrain Loss 0.7493\t\n",
      "Epoch: [1][550/658]\tPer Sample Total Time 0.06918\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06906\tTrain Loss 0.7193\t\n",
      "Epoch: [1][600/658]\tPer Sample Total Time 0.06914\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06903\tTrain Loss 0.6865\t\n",
      "Epoch: [1][650/658]\tPer Sample Total Time 0.06909\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.06898\tTrain Loss 0.6560\t\n",
      "start validation\n",
      "acc: 0.869773\n",
      "AUC: 0.982582\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.984358\n",
      "train_loss: 0.654871\n",
      "valid_loss: 1.830078\n",
      "validation finished\n",
      "Epoch-1 lr: 1e-05\n",
      "epoch 1 training time: 570.664\n",
      "---------------\n",
      "2025-12-12 13:52:47.234081\n",
      "current #epochs=2, #steps=658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][42/658]\tPer Sample Total Time 0.06993\tPer Sample Data Time 0.00122\tPer Sample DNN Time 0.06871\tTrain Loss 0.2889\t\n",
      "Epoch: [2][92/658]\tPer Sample Total Time 0.06932\tPer Sample Data Time 0.00058\tPer Sample DNN Time 0.06874\tTrain Loss 0.2490\t\n",
      "Epoch: [2][142/658]\tPer Sample Total Time 0.06896\tPer Sample Data Time 0.00039\tPer Sample DNN Time 0.06857\tTrain Loss 0.2305\t\n",
      "Epoch: [2][192/658]\tPer Sample Total Time 0.06881\tPer Sample Data Time 0.00030\tPer Sample DNN Time 0.06851\tTrain Loss 0.2232\t\n",
      "Epoch: [2][242/658]\tPer Sample Total Time 0.06874\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.06850\tTrain Loss 0.2212\t\n",
      "Epoch: [2][292/658]\tPer Sample Total Time 0.06873\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.06853\tTrain Loss 0.2100\t\n",
      "Epoch: [2][342/658]\tPer Sample Total Time 0.06870\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.06852\tTrain Loss 0.2108\t\n",
      "Epoch: [2][392/658]\tPer Sample Total Time 0.06868\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.06851\tTrain Loss 0.2135\t\n",
      "Epoch: [2][442/658]\tPer Sample Total Time 0.06864\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06849\tTrain Loss 0.2102\t\n",
      "Epoch: [2][492/658]\tPer Sample Total Time 0.06861\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06848\tTrain Loss 0.2100\t\n",
      "Epoch: [2][542/658]\tPer Sample Total Time 0.06860\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06848\tTrain Loss 0.2080\t\n",
      "Epoch: [2][592/658]\tPer Sample Total Time 0.06858\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06847\tTrain Loss 0.2022\t\n",
      "Epoch: [2][642/658]\tPer Sample Total Time 0.06856\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.06845\tTrain Loss 0.1995\t\n",
      "start validation\n",
      "acc: 0.845878\n",
      "AUC: 0.984044\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 3.034208\n",
      "train_loss: 0.196758\n",
      "valid_loss: 1.806641\n",
      "validation finished\n",
      "Epoch-2 lr: 1e-05\n",
      "epoch 2 training time: 565.444\n",
      "---------------\n",
      "2025-12-12 14:02:12.678448\n",
      "current #epochs=3, #steps=1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ast/src/traintest.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][34/658]\tPer Sample Total Time 0.07010\tPer Sample Data Time 0.00165\tPer Sample DNN Time 0.06846\tTrain Loss 0.1411\t\n",
      "Epoch: [3][84/658]\tPer Sample Total Time 0.06912\tPer Sample Data Time 0.00070\tPer Sample DNN Time 0.06843\tTrain Loss 0.1286\t\n",
      "Epoch: [3][134/658]\tPer Sample Total Time 0.06881\tPer Sample Data Time 0.00045\tPer Sample DNN Time 0.06836\tTrain Loss 0.1165\t\n",
      "Epoch: [3][184/658]\tPer Sample Total Time 0.06874\tPer Sample Data Time 0.00034\tPer Sample DNN Time 0.06840\tTrain Loss 0.1257\t\n",
      "Epoch: [3][234/658]\tPer Sample Total Time 0.06868\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.06841\tTrain Loss 0.1167\t\n",
      "Epoch: [3][284/658]\tPer Sample Total Time 0.06861\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.06838\tTrain Loss 0.1117\t\n",
      "Epoch: [3][334/658]\tPer Sample Total Time 0.06857\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.06837\tTrain Loss 0.1092\t\n",
      "Epoch: [3][384/658]\tPer Sample Total Time 0.06853\tPer Sample Data Time 0.00018\tPer Sample DNN Time 0.06836\tTrain Loss 0.1055\t\n",
      "Epoch: [3][434/658]\tPer Sample Total Time 0.06852\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.06836\tTrain Loss 0.1060\t\n",
      "Epoch: [3][484/658]\tPer Sample Total Time 0.06850\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.06835\tTrain Loss 0.1061\t\n",
      "Epoch: [3][534/658]\tPer Sample Total Time 0.06848\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.06835\tTrain Loss 0.1072\t\n",
      "Epoch: [3][584/658]\tPer Sample Total Time 0.06849\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.06836\tTrain Loss 0.1078\t\n",
      "Epoch: [3][634/658]\tPer Sample Total Time 0.06847\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.06835\tTrain Loss 0.1072\t\n",
      "start validation\n",
      "acc: 0.884110\n",
      "AUC: 0.979564\n",
      "Avg Precision: 0.100000\n",
      "Avg Recall: 1.000000\n",
      "d_prime: 2.891830\n",
      "train_loss: 0.108351\n",
      "valid_loss: 1.808594\n",
      "validation finished\n",
      "Epoch-3 lr: 1e-05\n",
      "epoch 3 training time: 566.913\n",
      "Fold 6: best val acc 0.8262\n",
      "Fold 7: best val acc 0.8652\n",
      "Fold 8: best val acc 0.7419\n",
      "Fold 9: best val acc 0.8664\n",
      "Fold 10: best val acc 0.8841\n",
      "10-fold mean acc: 0.8368 +/- 0.0510\n"
     ]
    }
   ],
   "source": [
    "# Kick off full 10-fold: each fold is held out as test once\n",
    "folds_to_run = list(range(6, 11))\n",
    "for f in folds_to_run:\n",
    "    run_fold(f)\n",
    "\n",
    "# Aggregate best validation accuracy per fold (col 0 of result.csv)\n",
    "fold_acc = []\n",
    "for f in folds_to_run:\n",
    "    res_path = REPO_DIR / 'urban8k_exp' / f'fold{f}' / 'result.csv'\n",
    "    arr = np.loadtxt(res_path, delimiter=',')\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr[None, :]\n",
    "    best_acc = float(arr[:, 0].max())\n",
    "    fold_acc.append(best_acc)\n",
    "    print(f'Fold {f}: best val acc {best_acc:.4f}')\n",
    "\n",
    "mean_acc = float(np.mean(fold_acc))\n",
    "std_acc = float(np.std(fold_acc))\n",
    "print(f'10-fold mean acc: {mean_acc:.4f} +/- {std_acc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 500970,
     "sourceId": 928025,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
