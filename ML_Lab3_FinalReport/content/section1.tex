\pagebreak
\section{Giới thiệu}
Lĩnh vực phân loại âm thanh (Audio Classification) đóng vai trò then chốt trong sự phát triển của các hệ thống trí tuệ nhân tạo hiện đại. Trong nhiều thập kỷ, các phương pháp tiếp cận từ mô hình thống kê GMM-HMM đến mạng nơ-ron tích chập (CNN) và các biến thể lai ghép (CNN-Attention Hybrid \cite{hershey2017cnn}) đã đặt nền móng vững chắc cho việc trích xuất đặc trưng từ tín hiệu âm thanh. Tuy nhiên, các kiến trúc dựa trên tích chập vẫn đối mặt với thách thức cố hữu trong việc nắm bắt các mối quan hệ ngữ cảnh toàn cục do giới hạn về vùng tiếp nhận cục bộ (local receptive field), hạn chế khả năng biểu diễn các chuỗi tín hiệu phức tạp.\\
Sự xuất hiện của kiến trúc Transformer, đặc biệt là thành công của mô hình Vision Transformer (ViT) \cite{dosovitskiy2020vit} trong thị giác máy tính, đã mở ra một hướng đi đột phá: xử lý dữ liệu không gian dưới dạng chuỗi các mảnh ghép (patches). Kế thừa tư duy này, mô hình \textbf{Audio Spectrogram Transformer (AST)} \cite{gong2021ast} đã được đề xuất như một giải pháp tiên phong loại bỏ hoàn toàn sự phụ thuộc vào tích chập (convolution-free). Bằng cơ chế Tự chú ý (Self-Attention), AST không chỉ giải quyết bài toán mô hình hóa sự phụ thuộc thời gian - tần số ở phạm vi toàn cục mà còn tận dụng hiệu quả tri thức chuyển giao (Transfer Learning) từ các bộ dữ liệu quy mô lớn như ImageNet và AudioSet để đạt hiệu suất vượt trội.\\
Trong phạm vi báo cáo này, chúng tôi tập trung nghiên cứu cơ chế hoạt động của kiến trúc AST và thực hiện quy trình thực nghiệm tinh chỉnh (fine-tuning) mô hình AST – vốn được huấn luyện trước trên AudioSet – để giải quyết bài toán phân loại âm thanh môi trường trên tập dữ liệu UrbanSound8K. Nghiên cứu nhằm mục đích kiểm chứng khả năng tổng quát hóa và hiệu quả của phương pháp học chuyển giao khi áp dụng các mô hình Transformer tiên tiến vào các bài toán cụ thể với tài nguyên dữ liệu giới hạn.